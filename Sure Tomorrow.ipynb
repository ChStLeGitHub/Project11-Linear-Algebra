{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Introduction](#1)\n",
    "\n",
    "[Data Exploration](#2)\n",
    "- [Preprocessing](#2.1)\n",
    "- [EDA (Exploratory Data Analysis)](#2.2)\n",
    "\n",
    "[Task 1: Similar Customers](#3)\n",
    "\n",
    "[Task 2: Is The Customer Likely to Receive Insurance Benefits?](#4)\n",
    "\n",
    "[Task 3: Linear Regression](#5)\n",
    "\n",
    "[Task 4: Obfuscating Data](#6)\n",
    "- [Proof That Data Obfuscation Can Work with Linear Regression](#6.1)\n",
    "- [Test the Linear Regression With Data Obfuscation](#6.2)\n",
    "\n",
    "[Conclusion](#7)\n",
    "\n",
    "[Appendices](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id = 1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <u>Sure Tomorrow</u> insurance company wants to solve several tasks with the help of Machine Learning, and I am tasked with solving them.\n",
    "\n",
    "<b>Task 1:</b> Find customers who are similar to a given customer. This will help the company's agents with marketing.\n",
    "\n",
    "<b>Task 2:</b> Predict whether a new customer is likely to receive an insurance benefit. Can a prediction model do better than a dummy model?\n",
    "\n",
    "<b>Task 3:</b> Predict the number of insurance benefits a new customer is likely to receive using a linear regression model.\n",
    "\n",
    "<b>Task 4:</b> Protect customers' personal data without breaking the model from the previous task. It's necessary to develop a data transformation algorithm that would make it hard to recover personal information if the data fell into the wrong hands. (This is called data masking, or data obfuscation.) Furthermore, the data should be protected in such a way that the quality of the machine learning models does not suffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration <a id = 2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preprocessing</b> <a id = 2.1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data and conduct a basic check to ensure that it is free from obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rename the columns so that they are written in snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.rename(columns = {'Gender': 'gender', 'Age': 'age', 'Salary': 'income', \n",
    "                                    'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think it is always a good idea to display a random sample of rows from the dataframe in order to see what the rows look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40600.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>55600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46600.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>37100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age   income  family_members  insurance_benefits\n",
       "3558       1  33.0  40600.0               3                   0\n",
       "4532       0  30.0  40400.0               0                   0\n",
       "2824       1  40.0  41900.0               1                   0\n",
       "205        0  25.0  45000.0               0                   0\n",
       "4255       1  24.0  55600.0               1                   0\n",
       "4176       0  39.0  35800.0               1                   0\n",
       "3751       0  35.0  44100.0               0                   0\n",
       "4415       1  19.0  46600.0               2                   0\n",
       "4940       1  39.0  42100.0               1                   0\n",
       "3523       0  35.0  37100.0               0                   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder if the Dtypes are appropriate. Here is where the **info** function comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              5000 non-null   int64  \n",
      " 1   age                 5000 non-null   float64\n",
      " 2   income              5000 non-null   float64\n",
      " 3   family_members      5000 non-null   int64  \n",
      " 4   insurance_benefits  5000 non-null   int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 195.4 KB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great to see that there are no null values! \n",
    "\n",
    "Thanks to the sample of 10 rows and the info function, I noticed that the **age** and **income** values have Dtype float64, and they all have 0 after the decimal.\n",
    "\n",
    "Since all of the digits after the decimal are 0, I might as well change the Dtypes of **age** and **income** to int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['age'] = main_df['age'].astype(int)\n",
    "main_df['income'] = main_df['income'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the Dtype conversions were successful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   gender              5000 non-null   int64\n",
      " 1   age                 5000 non-null   int32\n",
      " 2   income              5000 non-null   int32\n",
      " 3   family_members      5000 non-null   int64\n",
      " 4   insurance_benefits  5000 non-null   int64\n",
      "dtypes: int32(2), int64(3)\n",
      "memory usage: 156.4 KB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes they were!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder if any of the rows in the dataframe are exact duplicates. If so, then they should be dropped because it is unlikely that two or more distinct people would coincidentally have the same gender, age, number of family members, and income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>48100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>32900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>37400</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>32600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>35800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>37800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>38700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>32700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>45800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>40100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  income  family_members  insurance_benefits\n",
       "281        1   39   48100               1                   0\n",
       "488        1   24   32900               1                   0\n",
       "513        0   31   37400               2                   0\n",
       "718        1   22   32600               1                   0\n",
       "785        0   20   35800               0                   0\n",
       "...      ...  ...     ...             ...                 ...\n",
       "4793       1   24   37800               0                   0\n",
       "4902       1   35   38700               1                   0\n",
       "4935       1   19   32700               0                   0\n",
       "4945       1   21   45800               0                   0\n",
       "4965       0   22   40100               1                   0\n",
       "\n",
       "[153 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df[main_df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there are 153 duplicate rows, which get dropped in the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4847 entries, 0 to 4846\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   gender              4847 non-null   int64\n",
      " 1   age                 4847 non-null   int32\n",
      " 2   income              4847 non-null   int32\n",
      " 3   family_members      4847 non-null   int64\n",
      " 4   insurance_benefits  4847 non-null   int64\n",
      "dtypes: int32(2), int64(3)\n",
      "memory usage: 151.6 KB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe has gone from 5000 rows to 4847, which, thankfully, is a less than 5% decrease, so having done this should not negatively impact anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the descriptive statistics of each column to see if there are any outliers that should be dealt with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "0    2431\n",
       "1    2416\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing unusual with the **gender** column! \n",
    "\n",
    "If anything, this column implies that it is nearly equally common for men to seek insurance from <u>Sure Tomorrow</u> as women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4847.000000\n",
       "mean       31.023932\n",
       "std         8.487995\n",
       "min        18.000000\n",
       "25%        24.000000\n",
       "50%        30.000000\n",
       "75%        37.000000\n",
       "max        65.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing unusual here either! The minimum **age** in the dataframe is 18, which makes sense because at age 18 an individual is considered an adult, and therefore can qualify for insurance. Also, the maximum age in the dataframe is 65, which is also a reasonable age for a person seeking to get insurance.\n",
    "\n",
    "Since the third quartile age is 37, that means more than 75% of <u>Sure Tomorrow</u> customers are between the ages of 18 and 40. My takeaway from this observation is that <u>Sure Tomorrow</u> tends to attract adults who are in early to mid adulthood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4847.000000\n",
       "mean     39895.811223\n",
       "std       9972.952441\n",
       "min       5300.000000\n",
       "25%      33200.000000\n",
       "50%      40200.000000\n",
       "75%      46600.000000\n",
       "max      79000.000000\n",
       "Name: income, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['income'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought that the minimum **income** value, 5300, seemed very low, however I think low values like this are worth keeping because there are many reasons why a <u>Sure Tomorrow</u> customer would have this amount of income. For example, maybe the customer is a young adult who is only working part–time because they are also a full–time college student.\n",
    "\n",
    "If I used the IQR method for detecting outliers, then any income below 33200 – 1.5(46600 – 33200) = 13100 or above 46600 + 1.5(46600 – 33200) = 66700 would be considered an outlier. However, I will not drop any of the income \"outliers\" because none of them seem to be absurd in any way. In fact, dropping them might cause my models to lose valuable data, to the point that the models would not be as accurate as they otherwise would be.\n",
    "\n",
    "Notice also that the maximum income value is 79000, which means none of the customers in this dataframe make \"six figures\". I mention this because this implies that <u>Sure Tomorrow</u> appeals to adults who are lower or middle class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "family_members\n",
       "1    1748\n",
       "0    1461\n",
       "2    1038\n",
       "3     437\n",
       "4     124\n",
       "5      32\n",
       "6       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['family_members'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though having 0, 1, or 2 family members is far more common in this dataframe than having 3, 4, 5, or 6, I think those less common values are worth keeping because it is useful for <u>Sure Tomorrow</u> to know the extent to which larger families can qualify for benefits. With that said, it does appear as though <u>Sure Tomorrow</u> is more appealing to smaller families than larger ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insurance_benefits\n",
       "0    4284\n",
       "1     423\n",
       "2     114\n",
       "3      18\n",
       "4       7\n",
       "5       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['insurance_benefits'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is rare for a customer to receive 3, 4, or 5 benefits, I don't think any of these values are outlandish enough to justify dropping their rows.\n",
    "\n",
    "On the other hand, I find it interesting how the <b><i>overwhelming majority</b></i> of people in the dataframe do not qualify for any benefits. This makes me wonder which features values tend to allow a person to qualify for at least one benefit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EDA (Exploratory Data Analysis)</b> <a id = 2.2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if a pair plot can help me identify ways to categorize the customers into groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKEAAASgCAYAAAAgm1uCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADzgklEQVR4nOzde3wU1f3/8XeumxByBUm4RKTegC8IiAJRvEfTFq0XtKhUaUqxUlAgXmkRrTeUKmIrQrUKvUClaLUqFqVRUDSARlEUAS8oCCSg5AIBNtffH/7cOsvMht3szGx2X8/HIw89Z87MOTO7J7v5MPM5cS0tLS0CAAAAAAAAbBTv9gAAAAAAAAAQ/QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGECpOWlhbV1taqpaXF7aEAMYE5BziPeQc4izkHOI95B9iLIFSY7N27V5mZmdq7d6/bQwFiAnMOcB7zDnAWcw5wHvMOsBdBKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANtFZRDq9ddf1wUXXKBu3bopLi5Ozz33XKv7rFixQieeeKI8Ho+OOeYYLViwwPZxAgAAAAAAxIqoDELV1dVpwIABmjNnzmG137Jli0aMGKGzzjpL69at0+TJk/XLX/5SL7/8ss0jBQAAAAAAiA2Jbg/ADj/60Y/0ox/96LDbz5s3T7169dKDDz4oSerTp49WrVqlhx56SEVFRXYNEwAAAAAAIGZEZRAqWGVlZSosLDTUFRUVafLkyZb7eL1eeb1eX7m2ttau4QEQcw5wA/MOcBZzDnAe8w5wFkEoSRUVFcrNzTXU5ebmqra2VgcOHFBqauoh+8yYMUO/+93vnBoiEPPaMucKpvzNtD6paotp/Z7+F5vW56x/1rT+m6E/N63v9OqD5scvuMb8+Ov+aX784b8yrZekTqW/N9/nnJvM+1i70LS+43nXmdZ/vW65af1xJxWa1q/bttW0/ryje5jWv1EbZ1o/Oq/RtL6mwfwp8qykZtP6g03mx5ekI1LM90mIazGt75BkXm/Fqmero1g9H3/p0GzT+qfXVAXVPhShzrt/+o3tp62MafFqY/s4v4tX4zVenY5+r0W930v5zcHA2Qb21Bu37/Q7/g7/7Qe8hnJD7W7jAZubDMX4+v2GctYnrxnKjR2PMLZvOGjcnpplKCfX7DCU46q/MPYfn2Qsezoax5vTy9jcu89Q3p/b11BuTkw2jifdON6kTGP52DRj+x4e4wtS22h8QXt3NF4v/zmRlmisyUw2Hi/Belp/uz3euH+LXwf++/vPGf+51dp2szahastn3akT51lue/ORa0MdUkCnXzbJctvrSx62pc8BM9ZYbnt/6lBb+gxk3HP7Lbc9flEHW/p84o0ay21jT8u0pU//39PfN2pY+D53vs/qc06KjM+60386Oeh9Xv/n7KD3kaQ5K4IPjE04MyOkvkKx8K3qkPYbfUpWWMdh5Zm11u+lQEYOsee9bSaUMYY6Pif7MhOVOaGcMHXqVNXU1Ph+tm3b5vaQgKjGnAOcx7wDnMWcA5zHvAOcxZ1QkvLy8lRZWWmoq6ysVEZGhuldUJLk8Xjk8XicGB4AMecANzDvAGcx5wDnMe8AZ3EnlKSCggKVlpYa6pYvX66CggKXRgQAAAAAABBdojIItW/fPq1bt07r1q2TJG3ZskXr1q3T1q3f5iqZOnWqrr76al/7a6+9Vp9//rluvvlmbdy4UY8++qj++c9/asqUKW4MHwAAAAAAIOpEZRDqnXfe0aBBgzRo0CBJUklJiQYNGqTp06dLknbu3OkLSElSr169tHTpUi1fvlwDBgzQgw8+qD//+c8qKipyZfwAAAAAAADRJipzQp155plq8V8K5XsWLFhgus97771n46gAAAAAAABiV1TeCQUAAAAAAIDIQhAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALBdXEtLS4vbg4gGtbW1yszMVE1NjTIyMtweDhD1mHOA85h3gLOYc4DzmHeAvbgTCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB1BKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdlEbhJozZ46OOuoopaSkaOjQoVq7dm3A9rNnz9bxxx+v1NRU5efna8qUKTp48KBDowUAAAAAAIhuURmEWrx4sUpKSnT77bfr3Xff1YABA1RUVKRdu3aZtl+0aJFuvfVW3X777fr444/1xBNPaPHixfrNb37j8MgBAAAAAACiU1QGoWbNmqVx48apuLhYffv21bx589ShQwc9+eSTpu3feustnXrqqbryyit11FFH6bzzztMVV1zR6t1TAAAAAAAAODyJbg8g3Orr61VeXq6pU6f66uLj41VYWKiysjLTfU455RT9/e9/19q1azVkyBB9/vnneumll3TVVVdZ9uP1euX1en3l2tra8J0EgEMw5wDnMe8AZzHnAOcx7wBnRd2dUF9//bWampqUm5trqM/NzVVFRYXpPldeeaXuvPNODR8+XElJSTr66KN15plnBnwcb8aMGcrMzPT95Ofnh/U8ABgx5wDnMe8AZzHnAOcx7wBnxbW0tLS4PYhw2rFjh7p376633npLBQUFvvqbb75ZK1eu1Jo1aw7ZZ8WKFbr88st19913a+jQofr00081adIkjRs3TrfddptpP2YR8/z8fNXU1CgjIyP8JwbEOOYc4DzmHeAs5hzgPOYd4Kyoexyvc+fOSkhIUGVlpaG+srJSeXl5pvvcdtttuuqqq/TLX/5SktS/f3/V1dXpmmuu0W9/+1vFxx96w5jH45HH4wn/CQAwxZwDnMe8A5zFnAOcx7wDnBV1j+MlJydr8ODBKi0t9dU1NzertLTUcGfU9+3fv/+QQFNCQoIkKcpuFAMAAAAAAHBF1N0JJUklJSUaM2aMTjrpJA0ZMkSzZ89WXV2diouLJUlXX321unfvrhkzZkiSLrjgAs2aNUuDBg3yPY5322236YILLvAFowAAAAAAABC6qAxCjRo1Srt379b06dNVUVGhgQMHatmyZb5k5Vu3bjXc+TRt2jTFxcVp2rRp2r59u4444ghdcMEFuueee9w6BQAAAAAAgKgSdYnJ3VJbW6vMzEwS2AEOYc4BzmPeAc5izgHOY94B9oq6nFAAAAAAAACIPAShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjiAUAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB1BKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjiAUAAAAAAAAbBcxQaimpia9/vrrqq6uDsvx5syZo6OOOkopKSkaOnSo1q5dG7B9dXW1JkyYoK5du8rj8ei4447TSy+9FJaxAAAAAAAAxLqICUIlJCTovPPOU1VVVZuPtXjxYpWUlOj222/Xu+++qwEDBqioqEi7du0ybV9fX69zzz1XX3zxhZ5++mlt2rRJjz/+uLp3797msQAAAAAAAEBKdHsA39evXz99/vnn6tWrV5uOM2vWLI0bN07FxcWSpHnz5mnp0qV68skndeuttx7S/sknn9SePXv01ltvKSkpSZJ01FFHtWkMAAAAAAAA+J+IuRNKku6++27deOONevHFF7Vz507V1tYafg5HfX29ysvLVVhY6KuLj49XYWGhysrKTPd5/vnnVVBQoAkTJig3N1f9+vXTvffeq6amJst+vF5vSOMDEBrmHOA85h3gLOYc4DzmHeCsiApC/fjHP9b777+vn/zkJ+rRo4eys7OVnZ2trKwsZWdnH9Yxvv76azU1NSk3N9dQn5ubq4qKCtN9Pv/8cz399NNqamrSSy+9pNtuu00PPvig7r77bst+ZsyYoczMTN9Pfn7+4Z8ogKAx5wDnMe8AZzHnAOcx7wBnxbW0tLS4PYjvrFy5MuD2M844o9Vj7NixQ927d9dbb72lgoICX/3NN9+slStXas2aNYfsc9xxx+ngwYPasmWLEhISJH37SN/vf/977dy507Qfr9crr9frK9fW1io/P181NTXKyMhodZwAgsOcA5zHvAOcxZwDnMe8A5wVUTmhDifI1JrOnTsrISFBlZWVhvrKykrl5eWZ7tO1a1clJSX5AlCS1KdPH1VUVKi+vl7JycmH7OPxeOTxeNo8XgCHhzkHOI95BziLOQc4j3kHOCuiHseTpDfeeEM/+9nPdMopp2j79u2SpL/97W9atWrVYe2fnJyswYMHq7S01FfX3Nys0tJSw51R33fqqafq008/VXNzs69u8+bN6tq1q2kACgAAAAAAAMGJqCDUM888o6KiIqWmpurdd9/13RZZU1Oje++997CPU1JSoscff1x/+ctf9PHHH2v8+PGqq6vzrZZ39dVXa+rUqb7248eP1549ezRp0iRt3rxZS5cu1b333qsJEyaE9wQBAAAAAABiVEQ9jnf33Xdr3rx5uvrqq/XUU0/56k899dSAScL9jRo1Srt379b06dNVUVGhgQMHatmyZb5k5Vu3blV8/P/ib/n5+Xr55Zc1ZcoUnXDCCerevbsmTZqkW265JXwnBwAAAAAAEMMiKgi1adMmnX766YfUZ2Zmqrq6OqhjTZw4URMnTjTdtmLFikPqCgoKtHr16qD6AAAAAAAAwOGJqMfx8vLy9Omnnx5Sv2rVKv3gBz9wYUQAAAAAAAAIh4gKQo0bN06TJk3SmjVrFBcXpx07dmjhwoW68cYbNX78eLeHBwAAAAAAgBBF1ON4t956q5qbm3XOOedo//79Ov300+XxeHTjjTfquuuuc3t4YbNr1y7V1NQEtU9mZqa6dOli04gAAAAAAADsFVFBqLi4OP32t7/VTTfdpE8//VT79u1T37591bFjR7eHFja7du3SMcceq721tUHtl56RoU8/+YRAFFwTSvBUIoAKAAAAAPhWRAWhvpOcnKy+ffu6PQxb1NTUaG9trc6YNFtpnboe1j513+zUyocnq6amhj/m4YpQg6cSAVQAAAAAwLdcD0Jdcsklh932X//6l40jcVZap65Kz813exjAYQkleCoRQAUAAAAA/I/rQajMzEzf/7e0tOjZZ59VZmamTjrpJElSeXm5qqurgwpWAbAHwVMAAAAAQKhcD0LNnz/f9/+33HKLfvrTn2revHlKSEiQJDU1NenXv/61MjIy3BoiAAAAAAAA2ije7QF835NPPqkbb7zRF4CSpISEBJWUlOjJJ590cWQAAAAAAABoi4gKQjU2Nmrjxo2H1G/cuFHNzc0ujAgAAAAAAADh4PrjeN9XXFyssWPH6rPPPtOQIUMkSWvWrNF9992n4uJil0cHAAAAAACAUEVUEOqBBx5QXl6eHnzwQe3cuVOS1LVrV91000264YYbXB4dAAAAAAAAQhVRQaj4+HjdfPPNuvnmm1VbWytJJCQHAAAAAACIAhEVhPo+gk8AAAAAAADRI6ISk1dWVuqqq65St27dlJiYqISEBMMPAAAAAAAA2qeIuhPq5z//ubZu3arbbrtNXbt2VVxcnNtDAgAAAAAAQBhEVBBq1apVeuONNzRw4EC3hwIAAAAAAIAwiqjH8fLz89XS0uL2MAAAAAAAABBmERWEmj17tm699VZ98cUXbg8FAAAAAAAAYRRRj+ONGjVK+/fv19FHH60OHTooKSnJsH3Pnj0ujQwAAAAAAABtEVFBqNmzZ7s9BAAAAAAAANggooJQY8aMcXsIAAAAAAAAsEFE5YSSpM8++0zTpk3TFVdcoV27dkmS/vOf/+ijjz5yeWQAAAAAAAAIVUQFoVauXKn+/ftrzZo1+te//qV9+/ZJkt5//33dfvvtLo8OAAAAAAAAoYqoINStt96qu+++W8uXL1dycrKv/uyzz9bq1atdHBkAAAAAAADaIqKCUOvXr9fFF198SH2XLl309ddfuzAiAAAAAAAAhENEBaGysrK0c+fOQ+rfe+89de/e3YURAQAAAAAAIBwiKgh1+eWX65ZbblFFRYXi4uLU3NysN998UzfeeKOuvvpqt4cHAAAAAACAEEVUEOree+9V7969lZ+fr3379qlv37467bTTdMopp2jatGlBHWvOnDk66qijlJKSoqFDh2rt2rWHtd9TTz2luLg4XXTRRSGcAQAAAAAAAMxEVBAqOTlZjz/+uD7//HO9+OKL+vvf/65Nmzbpb3/7mxISEg77OIsXL1ZJSYluv/12vfvuuxowYICKioq0a9eugPt98cUXuvHGG3Xaaae19VQAAAAAAADwPYluD+D7SkpKDqlbvXq14uLilJKSomOOOUYXXnihcnJyAh5n1qxZGjdunIqLiyVJ8+bN09KlS/Xkk0/q1ltvNd2nqalJo0eP1u9+9zu98cYbqq6ubvP5AAAAAAAA4FsRFYR677339O6776qpqUnHH3+8JGnz5s1KSEhQ79699eijj+qGG27QqlWr1LdvX9Nj1NfXq7y8XFOnTvXVxcfHq7CwUGVlZZZ933nnnerSpYvGjh2rN954o9Wxer1eeb1eX7m2tvZwTxNACJhzgPOYd4CzmHOA85h3gLMi6nG8Cy+8UIWFhdqxY4fKy8tVXl6ur776Sueee66uuOIKbd++XaeffrqmTJlieYyvv/5aTU1Nys3NNdTn5uaqoqLCdJ9Vq1bpiSee0OOPP37YY50xY4YyMzN9P/n5+Ye9L4DgMecA5zHvAGcx5wDnMe8AZ0VUEOr3v/+97rrrLmVkZPjqMjMzdccdd2jmzJnq0KGDpk+frvLy8rD1uXfvXl111VV6/PHH1blz58Peb+rUqaqpqfH9bNu2LWxjAnAo5hzgPOYd4CzmHOA85h3grIh6HK+mpka7du065FG73bt3+26LzMrKUn19veUxOnfurISEBFVWVhrqKysrlZeXd0j7zz77TF988YUuuOACX11zc7MkKTExUZs2bdLRRx99yH4ej0cej+fwTw5AmzDnAOcx7wBnMecA5zHvAGdF1J1QF154oX7xi1/o2Wef1VdffaWvvvpKzz77rMaOHauLLrpIkrR27Vodd9xxlsdITk7W4MGDVVpa6qtrbm5WaWmpCgoKDmnfu3dvrV+/XuvWrfP9/OQnP9FZZ52ldevWcTsmAAAAAABAGETUnVB/+tOfNGXKFF1++eVqbGyU9O3dSGPGjNFDDz0k6dug0Z///OeAxykpKdGYMWN00kknaciQIZo9e7bq6up8q+VdffXV6t69u2bMmKGUlBT169fPsH9WVpYkHVIPAAAAAACA0ERUEKpjx456/PHH9dBDD+nzzz+XJP3gBz9Qx44dfW0GDhzY6nFGjRql3bt3a/r06aqoqNDAgQO1bNkyX7LyrVu3Kj4+om4CAwAAAAAAiGoRFYT6TseOHXXCCSe06RgTJ07UxIkTTbetWLEi4L4LFixoU98AAAAAAAAw4nYgAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB1BKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjiAUAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA20VtEGrOnDk66qijlJKSoqFDh2rt2rWWbR9//HGddtppys7OVnZ2tgoLCwO2BwAAAAAAQHCiMgi1ePFilZSU6Pbbb9e7776rAQMGqKioSLt27TJtv2LFCl1xxRV67bXXVFZWpvz8fJ133nnavn27wyMHAAAAAACITlEZhJo1a5bGjRun4uJi9e3bV/PmzVOHDh305JNPmrZfuHChfv3rX2vgwIHq3bu3/vznP6u5uVmlpaUOjxwAAAAAACA6Jbo9gHCrr69XeXm5pk6d6quLj49XYWGhysrKDusY+/fvV0NDg3JycizbeL1eeb1eX7m2tjb0QQNoFXMOcB7zDnAWcw5wHvMOcFbU3Qn19ddfq6mpSbm5uYb63NxcVVRUHNYxbrnlFnXr1k2FhYWWbWbMmKHMzEzfT35+fpvGDSAw5hzgPOYd4CzmHOA85h3grKgLQrXVfffdp6eeekrPPvusUlJSLNtNnTpVNTU1vp9t27Y5OEog9jDnAOcx7wBnMecA5zHvAGdF3eN4nTt3VkJCgiorKw31lZWVysvLC7jvAw88oPvuu0///e9/dcIJJwRs6/F45PF42jxeAIeHOQc4j3kHOIs5BziPeQc4K+ruhEpOTtbgwYMNScW/SzJeUFBgud/MmTN11113admyZTrppJOcGCoAAAAAAEDMiLo7oSSppKREY8aM0UknnaQhQ4Zo9uzZqqurU3FxsSTp6quvVvfu3TVjxgxJ0v3336/p06dr0aJFOuqoo3y5ozp27KiOHTu6dh4AAAAAAADRIiqDUKNGjdLu3bs1ffp0VVRUaODAgVq2bJkvWfnWrVsVH/+/m8Dmzp2r+vp6XXrppYbj3H777brjjjucHDoAAAAAAEBUisoglCRNnDhREydONN22YsUKQ/mLL76wf0AAAAAAAAAxLOpyQgEAAAAAACDyEIQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB1BKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtEt0eAADYbfj4P5rWx+/daVr/zWm/Nq3vtOZvpvVVfX9sWp+9brFp/Z7TrzOtz3l1lvnxTxptWi9JWZv+a1pfPWyMefvVCyza/9y0Pmnb+6b1PfsNN63/dMvHpvUX9jvWtP6FygbT+hFdkk3r61tMq3VceqNpfUNznPkOktKTmk3rEyx2ibOoT4gzH9SoYdmm9UvWVJnWXzbUvP3TFu0vtWgfifzPocnvkjW1GC9ucryxQV2jcXuS3z+h1TUYt1ceTDCUOyQYX+ttB4zbK+qNB0zye63XVe83lJsb6g3llv3Vxv33fm0oJ+//xlD27PnSUI7z1hiPl5hiKDem5xmPv+M94wCb/d7LHbsYivWdjzH212Scd03JaYby/iOM7RM69TCO52Cdodwho7OhfEIH43jSjZdbR3YwzteOScbXO9Hv+if4vR+S/V7/KwqyDOXFq43vN/+56P9+9J9LrW2PVFafdZK0aq75505bnX7lLZbbXl90vy19Dpix2nLb+1OH2dJnIKP/dcBy28JLUm3p80+v11hu+9Xpmbb06T+vvs/q866tnllr3efIIe7Py9MvmxT0Pq8veTikvh5+rTbofSadlRFSX6F4anV1SPtdPiwrrOOwYvVdqjVO/v4P9H63EgnzIBTcCQUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA20VtEGrOnDk66qijlJKSoqFDh2rt2rUB2y9ZskS9e/dWSkqK+vfvr5deesmhkQIAAAAAAES/qAxCLV68WCUlJbr99tv17rvvasCAASoqKtKuXbtM27/11lu64oorNHbsWL333nu66KKLdNFFF+nDDz90eOQAAAAAAADRKSqDULNmzdK4ceNUXFysvn37at68eerQoYOefPJJ0/YPP/ywfvjDH+qmm25Snz59dNddd+nEE0/UI4884vDIAQAAAAAAolOi2wMIt/r6epWXl2vq1Km+uvj4eBUWFqqsrMx0n7KyMpWUlBjqioqK9Nxzz1n24/V65fV6feXa2tq2DRxAQMw5wHnMO8BZzDnAecw7wFlRF4T6+uuv1dTUpNzcXEN9bm6uNm7caLpPRUWFafuKigrLfmbMmKHf/e53bR8wgMPSljm3au514RnEr6a23sZgQHDNr/l9kMeXpIHBNR97U5DHLwyy/aCgWt8d5NGjwWVDs4Nqf2mQ7cMpXJ91bp5DeKS2sr2rI6P4n6sd7s9fZL+eo4YFHl9r78f2OufC9lkXhNcX3e94n+9PHeZ4n4EsvKS13w/h96vTMx3vs7V5ZYeRQ5zpM9R59/qSh20YjblJZ2U41lcoLh+W5fYQAmoP30Ocer9Hgqh8HM8JU6dOVU1Nje9n27Ztbg8JiGrMOcB5zDvAWcw5wHnMO8BZUXcnVOfOnZWQkKDKykpDfWVlpfLy8kz3ycvLC6q9JHk8Hnk8nrYPGMBhYc4BzmPeAc5izgHOY94Bzoq6O6GSk5M1ePBglZaW+uqam5tVWlqqgoIC030KCgoM7SVp+fLllu0BAAAAAAAQnKi7E0qSSkpKNGbMGJ100kkaMmSIZs+erbq6OhUXF0uSrr76anXv3l0zZsyQJE2aNElnnHGGHnzwQY0YMUJPPfWU3nnnHT322GNungYAAAAAAEDUiMog1KhRo7R7925Nnz5dFRUVGjhwoJYtW+ZLPr5161bFx//vJrBTTjlFixYt0rRp0/Sb3/xGxx57rJ577jn169fPrVMAAAAAAACIKlEZhJKkiRMnauLEiabbVqxYcUjdZZddpssuu8zmUQEAAAAAAMSmqMsJBQAAAAAAgMhDEAoAAAAAAAC2i9rH8ZzW0tIiSaqtrQ3Ybt++fZKkvbu2q6mp6bCOvf+bCknShg0bfPsDTtq6dauk4N630v/eu/v27Wt1bqSnpysuLu6wj324cw6ANeYd4CzmHOCsYOecxLwD2qq1eRfX8t0sQ5t89dVXys/Pd3sYQLtVU1OjjIyMw27PnAPajnkHOIs5Bzgr2DknMe+Atmpt3hGECpPm5mbt2LGj1ahfbW2t8vPztW3btqB/ISJ0XHd3BHPdg/2XqsOdc+EcIw7F9Wsbt6+fW/OuvXD79XFTLJ+7ZN/52zXnYvX1itXzljh3u75fSoc372L5+geLaxWcaLherc07HscLk/j4ePXo0eOw22dkZLTbN1V7xnV3hx3XPdg51xreG23D9Wub9nL9wj3v2ov28vrYIZbPXXL//Pl+eXhi9bwlzt2Ocw9m3sXy9Q8W1yo40Xy9SEwOAAAAAAAA2xGEAgAAAAAAgO0IQjnM4/Ho9ttvl8fjcXsoMYXr7o72cN3bwxgjGdevbbh+kS2WX59YPnep/Z1/extvuMTqeUucu9vnHgljaC+4VsGJhetFYnIAAAAAAADYjjuhAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjiBUmLS0tKi2tlak2AKcwZwDnMe8A5zFnAOcx7wD7EUQKkz27t2rzMxM7d271+2hADGBOQc4j3kHOIs5BziPeQfYiyAUAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGyX6PYAALQPT6+pCmm/S4dmh3kkABBbFpVVG8pXFmS5Mg7AX6DvBnz+A0BkemZt8H/XjRwSvt/p3AkFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB2r47kglFXGWGEEbuM9CMAtsb46XKydL0Ljxkp1fDcAgPBwcsW6cK50FwruhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjtXxXMBKImiPQlnVUeL9DqDtYn11uFhfHRCHx43PWzdW5AMAtG/cCQUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGC7mAlCbd++XT/72c/UqVMnpaamqn///nrnnXd821taWjR9+nR17dpVqampKiws1CeffOLiiAEAAAAAAKJHTAShqqqqdOqppyopKUn/+c9/tGHDBj344IPKzv7fqh0zZ87UH/7wB82bN09r1qxRWlqaioqKdPDgQRdHDgAAAAAAEB0S3R6AE+6//37l5+dr/vz5vrpevXr5/r+lpUWzZ8/WtGnTdOGFF0qS/vrXvyo3N1fPPfecLr/88rCOZ0kIS91fxjK3cFmz2wMAgAixqKw64PYrC7ICtvff3ppg27e1P7uPB3s8tbractvlw7Js6fNSF76f/jPA9+if8n0ZQDvV1OL2CJwTE3dCPf/88zrppJN02WWXqUuXLho0aJAef/xx3/YtW7aooqJChYWFvrrMzEwNHTpUZWVlpsf0er2qra01/ACwD3MOcB7zDnAWcw5wHvMOcFZMBKE+//xzzZ07V8cee6xefvlljR8/Xtdff73+8pe/SJIqKiokSbm5uYb9cnNzfdv8zZgxQ5mZmb6f/Px8e08CiHHMOcB5zDvAWcw5wHnMO8BZMRGEam5u1oknnqh7771XgwYN0jXXXKNx48Zp3rx5IR9z6tSpqqmp8f1s27YtjCMG4I85BziPeQc4izkHOI95BzgrJnJCde3aVX379jXU9enTR88884wkKS8vT5JUWVmprl27+tpUVlZq4MCBpsf0eDzyeDz2DBjAIZhzgPOYd4CzmHOA85h3gLNi4k6oU089VZs2bTLUbd68WT179pT0bZLyvLw8lZaW+rbX1tZqzZo1KigocHSsAAAAAAAA0Sgm7oSaMmWKTjnlFN1777366U9/qrVr1+qxxx7TY489JkmKi4vT5MmTdffdd+vYY49Vr169dNttt6lbt2666KKLwj4eVrpDexTn9gAAwCXBroYX7PZwC3d/rIbXPiTGOb+00tMBVqqza+U8VsADEKxAv6sCcXIF0Fj63RYTQaiTTz5Zzz77rKZOnao777xTvXr10uzZszV69Ghfm5tvvll1dXW65pprVF1dreHDh2vZsmVKSUlxceQAAAAAAADRISaCUJJ0/vnn6/zzz7fcHhcXpzvvvFN33nmng6MCAAAAAACIDTGREwoAAAAAAADuIggFAAAAAAAA2xGEAgAAAAAAgO1iJidUJFm8Ovjs/KOGxU62fEQm59fcAQBnzF9VYygXD880lP1Xh2tttTy7+fcf7tXrWrserbF7fDDX7PYAHPKPAPPvCt5rAEw08YdMROFOKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdoluDyAWNbXEuT0EAADw/xUPzwyq/ZVBLgO/yG9JeW+T8XuAJyHw2tGt9Td/VY2hHOz5+Gttf//z8R9fsNcH4dHswvdL//eyE5LiWWsdQHBaxN/fkYQ7oQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2Y3U8F7SwqAfaof0NrCoBIDq0tlpdsKvLtbZaXE298fjjzzAev7X9/Ve/k4Ib76H7GwW7f/HwLPOGcFVDk/N9NrvwnfZAI99HgEjz1zerQ9rv6lOzwjoOK5cPc6YfHB7uhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjtXxXNDE6nhoh5paWI0GQGRqbXU5f61tb2t/c1caV5NLSVDA7ePPCDweT4Lxi4P/an7+4zl0f2PZf7ytnY9//62tLujfvq3XG5HrYJPz3w2SElpv46R/rqmy3PbTodm29Pl0gD4vtalPIBD+TkAwuBMKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALBdotsDiEV7G4j9of3ZfZD3LYDI5A1ymfhFZdWG8pUFWYby/FU1Aff3+C0R799+/BmZhvKs0lpDOa9Dc8Djz13p37/x/A40Gst5HVoM5be/STKU81ObAo63eHhWwO0H/a6v//m1xv96+/O//uHW2usdLfbUO/85vbfB+WXZ99ZH1lLwzTGyNP3Ta6ost106NNvBkSASVXljYx4gPGLir8o77rhDcXFxhp/evXv7th88eFATJkxQp06d1LFjR40cOVKVlZUujhgAAAAAACC6xEQQSpL+7//+Tzt37vT9rFq1yrdtypQpeuGFF7RkyRKtXLlSO3bs0CWXXOLiaAEAAAAAAKJLzDyOl5iYqLy8vEPqa2pq9MQTT2jRokU6++yzJUnz589Xnz59tHr1ag0bNszpoQIAAAAAAESdmAlCffLJJ+rWrZtSUlJUUFCgGTNm6Mgjj1R5ebkaGhpUWFjoa9u7d28deeSRKisrswxCeb1eeb1eX7m2tta0HYDwYM4BzmPeAc5izgHOY94BzoqJx/GGDh2qBQsWaNmyZZo7d662bNmi0047TXv37lVFRYWSk5OVlZVl2Cc3N1cVFRWWx5wxY4YyMzN9P/n5+TafBRDbmHOA85h3gLOYc4DzmHeAs+JaWlpaWm8WXaqrq9WzZ0/NmjVLqampKi4uNkS/JWnIkCE666yzdP/995sewyxinp+fr5qaGmVkZATs/7HXA6+6Y+aa04NbiQYIt9mvhvavQpPPDjwfDldb5hyA0LTXeRfu1dBaWy2veLjxM9p/dbvMZONXrdZW8/tsr3H5vaPTjavbHTQWD1ktL9tj7M+T0Laveq1dv7aufhcrq9cdjrbMuT8F+H75K5u+Rz78mvV3g0ln2fM7YuFb1ZbbRp+SZUufgfwjwPv/Cpvey26sVBfNq+O1h8+6QO8zK3a9/8w8HsLft5I0jr9xY1LMPI73fVlZWTruuOP06aef6txzz1V9fb2qq6sNd0NVVlaa5pD6jsfjkcfjcWC0ACTmHOAG5h3gLOYc4DzmHeCsmHgcz9++ffv02WefqWvXrho8eLCSkpJUWlrq275p0yZt3bpVBQUFLo4SAAAAAAAgesTEnVA33nijLrjgAvXs2VM7duzQ7bffroSEBF1xxRXKzMzU2LFjVVJSopycHGVkZOi6665TQUEBK+MBAAAAAACESUwEob766itdccUV+uabb3TEEUdo+PDhWr16tY444ghJ0kMPPaT4+HiNHDlSXq9XRUVFevTRR10eNQAAAAAAQPSIiSDUU089FXB7SkqK5syZozlz5jg0IgAAAAAAgNgSE0GoSLN5L5cd7U91Q0ymkAMQAfxXp/Nfja611dla09bV2fz3T0kwrla3YleyoVzQqSHg8er8Vs+r8hrLG/cZv0f07thoKH9Qbdyen2pcTq+11fNq6o39tXZ9/Nv7rwbo//r598fqeeFR5XX+c3rHgYTWG4XZ1y6cZyCNzc732dAceIVNRJ/3q5KC3ucKG8ZhhVXuEIzI+i0OAAAAAACAqEQQCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGC7xNabINySWVUV7VBmkgtrEAOICYvKqg3lKwuyDOXi4YGXfvZv73+81o7f2v5VfkvC53Uw/j5sbf+eqU0KxnHpjYbygUbjF4feHY3btx1IMJQfOj8t4Hgq9hvP50CTsZya0GIoZyYby/NX1QTc7u+g3+kXD88K2L611wuRIyOR7waJLvyT/hUuzIlLh2Y73if+Jy0h8O9ZoD3hTigAAAAAAADYjiAUAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7VgdzwVLd9UHvc+9Smu9EWCjhRWh/bqYEuZxAIg+bV39zH81tWDb19T7L1trLKcmGlclevubJEN56b8OGMqDM43/xrdhn/H354Em43Jxr9YYt/fyW22uS7JxBTL/VZLy/VbfG7HkoKE8qGPg39/v+Y2vym81uxE5DYay/+p52R5je4/f9hTj4n2HrK7X2uqH/lpbPS9WV9dbtifJctutNvX5z53WKz/+1qY+P9sXWX++7DrIv+nb5ek1VZbbYm21vmcqg1tlVZJus2EcQDjwWxMAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB27SII9emnn+rll1/WgQPfJv5saWlpZQ8AAAAAAABEkshaXsLPN998o1GjRunVV19VXFycPvnkE/3gBz/Q2LFjlZ2drQcffNDtIYbkglzr1UuASHVaBsFfAO1Da6ul+Rt/hnF1ttZWz+vst1rdCVmNhvJBv0WMhncyror7XrXxe8DQjsYdjks3Hs/fHq/x3xD9V+87v4vXUN6+37g8nf/qdufkGMeX7TFu91/tzv96+K9u57/6nf/+bV3Nrq3bo9WITg0BtqbY0ufw7GRbjhvID9ICzw+npSc6//3onwFWjftpFK0aF2sr4AVS2Cmi/2wHghLRd0JNmTJFiYmJ2rp1qzp06OCrHzVqlJYtW+biyAAAAAAAABCMiA6pvvLKK3r55ZfVo0cPQ/2xxx6rL7/80qVRAQAAAAAAIFgRfSdUXV2d4Q6o7+zZs0cej8eFEQEAAAAAACAUER2EOu200/TXv/7VV46Li1Nzc7Nmzpyps846y8WRAQAAAAAAIBgR/TjezJkzdc455+idd95RfX29br75Zn300Ufas2eP3nzzTbeHBwAAAAAAgMMU0UGofv36afPmzXrkkUeUnp6uffv26ZJLLtGECRPUtWtXt4cXsn9/+EnQ+9z9o0E2jAQ4fK989lWIex4f1nEAaH9aW/0s2NXRWuO/Olvx8KyA26f9Z5+hfHS6cfU3/9Xovq43lg80GdtvOWBcjW7dl1sM5fiMIwzlIzPSDeU0v9Xk/r3jgHH/ROPqeomJgVfd9SQkBNzeK9nYX7Xf+fivnldeY+xvu9/1y0k27i8Zy3NX1gTc3lbhfj+1dnw7+gjFgo8rLbfdVJhuua0tVnyxPcDWY23p87nd1ivyTbalx8B2HnD+wZIDjeGdM4fj6QAr8sXqKnb9n9gd9D7rxx7ReiMTnfxWZQXas4gOQklSZmamfvvb37o9DAAAAAAAALRBRAehPvjgA9P6uLg4paSk6MgjjyRBOQAAAAAAQDsQ0UGogQMHKi7u29tNW1q+vVX8u7IkJSUladSoUfrTn/6klJQUV8YIAAAAAACA1kX06njPPvusjj32WD322GN6//339f777+uxxx7T8ccfr0WLFumJJ57Qq6++qmnTprk9VAAAAAAAAAQQ0XdC3XPPPXr44YdVVFTkq+vfv7969Oih2267TWvXrlVaWppuuOEGPfDAAy6OFAAAAAAAAIFE9J1Q69evV8+ePQ+p79mzp9avXy/p20f2du7cGdRx77vvPsXFxWny5Mm+uoMHD2rChAnq1KmTOnbsqJEjR6qy0nqVEQAAAAAAABy+iL4Tqnfv3rrvvvv02GOPKTn52+VYGxoadN9996l3796SpO3btys3N/ewj/n222/rT3/6k0444QRD/ZQpU7R06VItWbJEmZmZmjhxoi655BK9+eab4Tuh/++YXn3CfkzAbgPzj3R7CADaCf8l7Ftbvr6ty9v77+/ff2uOTm8ylIuHZxrK97yy11A+uVODoVxTb1wuva7JWB57Qg9DeU+98d8Ac5LrDeVtBxIM5cLcDoZyWkKLofzePmP77n5LefdMNY73gN/4/M//oLGozXuNXxdHdPUayhuqjduzPcbxefzG29rrPX9VTZv2b+v7qTV2Hz9UJ/fo7nif/br3aL1RmJ2T1eh4n4F0SWluvVGYpSa2tN4ItjsmM92xvqae61xfgN0iOgg1Z84c/eQnP1GPHj18QaP169erqalJL774oiTp888/169//evDOt6+ffs0evRoPf7447r77rt99TU1NXriiSe0aNEinX322ZKk+fPnq0+fPlq9erWGDRsW5jMDAAAAAACILREdhDrllFO0ZcsWLVy4UJs3b5YkXXbZZbryyiuVnv5tNPiqq6467ONNmDBBI0aMUGFhoSEIVV5eroaGBhUWFvrqevfurSOPPFJlZWWmQSiv1yuv93//ElhbWxv0+QE4fMw5wHnMO8BZzDnAecw7wFkRnRNKktLT03X66afrvPPO05lnnqmuXbvqtdde0/PPPx/UcZ566im9++67mjFjxiHbKioqlJycrKysLEN9bm6uKioqTI83Y8YMZWZm+n7y8/ODGg+A4DDnAOcx7wBnMecA5zHvAGdFdBDq888/14ABA9SvXz+NGDFCF110kS6++GLfz+Hatm2bJk2apIULFyolJSUsY5s6dapqamp8P9u2bQvLcQGYY84BzmPeAc5izgHOY94Bzorox/EmTZqkXr16qbS0VL169dKaNWu0Z88e3XDDDXrggQcO+zjl5eXatWuXTjzxRF9dU1OTXn/9dT3yyCN6+eWXVV9fr+rqasPdUJWVlcrLyzM9psfjkcfjCfncAASHOQc4j3kHOIs5BziPeQc4K6KDUGVlZXr11VfVuXNnxcfHKyEhQcOHD9eMGTN0/fXX67333jus45xzzjlav369oa64uFi9e/fWLbfcovz8fCUlJam0tFQjR46UJG3atElbt25VQUFB2M/ryw9XBb/TpYWttwFstPmd/4a24yUXhHcgACJesKuHBbuaXmu27DWuFue/ul1OK39rzCo15gP5ut54vKVfJhnK3ibjcnKNjcbV6BrrjKu9HXWEcVXfivUrjcfrYVzBt6WuyjhAT5qhGJeYbCh/4a0zlD88IvAKZv/eccBQTk4xrsY3uKNxNT3/1fBy/Fbj819d74Nqv+vVyup3xcOzDGX/1fJgrvyTjwNsPTHAttB9tm6F9caRP7Klz6d3Nlhuu82WHgP7qCap9UZh5m2Ma71RmDW2ON9npPvq3eXB73Qp34uBiA5CNTU1+RKQd+7cWTt27NDxxx+vnj17atOmTYd9nPT0dPXr189Ql5aWpk6dOvnqx44dq5KSEuXk5CgjI0PXXXedCgoKWBkPAAAAAAAgDCI6CNWvXz+9//776tWrl4YOHaqZM2cqOTlZjz32mH7wgx+Eta+HHnpI8fHxGjlypLxer4qKivToo4+GtQ8AAAAAAIBYFdFBqGnTpqmu7ttbyu+8806df/75Ou2009SpUyctXry4TcdesWKFoZySkqI5c+Zozpw5bTouAAAAAAAADhXRQaiioiLf/x9zzDHauHGj9uzZo+zsbMXF8VwyAAAAAABAexHRQSgzOTk5bg8BAAAAAAAAQWp3Qaho0JA/wO0hAEHrPPBct4cAIEq1dTU8/9X1eqUHPv7clcbV1g74rTRVck6Goey/Wl5+qt/yb37+8pVf/8cY/wHtqW3G1fouH36Kobxhn/HrWVpupqHc06//pXuMq3ONyOloKH95wLh6Xe+OjYbynsxUQzkn2Xj8bQeMqwP6O9BkvH55HYz9ndzJuJpZTb2xvcfv8P6vp/9qeTA3+Ng+jvfp7TnY8T5/2CW59UYOOiqtsfVGYZYUeEraIjGupfVGMaaxz5luDwFol+LdHgAAAAAAAACiH0EoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0SW2+CcMtavSD4ncbeFPZxAMHY98ofQ9vxp7x3AQRnUVl1wO1XFmQFtX3+qhpDeft+4/rmu+qN/yZ3ylMHDWVvk7G9t67WUPakZfiNoNlQWvTpHkM5effnhvLTXxn3bkk0LkHfkN3DUP5w82vG3hKM7Zc21RvHe/JlhnLZ114FUpjbwVDefMB4/hX1TYby4I7G6/flgcDrxxd0agi43Z//+6G11z/Y9uHe3y0b33reeuPFo2zpM+vtf1hv/OUkW/r8zwcbLLfd/+OTbekzkE/2Of/n1N76OMf7bG69ScxJf/UPwe901W/DPxCgneFOKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtWB3PBdXDfu72EICg7Rky2u0hAIhSra2G1xr/1csOPZ5xJamj042ru+V4jes+DcpqMZT3eI3/ZncgJ924f7LxeAf8VtM70NTJUH4hLdNQ7pfuMZTTEoz9+yvzjAi4PT3NOD5vbZWhPKBzlqHcK9U4/tQE4/XI99u+x281Qf/zz/YYx+9p5Xxae/2CXZ2uravntZfV8PzVDzjf8T6rTrrc8T77HNvP8T4DObZjo+N9dkgMPKfs8NOh2Y73+fSaKsttl7owHn/fFBS7PQSgXeJOKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtWB3PBVmr/xL8TmNvDP9AgCB0Kv19aDte81B4BwKg3WttNbzWViebv6rGUK7yGle/81+dzt+BJmP7XX6rvW33K3dPNq4WV77PuDJV79QkQ/mDqn2GcnPtbkM5ab9xxaeP/MbX0MG46pN/++x1/zSU648caijvO+JYQ3nAccbVxNZv/tA43iOOMo53v/H6HpXXw1DeWrvXUD4hu6Oh3NdvtbDUVlbHm1Vaayhne4yvj//7pabeuH38GcbVBqN19bvWJHz8WoCt9qycl/PaLOuN4+63pc/NH6213jjyDFv6DOSNPUmW2ybb1GdDc+ttwi3SV6pzQ6eVfwx+p2tmhH8gQDvDnVAAAAAAAACwHUEoAAAAAAAA2I4gFAAAAAAAAGxHEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0S3R5ALKo+vtDtIQBB++acm9weAoAocWVBVlDt56+qMZQ9CS2Gcl4HY9mftynOUK7yGstHpzcZyjv2G/+NLsdjXA+9S3KCofxqjfF4hbkdDOVd2b0M5bSEowzl8n3G8f9fqrH/jQd6GsoXDetvKM//wmsotzQ1+u1vHH9TRhdDOSXFON7T/cafn1pvPF5ymqHcu2ODoZzXwdjflr3G69XNb3vx8ExDeVFZtaHs//qNP8PY3l+w769osb9rX8f7/GbYLx3v87j/G+J4n4GcltMQYGuqLX16ElpvE26XDs12vtMI982Qn7s9BKBd4k4oAAAAAAAA2C4mglBz587VCSecoIyMDGVkZKigoED/+c9/fNsPHjyoCRMmqFOnTurYsaNGjhypyspKF0cMAAAAAAAQXWIiCNWjRw/dd999Ki8v1zvvvKOzzz5bF154oT766CNJ0pQpU/TCCy9oyZIlWrlypXbs2KFLLrnE5VEDAAAAAABEj5jICXXBBRcYyvfcc4/mzp2r1atXq0ePHnriiSe0aNEinX322ZKk+fPnq0+fPlq9erWGDRvmxpABAAAAAACiSkwEob6vqalJS5YsUV1dnQoKClReXq6GhgYVFv4vWXjv3r115JFHqqyszDII5fV65fX+LxFobW2t7WMHYhlzDnAe8w5wFnMOcB7zDnBWzASh1q9fr4KCAh08eFAdO3bUs88+q759+2rdunVKTk5WVlaWoX1ubq4qKiosjzdjxgz97ne/C2ks2e8sDGGvgSH1BYRLp1V/Cm3Ha0KbJ/7aMucAhMaueee/+llrq5kdNC5ep+Lhxvatrabmv/+2Awl+ZeP2142L8cmTkGQoD+1oPGCvZOPqdq9+Y1wtq7HOeMAOX31gKPvnRlifkWcop1ZtNZT/9mmOoZz9yXJDubbPCEO5eadxdTtl5BqK9TurDeX/HuxmKPuvtudJyzCUe3c0Hn7pTo+hPLyTsX//1QfnrvS74DK+fpnJgVc/9F89sbXV9iJ59by2zLmcdc8E2GrPCred1i4IsPUeW/r8cNsXAbb2saXPQNbXOv/nVG1DXOuNwuwffvPo+66I4Dl1OEKdd53KHg++s0kPBL8PEGViIieUJB1//PFat26d1qxZo/Hjx2vMmDHasGFDyMebOnWqampqfD/btm0L42gB+GPOAc5j3gHOYs4BzmPeAc6KmTuhkpOTdcwxx0iSBg8erLffflsPP/ywRo0apfr6elVXVxvuhqqsrFReXp7F0SSPxyOPx2O5HUB4MecA5zHvAGcx5wDnMe8AZ8XMnVD+mpub5fV6NXjwYCUlJam0tNS3bdOmTdq6dasKCgpcHCEAAAAAAED0iIk7oaZOnaof/ehHOvLII7V3714tWrRIK1as0Msvv6zMzEyNHTtWJSUlysnJUUZGhq677joVFBSwMh4AAAAAAECYxEQQateuXbr66qu1c+dOZWZm6oQTTtDLL7+sc889V5L00EMPKT4+XiNHjpTX61VRUZEeffRRl0cNAAAAAAAQPWIiCPXEE08E3J6SkqI5c+Zozpw5joxnz9kljvQDhNOegT91ewgAYoT/amaZyYHb+6+G50lo8Ssb2x+Xblzt7UCjcf/Rqf49NPlXGNT59X92J+Nqems8xtXoLj3+DEP56d3GE+ziN94vq3oE7D+9rzF9wJ6qKkM5IyPbUI5vMp5P/cH9hnLJ8cbxfLbXeEHu/lGaoTyr1Lic+eBM4+qA/rp1aA643f/1a02w7aPVnv4/cbzPbwp+6Xifp/Xq6XifgZyQ2dh6ozDrmOj8e96NFfAuHZrdeiMXfXPqtW4PAWiXYjYnFAAAAAAAAJxDEAoAAAAAAAC2IwgFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgu0S3BxCLcl7/Y/A7XXNv+AcCBCGn7LEQ93w4rOMA0P5d6bfU96Ky6oDb/fm3Lx5ubD+rtNZQPtAUZyjneJoN5W0HEgzlOr/2/uX3vzb2H1e7y1Bu7mAcT7yng6G8cMO7xu2N9cbxZOQZyi0ZXQzlTmvmG8p7EzyGcmpeP0O5pmsfQzlr86uGcn3PoYbygxuM/XnSMgzlXf/ebyinJRiv3656479x9u1oXMK+Wwfj9a/yGq9vXgfj8vOtvR+CfT+1dXukytnwUoCtx9vSZ6fX/2C9ccJDtvS5+sP3rDdeeKotfQby1f6E1huFWU298/cRPLW62nLb5cOyHBtHJOkUyt901/G9GOBOKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtWB3PBVUDR7k9BCBo35x9g9tDABCj5q+qMZQ9rSxGlZpoXF2t5Bzj6m7+xzsu3bh6W4rf8T+oNn5dOiU301Dukp9u7D/B2P+/dhv/ze+S4acYykv3JBmP59f/IL/V5V5Im2woN+7ZYSjHpWUbyud1M57/qxk/NZSP7JBiKFc1GfvvlWw8n56pxvFs2Ge8PsM7GVf787+eHr/rk21c3E9ev9UI/bW2el2wq+kFuz1SVZ10heN9fnP2jY73mdhrkON9BpKV1Nx6ozBLd6HP+LiW1huF2dNrqiy3XTo023KbU7459Vq3hwC0S9wJBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdq+O5IHvDSyHsNSDs4wCC0WnNgtB2HD89rOMAEH1aW43MfzU1//b+q6Xt8RqXY/NfDc/f9v3G9v6r263ZZ9xes/NzQzmz6w8M5X1frDeUszb/11BemtHVUG5OSDaUt3b9P0P5iwTj6nnZm0sN5ar+PzGUO256zVBerrMM5ZY644pTWxuPMJTjdn9hKPca0MdQfqvGOJ5Lu3qN4/EaV7fb41f+7XnG1QT9X5/i4cbVB1tbDQ/fSv3inQBbz7elz05vPGq98Vf32NKn96uNAbaeaEufgfjPh2jV3BJ41Uo7RMIKeIF0evepEPb6XdjHAbQ33AkFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO4JQAAAAAAAAsB2r47ngm6FXuT0EIGh7+l/s9hAAxCj/1dD8V1PzGBevU7cOzX7bjavd+eveoclQ3uM1/hvdiJwGQzmna3dDefNe4/5pfqvJ/Se/r6Fcf3C/oVyY28F4vAPGE6oyHl7VacYVowZ2zjKUuxx5oaH8342fGsqerscYyt66WkP5yKP7G8o5yfWG8nGpfgNqRa90Y/u5K42vX2ay8fVpbTU8VsszV3/sqY73+c3JVzveZ/qRfVtv5KARR9QH2JpiS591jc6vVHf5sCzH+4x03wy+0u0hAO0Sd0IBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjiAUAAAAAAAAbEcQCgAAAAAAALZLdHsATpgxY4b+9a9/aePGjUpNTdUpp5yi+++/X8cff7yvzcGDB3XDDTfoqaeektfrVVFRkR599FHl5uaGfTyd3ng0+J1+dW/YxwEEI2f9syHu2b/1JgCiyqKyakP5yoKsNh1v7soaQzklwbjd//jzVxnb19QblzN/rzrJUO7dsdFQ/rre+G90aQkthvLmvcavT69s/frQQX9PYlqmoZz85buG8lub9xnKcY1eQ7nJk24o51R8aBxPXj9DeWNisrE/v/E0eY39tXTINpS/8qQayuUJHkO5r9/1+myv8QU5Or3JUN5QnRjU9pzkZkPZ//X0+L3+4X6/tVeejSsCbL3Ylj47rQrwnXbSw7b0WbvjkwBbnf/O8daeJMttv3ZwHHb725vVltuuOjXLsXFEkk5rF4Sw14xwDwNod2LiTqiVK1dqwoQJWr16tZYvX66Ghgadd955qqur87WZMmWKXnjhBS1ZskQrV67Ujh07dMkll7g4agAAAAAAgOgRE3dCLVu2zFBesGCBunTpovLycp1++umqqanRE088oUWLFunss8+WJM2fP199+vTR6tWrNWzYMDeGDQAAAAAAEDViIgjlr6bm29u6c3JyJEnl5eVqaGhQYWGhr03v3r115JFHqqyszDQI5fV65fX+73b52tpam0cNxLb2OOd+fu112vl1zSH1XTtnasG8P7a5PWC39jjvgPaMOQc4j3kHOCvmglDNzc2aPHmyTj31VPXr920OhYqKCiUnJysrK8vQNjc3VxUVFabHmTFjhn73u9/ZPVwA/58dc87uINHOr2uUfd74Q+tfmWs6nmDbhzImIBh81gHOYs4BzmPeAc6KuSDUhAkT9OGHH2rVqlVtOs7UqVNVUlLiK9fW1io/P7+twwNgwY4550SQyG7BjomgFYLBZx3gLOYc4DzmHeCsmApCTZw4US+++KJef/119ejRw1efl5en+vp6VVdXG+6GqqysVF5enumxPB6PPB6P6bbWNKd3DWk/wE0N2b1c7b8tc84q8LJh82adel5bR9a+RGIgDZEr1HkX7Opkra1u5r8aXvFw42pz/qq8cQG3D8pqCLg9P9W4etsev9Xy/Lf7r36XmGhcLevgri8N5R79zzCUt28uN5QT/FavO5ht/GOo/vjTDOX01X8zlPf1ODHg8fzL3Y8brEA2HjCe74d7jeV+6cb3SPcOxu27/K5f9ybj9r5ZxtX2/Fcz9PitTugvmlbDa8tnXXzjwTCPpnWN3QY63qfiElpv46Dj05pabxRm6UmB54QdPInO9/n0mirLbZcOzbbcFqxQ511zJoEqIBQxEYRqaWnRddddp2effVYrVqxQr17GP6YHDx6spKQklZaWauTIkZKkTZs2aevWrSooKHBjyADCyCrwUv/hdS6MBgAAAABiU0wEoSZMmKBFixbp3//+t9LT0315njIzM5WamqrMzEyNHTtWJSUlysnJUUZGhq677joVFBSwMh4AAAAAAEAYxEQQau7cbx8zOfPMMw318+fP189//nNJ0kMPPaT4+HiNHDlSXq9XRUVFevTRRx0eKQBEFnJIAQAAAAiXmAhCtbS0/gxzSkqK5syZozlz5jgwIgBoH8ghBQAAACBc4ltvAgAAAAAAALRNTNwJFWlWzSUZMtqfsoeucnsIEWvDRx+q6NKrD62PwdX3eHwPoWhtdbPWVsPzV3JORhtGE7ySVlv0bWX7qW0bwJhI+16R6vYAYtLqB65wvM+3Hi52vM8Pp7Q2n5x1W1FHx/scfUqW433+NIyr0R2ucK6AZ4dVj/7a7SEA7RJBKADwE2xQqb4lPqjV94I9vlX7QPu4hcf3AAAAAFghCAUAfoINKtl9fKv2gfbh7iwAAAAAkYYgFABEIbvvzgoXHt8DAAAAYgdBKACA7Xd/WeHxPQAAACB2EIQCAASNx/0AAAAABIsgFAAgaG7dOQUAAACg/SIIBQCwXbhWBNzy6Sb1Oub4Q+rJIQUAAABEPoJQAADbhWtFwHUfXmdaX/rQhKCCVhKBKwAAAMBpBKHCpKWlRZJUW1vr8kiA9ik9PV1xcXGH3T6YOdfY1KSmxibTY7Tn+kgck1v13uY4ZZx9zSH11esnmdZL0vI/TNQ5F48+pP7Lzzar59HHHVKfl5OuuQ/NND1We2XnvANwKOYc4Kxg55zEvAPaqrV5F9fy3SxDm3z11VfKz893exhAu1VTU6OMjIzDbs+cA9qOeQc4izkHOCvYOScx74C2am3eEYQKk+bmZu3YsaPVqF9tba3y8/O1bdu2oH8hInRcd3cEc92D/Zeqw51z4RwjDsX1axu3r59b8669cPv1cVMsn7tk3/nbNedi9fWK1fOWOHe7vl9KhzfvYvn6B4trFZxouF6tzTsexwuT+Ph49ejR47DbZ2RktNs3VXvGdXeHHdc92DnXGt4bbcP1a5v2cv3CPe/ai/by+tghls9dcv/8+X55eGL1vCXO3Y5zD2bexfL1DxbXKjjRfL3i3R4AAAAAAAAAoh9BKAAAAAAAANiOIJTDPB6Pbr/9dnk8HreHElO47u5oD9e9PYwxknH92obrF9li+fWJ5XOX2t/5t7fxhkusnrfEubt97pEwhvaCaxWcWLheJCYHAAAAAACA7bgTCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7QhCAQAAAAAAwHYEocKkpaVFtbW1Is874AzmHOA85h3gLOYc4DzmHWAvglBhsnfvXmVmZmrv3r1uDwWICcw5wHnMO8BZzDnAecw7wF4EoQAAAAAAAGA7glAAAAAAAACwnatBqKamJt12223q1auXUlNTdfTRR+uuu+4yPH/b0tKi6dOnq2vXrkpNTVVhYaE++eQTw3H27Nmj0aNHKyMjQ1lZWRo7dqz27dtnaPPBBx/otNNOU0pKivLz8zVz5sxDxrNkyRL17t1bKSkp6t+/v1566SV7ThwAAAAAACDGuBqEuv/++zV37lw98sgj+vjjj3X//fdr5syZ+uMf/+hrM3PmTP3hD3/QvHnztGbNGqWlpamoqEgHDx70tRk9erQ++ugjLV++XC+++KJef/11XXPNNb7ttbW1Ou+889SzZ0+Vl5fr97//ve644w499thjvjZvvfWWrrjiCo0dO1bvvfeeLrroIl100UX68MMPnbkYAAAAAAAAUSyuxcW0/+eff75yc3P1xBNP+OpGjhyp1NRU/f3vf1dLS4u6deumG264QTfeeKMkqaamRrm5uVqwYIEuv/xyffzxx+rbt6/efvttnXTSSZKkZcuW6cc//rG++uordevWTXPnztVvf/tbVVRUKDk5WZJ066236rnnntPGjRslSaNGjVJdXZ1efPFF31iGDRumgQMHat68ea2eS21trTIzM1VTU6OMjIywXSMA5phzgPOYd4CzmHOA85h3gL1cvRPqlFNOUWlpqTZv3ixJev/997Vq1Sr96Ec/kiRt2bJFFRUVKiws9O2TmZmpoUOHqqysTJJUVlamrKwsXwBKkgoLCxUfH681a9b42px++um+AJQkFRUVadOmTaqqqvK1+X4/37X5rh9/Xq9XtbW1hh8A9mHOAc5j3gHOYs4BzmPeAc5yNQh166236vLLL1fv3r2VlJSkQYMGafLkyRo9erQkqaKiQpKUm5tr2C83N9e3raKiQl26dDFsT0xMVE5OjqGN2TG+34dVm++2+5sxY4YyMzN9P/n5+UGfP4DDx5wDnMe8A5zFnAOcx7wDnOVqEOqf//ynFi5cqEWLFundd9/VX/7yFz3wwAP6y1/+4uawDsvUqVNVU1Pj+9m2bZvbQwKiGnMOcB7zDnAWcw5wHvMOcFaim53fdNNNvruhJKl///768ssvNWPGDI0ZM0Z5eXmSpMrKSnXt2tW3X2VlpQYOHChJysvL065duwzHbWxs1J49e3z75+XlqbKy0tDmu3Jrbb7b7s/j8cjj8YRy2kC79PSaqpD2u3Rodlj6Z861D4vKqk3rryzIcnQcCA/mHeAs5lzrlgT4PnJZmL5zILaEOu+eWRv8d+ORQ3iPAq7eCbV//37FxxuHkJCQoObmZklSr169lJeXp9LSUt/22tparVmzRgUFBZKkgoICVVdXq7y83Nfm1VdfVXNzs4YOHepr8/rrr6uhocHXZvny5Tr++OOVnZ3ta/P9fr5r810/AAAAAAAACJ2rQagLLrhA99xzj5YuXaovvvhCzz77rGbNmqWLL75YkhQXF6fJkyfr7rvv1vPPP6/169fr6quvVrdu3XTRRRdJkvr06aMf/vCHGjdunNauXas333xTEydO1OWXX65u3bpJkq688kolJydr7Nix+uijj7R48WI9/PDDKikp8Y1l0qRJWrZsmR588EFt3LhRd9xxh9555x1NnDjR8esCAAAAAAAQbVx9HO+Pf/yjbrvtNv3617/Wrl271K1bN/3qV7/S9OnTfW1uvvlm1dXV6ZprrlF1dbWGDx+uZcuWKSUlxddm4cKFmjhxos455xzFx8dr5MiR+sMf/uDbnpmZqVdeeUUTJkzQ4MGD1blzZ02fPl3XXHONr80pp5yiRYsWadq0afrNb36jY489Vs8995z69evnzMUAAAAAAACIYnEtLS0tbg8iGtTW1iozM1M1NTXKyMhwezhA1GPOAc5j3gHOYs4BzmPeAfZy9XE8AAAAAAAAxAaCUAAAAAAAALAdQSgAAAAAAADYjiAUAAAAAAAAbOfq6nix6uk1VUHvc+nQbBtGAhy+UN63Umy/dxeVVZvWX1mQ5eg4vi8SxwQAaLvFq60/p0cNi93PYsAu/E0HhIY7oQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2C6upaWlxe1BRIPa2lplZmaqpqZGGRkZbg8HiHrMOcB5zDvAWcw5wHnMO8Be3AkFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2iW4PIBY9vaYq6H0uHZptw0iAwxfK+1aK7ffuorJq0/orC7Kium8AgPOWBPicviyKPotj5TwR+fibDggNd0IBAAAAAADAdgShAAAAAAAAYDuCUAAAAAAAALAdOaFcwLPAaI+aWtweQftjlX/JKl9TsMcJ9z7RKNC15hoBiCbNfE4DcMkza0PLHTtyCH8XxyLuhAIAAAAAAIDtCEIBAAAAAADAdgShAAAAAAAAYDtyQrlg8ergn5kdNYznZeGuuDi3R9D+WOUjCmcuomD7sHtMkTYe8j4BgH3+ESDv3hU2/f69jNyqiBBOpmF7ek3wfz86mYeY3E4IBndCAQAAAAAAwHYEoQAAAAAAAGA7glAAAAAAAACwHTmhXEB+J7RHTc3RlxTKrXxEVv16m8yvcfHwzKD7CFf7YEXaeAAgVsS78DEdH+dkVpxvLQmQG4d8UXCSk+9+J/M7AXbjTigAAAAAAADYjiAUAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbkZjcBf+wSEocyBUk7wVCZpUIPNj2wSYat2ofzmTcc1fWmNaPP8M6mXkksTs5PADAPs0tzmdDb3Y+F3rEcSM5OwnhD+Xkoj3PrLW+/lZGDonN1wWRjzuhAAAAAAAAYDuCUAAAAAAAALAdQSgAAAAAAADYjpxQLqhvdnsEQPCaojAHg7fJ/Fn+4uHm+ZTClb8o2BxVVuOUpMzk4F6YYM9h/irznFOeBPN+g70W4bp25JACEOsaHcxP850Djc73Ge98lwEtXm2dq2fUsOjJyROreZ8CaeBvOiAk3AkFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB25IRyQZMLz+wDbVVT335j1jX15nPOKpeF3XmTrFiNM1DeJ6t8UcHmnbJqXzw8y7Te6pyDFew4yf0EAObcyM/0jdf57wbNUZijMljkZ4oMBwLk7Ay3Ft73iCLt969KAAAAAAAAtBsEoQAAAAAAAGA7glAAAAAAAACwHTmhXNDIM71oh+pcyDURLlY5lbbvTzCtz+vQbFofbB6kiv3mcf5sT3C/BALlQZpVWmtaX3JOpmm93bmi5q40v0ZWr0G4cjwFm8cLAKJNvflHl61Sg8x9GA7fHDT/7I4lS9ZUWW4jX5RzDjqYEyouwr+GP7PW+j0ZyMghvF9jket3Qm3fvl0/+9nP1KlTJ6Wmpqp///565513fNtbWlo0ffp0de3aVampqSosLNQnn3xiOMaePXs0evRoZWRkKCsrS2PHjtW+ffsMbT744AOddtppSklJUX5+vmbOnHnIWJYsWaLevXsrJSVF/fv310svvWTPSQMAAAAAAMQYV4NQVVVVOvXUU5WUlKT//Oc/2rBhgx588EFlZ/8vIjpz5kz94Q9/0Lx587RmzRqlpaWpqKhIBw8e9LUZPXq0PvroIy1fvlwvvviiXn/9dV1zzTW+7bW1tTrvvPPUs2dPlZeX6/e//73uuOMOPfbYY742b731lq644gqNHTtW7733ni666CJddNFF+vDDD525GAAAAAAAAFHM1cfx7r//fuXn52v+/Pm+ul69evn+v6WlRbNnz9a0adN04YUXSpL++te/Kjc3V88995wuv/xyffzxx1q2bJnefvttnXTSSZKkP/7xj/rxj3+sBx54QN26ddPChQtVX1+vJ598UsnJyfq///s/rVu3TrNmzfIFqx5++GH98Ic/1E033SRJuuuuu7R8+XI98sgjmjdvnlOXBAAAAAAAICq5GoR6/vnnVVRUpMsuu0wrV65U9+7d9etf/1rjxo2TJG3ZskUVFRUqLCz07ZOZmamhQ4eqrKxMl19+ucrKypSVleULQElSYWGh4uPjtWbNGl188cUqKyvT6aefruTkZF+boqIi3X///aqqqlJ2drbKyspUUlJiGF9RUZGee+4507F7vV55vV5fubbWPC+LmX0NEf5QL2DC7XdtW+ZcTb356I9Obwqq/fgzgsuzlO1pfWzft8drfnNq4FxU5mO1GpPXIn/BQfNLoZQwpd6wys1kdW7Fw4O71lbHD5QDi3xRrWvLvAMQvLbMucZm5z+pq+qdf6gixYU8VIE0t7j9DQltFeq8a3HwrdjgwvwG7OLq43iff/655s6dq2OPPVYvv/yyxo8fr+uvv15/+ctfJEkVFRWSpNzcXMN+ubm5vm0VFRXq0qWLYXtiYqJycnIMbcyO8f0+rNp8t93fjBkzlJmZ6fvJz88P+vwBHD7mHOA85h3gLOYc4DzmHeAsV4NQzc3NOvHEE3Xvvfdq0KBBuuaaazRu3Lh28fjb1KlTVVNT4/vZtm2b20MCohpzDnAe8w5wFnMOcB7zDnCWq4/jde3aVX379jXU9enTR88884wkKS8vT5JUWVmprl27+tpUVlZq4MCBvja7du0yHKOxsVF79uzx7Z+Xl6fKykpDm+/KrbX5brs/j8cjjyfIZ20AhIw5BziPeQc4izkHOI95BzjL1SDUqaeeqk2bNhnqNm/erJ49e0r6Nkl5Xl6eSktLfUGn2tparVmzRuPHj5ckFRQUqLq6WuXl5Ro8eLAk6dVXX1Vzc7OGDh3qa/Pb3/5WDQ0NSkpKkiQtX75cxx9/vG8lvoKCApWWlmry5Mm+sSxfvlwFBQVhP++t+1297EBINu4LU3IgF7xXnWRa3yW52bS+b1ajaf09r+w1re/Wwfw5/R37zW82zfGY92tVb3UcSUoNMjdG2Tfm1+LMLvWm9W9btLfKtXSg0Xys1rmZzK/d3JXmuaJSEsiJAABmyqrMf19L0kSb+vzGhZxQ1RZ5G93itcipaKfmyEqLFbO+qHPub7pG86+IQLvk6uN4U6ZM0erVq3Xvvffq008/1aJFi/TYY49pwoQJkqS4uDhNnjxZd999t55//nmtX79eV199tbp166aLLrpI0rd3Tv3whz/UuHHjtHbtWr355puaOHGiLr/8cnXr1k2SdOWVVyo5OVljx47VRx99pMWLF+vhhx82JCKfNGmSli1bpgcffFAbN27UHXfcoXfeeUcTJ9r1sQ0AAAAAABA7XL0l5+STT9azzz6rqVOn6s4771SvXr00e/ZsjR492tfm5ptvVl1dna655hpVV1dr+PDhWrZsmVJSUnxtFi5cqIkTJ+qcc85RfHy8Ro4cqT/84Q++7ZmZmXrllVc0YcIEDR48WJ07d9b06dN1zTXX+NqccsopWrRokaZNm6bf/OY3OvbYY/Xcc8+pX79+zlwMAAAAAACAKOb6c2Hnn3++zj//fMvtcXFxuvPOO3XnnXdatsnJydGiRYsC9nPCCSfojTfeCNjmsssu02WXXRZ4wAAAAAAAAAiaq4/jAQAAAAAAIDa4fidULNrrQgJDoK0yEttvFsxBWQ2m9SkWudYrLBKBWyUBP2gxpzfsM/8VOzjBfDzlNeZJZUd09Zp3IGnLXvOT8DaFJ3HrcenmSdqDPb5Ve4/FNfUEmQffKvH5lQVZYd3HzuMAQFvkJDn/Ob3fhWTJDS2RlZg8PrKGAwc5+Scd67K0zTNrq0Lab+SQ7DCPBBJ3QgEAAAAAAMABBKEAAAAAAABgO4JQAAAAAAAAsB05oVzwgUW+GSCSfeVtv+/bVd8km9b3SjV/mv/o9OCe8v/vLvPjd0kOLlnG4EzzXFFWOaok67xTqRZ5p6xY5ZayyoO1PcjfYyXndDStn7+qxrTeKldUTb15UoTM5OBzoYQrbxa5nwBEAjc+p9+udT7RaX2YfneHS7MLKTObXciLtWSNdU6dy4bGZt6cj/mbzseNeRAMcjtFFmYOAAAAAAAAbEcQCgAAAAAAALYjCAUAAAAAAADbkRPKBftrvw5hrx5hHwcQjE/q6kPcMzWs4wjFh3u9pvV9O5rnQfqg2vxX4+YD5u1Pscjl9KVF+5JzMkzrBy+sM6/vaJ374YOqfab1vVLNr3v5PvOH9rskm/dxwCL3Rt+sRtP6pTs9pvVzV5rnfjrQaH78bPPDaPwZmeYbQmCVd8rKorJq03pyQgGIBJ/tNf8M+VaKLX3GxTn/79lrayPrz5ft+80/6+0UH+d8Ap5YzfsUSOW+vSHsFdpcbAwuzajj4iMrVdshnllrndMsEHJJ2YM7oQAAAAAAAGA7glAAAAAAAACwHUEoAAAAAAAA2C6yHqqOEYkpaW4PAQhaQ83uEPcMXw6fUCUmJpnWb9hnHocfbJHjKc0ih9CGfea/SjceMH+Af9p/zPM4eevMcwv0zrP+nbG9Pt20PifZPIdXXnKyaX1dU5NFvflD/nXfmF9Tq2uXmWx+7fZ4zV+DvATzaxdsXiarXFTfjsm8fv4q832Kh5v3ESxySwGwQ3Ojea4+O3mrdgbYeowtfeZ7Iis5TrIL/6Q/apjzeWqWrLHOqROr+aJampybcwkRfutIQ3NkJ4VqD7mdQslb1R7Oy0yEv50BAAAAAAAQDQhCAQAAAAAAwHYEoQAAAAAAAGA7ckK5oOmbr0LYq30+74nokbg31JxQ9uSECEZecoJp/Yd7D5rWVzelmNZv+2y9aX3Ho/qb1nvrak3rj+7ZwbQ+LsH8V/K2A+bjl6QvKsx/nxzIzDWtPy7VPPdTvkX9wgrzvn/ZwzwPwou7PKb1l3q8pvVL95jnlrrUIv9WaqJ5vVWepZQE6xwF4crBZJ1DyjwfGrmfANihpcH8M81OHXZuCLDVns//1bXmnwNuSbP4XLLT39+qttz2s1OyHBuH3SI+D9W+r0PYqWtIXdXWR3bOpYS4yJqX/p4O8F4K5FIH32ftNb9TKNp8J9TBg85/4AEAAAAAAKB9CSkI1dzcrLvuukvdu3dXx44d9fnnn0uSbrvtNj3xxBNhHSAAAAAAAADav5CCUHfffbcWLFigmTNnKvl7y33369dPf/7zn8M2OAAAAAAAAESHkHJC/fWvf9Vjjz2mc845R9dee62vfsCAAdq4cWPYBhetOuz+NIS9zHPOAE6Jb6x3ewhh17hnh2n9l17zZ7LjjjjKtD7bImXT3tpdpvWzNnUz36HKfDyvp1jn1YjvYJ536ECTee6A/1buN62/sFuqaX39QfP2KQnJpvVZFrmcqrzm47G6dlbjz+vQbL6DBau8TJJ1HqlgczYF6gMAnJJQWxlga09b+mxOMv/ssJN37zcBtqY5No7vbN7rfIrdxuA+CsPCjRxMEZH3KYCUqu0h7BXa33TxkZ0SShE+PEdzO6F1Id0JtX37dh1zzKF/FDU3N6uhoaHNgwIAAAAAAEB0CSkI1bdvX73xxhuH1D/99NMaNGhQmwcFAAAAAACA6BLS/aPTp0/XmDFjtH37djU3N+tf//qXNm3apL/+9a968cUXwz1GAAAAAAAAtHMh3Ql14YUX6oUXXtB///tfpaWlafr06fr444/1wgsv6Nxzzw33GAEAAAAAANDOhZxJ77TTTtPy5cvDOZaYkVBf5/YQgKB1qNwQ4p5nhHUcoahYv9K0PsnT0bQ+oYt5AteDu740rf8qMcm0PuPLNebH6TravD7B/DgHa742rZekBIvk51uy+1nuYyYn2TzLaXpaumn9Z3sbzfutN09N2dci0figjubHSbVIcO61OI7Hov38VTWm9ZJUPDwrqH1IQA4gkqVWbQ2wdYgtfbrxnTbpm0DneaRj43BTYki3EbTN4tVVlttGDbMn6fOSNdZ9RkLSck/NV24PIWK4kCsf7Vibl3PYt2+fmpuNb7uMjIy2HhYAAAAAAABRJKQ4+pYtWzRixAilpaUpMzNT2dnZys7OVlZWlrKz3Y9KAwAAAAAAILKEdCfUz372M7W0tOjJJ59Ubm6u4uLMH48AAAAAAAAApBCDUO+//77Ky8t1/PHHh3s8MaHFIu8LEMmaLfIntWcJ3n2m9fU7PzWtj8voYlp/difzOf3KcWeb1mcmJJjWN9dWmtbHH2Ody6N3nvmY3v+62rTek2b+uPTGfcH9Y4JVziYrByxyOVnJ62CeXaBiv/kNvHkdzMdT5bXud1FZtcUW/mEFQPvTlOz853Ry7U7H+2zp8X+O9xlIbZCfb+HQHNxHMGzixpyLVE3NfHfC4QvpcbyTTz5Z27ZtC/dYAAAAAAAAEKVCuhPqz3/+s6699lpt375d/fr1U1KS8S6AE044ISyDAwAAAAAAQHQIKQi1e/duffbZZyouLvbVxcXFqaWlRXFxcWpqagrbAAEAAAAAAND+hRSE+sUvfqFBgwbpH//4B4nJQ5D8tXm+GSCSJe3Z4vYQQtZkkc/KKidUYe9jTOvLXvu3af1ynWVa32Hnx6b1tZ400/rExGTTem9drWm9JK3f9pVpfcZR/c13WP2UaXXPH480rX9z6w7T+i9Tu5nWey3+EaJ7B/P6F3d5TOvv/pH5azblxTrT+myPeYKMbQfM829J1nmniodnWu4TDla5qK4syLK1XwDRzVOz3fE+43dtdLzP5q+3Btjq/CrdKfHOJ2g66EIeKjdcNjSyV11P/uYzx/qK9DRg5Clru2fWVgW9z8ghkT1HrIQUhPryyy/1/PPP65hjzP9QAwAAAAAAAL4vpMTkZ599tt5///1wjwUAAAAAAABRKqQ7oS644AJNmTJF69evV//+/Q9JTP6Tn/wkLIMDAAAAAABAdAgpCHXttddKku68885DtpGY/DDs2+X2CIDgWeRPag86fvWuab03+yjT+l315jeJ7j36VPMO6syf4U6t+NC0vsugc82P//pS0/qqvCnm/UrqsPsT82MdcZRpfVqCed6ppXuSTOvjLPJXbbe4RlJwv//Pyak3rZ/yovlx8lPN66u85vkxTu7UENR4Apm/qsa0PtgcUuR+AmCHhK/NPw9sldbZ8S4T91c73mcgWw6G9GBJmzQ2O58TKj420lAFx8G/6SL98ic4Pw2C8vSa4PMtSdKlDuYla6/5nUIRUhCqudk8mSsAAAAAAABgJsJjlgAAAAAAAIgGIQehVq5cqQsuuEDHHHOMjjnmGP3kJz/RG2+8Ec6xAQAAAAAAIEqE9Dje3//+dxUXF+uSSy7R9ddfL0l68803dc4552jBggW68sorgz7mfffdp6lTp2rSpEmaPXu2JOngwYO64YYb9NRTT8nr9aqoqEiPPvqocnNzfftt3bpV48eP12uvvaaOHTtqzJgxmjFjhhIT/3dqK1asUElJiT766CPl5+dr2rRp+vnPf27of86cOfr973+viooKDRgwQH/84x81ZMiQ4C/O4YjnBjS0Q83hy63jtL3DrjKtz1w517T+/a9PMq3PXv98UMdXk9e0+ssq8+fSk441zxVVfJTH/PiSnlu2xrS+rq/5seKbzHMwjcgxf30X7TFvP6hjo2n9C7vM6/d4E0zrDzSZZzmwyv20cZ/5x9agLPPxV+y3/n2b7WkxrbfK/eRJMG+/qKzatJ7cTwAcFefC90vvXse7jG886HifgQzNNP/cs9PeRuczBLmRhyriJVp/Pwu3eovvS5GikWw9CEJIn1b33HOPZs6cqcWLF+v666/X9ddfr8WLF+u+++7TXXfdFfTx3n77bf3pT3/SCSecYKifMmWKXnjhBS1ZskQrV67Ujh07dMkll/i2NzU1acSIEaqvr9dbb72lv/zlL1qwYIGmT5/ua7NlyxaNGDFCZ511ltatW6fJkyfrl7/8pV5++WVfm8WLF6ukpES333673n33XQ0YMEBFRUXatYsE4gAAAAAAAOEQUhDq888/1wUXXHBI/U9+8hNt2bIlqGPt27dPo0eP1uOPP67s7P9lhK+pqdETTzyhWbNm6eyzz9bgwYM1f/58vfXWW1q9erUk6ZVXXtGGDRv097//XQMHDtSPfvQj3XXXXZozZ47q67/91/t58+apV69eevDBB9WnTx9NnDhRl156qR566CFfX7NmzdK4ceNUXFysvn37at68eerQoYOefPLJUC4PAAAAAAAA/IQUhMrPz1dpaekh9f/973+Vn58f1LEmTJigESNGqLCw0FBfXl6uhoYGQ33v3r115JFHqqysTJJUVlam/v37Gx7PKyoqUm1trT766CNfG/9jFxUV+Y5RX1+v8vJyQ5v4+HgVFhb62pjxer2qra01/ACwD3MOcB7zDnAWcw5wHvMOcFZIOaFuuOEGXX/99Vq3bp1OOeUUSd/mhFqwYIEefvjhwz7OU089pXfffVdvv/32IdsqKiqUnJysrKwsQ31ubq4qKip8bb4fgPpu+3fbArWpra3VgQMHVFVVpaamJtM2GzdutBz7jBkz9Lvf/e7wTtRPQ7dBIe0HuKkl6yhX+2/LnGvcs8O0/kBeP9P6jIxs0/qq484xrb+4i/mv0meHFpvWWz3Vn7x/j2n9wgrzfEqS1DTwp6b1BZ3TTOvfPO4s0/ovD1j04a0zra5r6mxa39xonpspx2N+1pv3ml+7HPPRqLdFLqoUy0tknsdJss7x5LXIu2B3jqdgc0s5kYuqLfMOQPDaMucOHmlTLtMAGrv0drzPg9nB/YO33T6ps/6Mtkt2Mgl4winUedfU+VgbRmMu2eI7S6RIiOyUVbp0qPl3+0jyzFrznLGBjBwS2nk52ZeZkO6EGj9+vJ566imtX79ekydP1uTJk/Xhhx9q8eLF+tWvfnVYx9i2bZsmTZqkhQsXKiUlJZRhuGrq1Kmqqanx/Wzbts3tIQFRjTkHOI95BziLOQc4j3kHOCukO6Ek6eKLL9bFF18ccsfl5eXatWuXTjzxRF9dU1OTXn/9dT3yyCN6+eWXVV9fr+rqasPdUJWVlcrLy5Mk5eXlae3atYbjVlZW+rZ999/v6r7fJiMjQ6mpqUpISFBCQoJpm++OYcbj8cjjcW5FBCDWMecA5zHvAGcx5wDnMe8AZ4V0J9Tbb7+tNWsOXRZ8zZo1eueddw7rGOecc47Wr1+vdevW+X5OOukkjR492vf/SUlJhtxTmzZt0tatW1VQUCBJKigo0Pr16w2r2C1fvlwZGRnq27evr41//qrly5f7jpGcnKzBgwcb2jQ3N6u0tNTXBgAAAAAAAG0T0p1QEyZM0M0336yhQ4ca6rdv367777/fNEDlLz09Xf36GfOxpKWlqVOnTr76sWPHqqSkRDk5OcrIyNB1112ngoICDRs2TJJ03nnnqW/fvrrqqqs0c+ZMVVRUaNq0aZowYYIvmn3ttdfqkUce0c0336xf/OIXevXVV/XPf/5TS5cu9fVbUlKiMWPG6KSTTtKQIUM0e/Zs1dXVqbjYPJ9LWyXurbDluICd6jO7uT2EkKVUmd9WneDda1qfbZHeYW+Teb6j9/aZ/ypNqN1lWp9/dH/T+m3ZR5rW90+1/veCdR2Cez47qeor0/q6vC6m9XFpwR3/wm6pFluaTGt31Zuf23Hp5rmfrHJI7ak3z5XQvYN5v1LwuZPszsEU7HHszlEFoH1piQ/5AYeQxTd6Y6LPQLp6nM/PlOhC/p34OOdzEi1ZY5235rIIyPHTEu9cPrCmyE4JFfFCyYEkhTcPUqz2ZSakT6sNGzYYHqP7zqBBg7Rhw4Y2D+o7Dz30kOLj4zVy5Eh5vV4VFRXp0Ucf9W1PSEjQiy++qPHjx6ugoEBpaWkaM2aM7rzzTl+bXr16aenSpZoyZYoefvhh9ejRQ3/+859VVFTkazNq1Cjt3r1b06dPV0VFhQYOHKhly5YdkqwcAAAAAAAAoQkpCOXxeFRZWakf/OAHhvqdO3cqMTH0f4VZsWKFoZySkqI5c+Zozpw5lvv07NlTL730UsDjnnnmmXrvvfcCtpk4caImTpx42GMFAAAAAADA4QspJ9R5553nW0XgO9XV1frNb36jc889N2yDAwAAAAAAQHQI6balBx54QKeffrp69uypQYMGSZLWrVun3Nxc/e1vfwvrAAEAAAAAAND+hRSE6t69uz744AMtXLhQ77//vlJTU1VcXKwrrrhCSUlJ4R5j1IlrPOj2EICgJR6odnsIIWvydDStT/TuM60/LtU8mfU3Oz8yra/qcbxpvafWfBGCqibzxORW7Tce6GtaL0lJ+80TLdY19TKtj2usN63v29E8EfjGdR+Y1ucfbb56aOmeZIvxmGdR3VJvXl9okevzhCzzcVopHp4ZVHvJOgE5AESy5kTnl5iP37XR8T7VQobmeudzoSvehWTokZB8PJCEdvzdONwS45mXOHwhJ3BKS0vTNddcE86xAAAAAAAAIEqFHIT65JNP9Nprr2nXrl1qbjaG46dPn97mgQEAAAAAACB6hBSEevzxxzV+/Hh17txZeXl5iov73/2ZcXFxBKEAAAAAAABgEFIQ6u6779Y999yjW265JdzjiQktnuBzlABua05KcXsIIet+3GDT+or1K03r/1u537Q+vck8n9KInAbT+n8lmudHuvQI8+P8w7RWGtzROhHDWov6D/d6TeutlkR9apt5rroj+59hWr+n3jw309bavab13ZPTTOvPzgwux1OwAuV3qrHIRzX+jCzT+vmrakzrASASxFl8RtkqPc/xLpuTOzjeZyCNzc4nS+qQGBv5dxavNs97KUmjhrmfL6rZ4ruNHRJcyMkVjEh/R5JKLrJY/T0SUFVVlS677LJwjwUAAAAAAABRKqQg1GWXXaZXXnkl3GMBAAAAAABAlArpcbxjjjlGt912m1avXq3+/fsrKSnJsP36668Py+AAAAAAAAAQHUIKQj322GPq2LGjVq5cqZUrjTlV4uLiCEK1wpvT0+0hAEFL3Lfb7SGE7IuvPjetTzx6qGl9cmKSaX1i7U7T+n/tNr+ptL7niab1T+82zxW1v8cJpvV1TdaJABo6mOdEuLiL+a/3Z+t+YFp/Zb55zq9Fn1aa1p+TY95vc635+2TQMebnvOob8/rUBPOH9788kGBaf2YX81woFfutb/jN9pj3MXelee6nzOTwJBSwylN1ZUFWWI4PIDbVp+c63mdLfMgLbUeNJhf6PBjge4FdDjQ632ck5H0KpNHiO5gdDrjwmgejIcLHFxfZw5MkPbPWOgealZFDInuOWAnpk2PLli3hHgcAAAAAAACi2GEHoUpKSnTXXXcpLS1NJSUllu3i4uL04IMPhmVwAAAAAAAAiA6HHYR677331NDQ4Pt/K3Ht4V43AAAAAAAAOOqwg1Cvvfaa6f8jePUdOrk9BCBo1cee5fYQQpbSxTwP28Gar03rL+hlPkefP67QtH7UEc2m9Ys+3W9aPzS3g2n9q95M0/ouyebHl6T4jCNM661yKiWmmffxz53mWS2s2m+zyM00sGcv03rJPGfT4MwG0/q8Dubn3M2ivqbe/B9ASs7JsBiPde6n8WeYn3O4kPsJgB2aOmQ53mdDZnfH+xzcM7Jyq3riw5MvMBjpSc73efWpWY73GekOZuU71ldWgO+CkSDRhXkQjPaQO6k9jDFcrDO2AgAAAAAAAGFCEAoAAAAAAAC2IwgFAAAAAAAA2x12TiiET0N6Z7eHAAStOdk8j1F70NhonnfISl2TeX6hjkf1N60/0NRoWh+/v9ri+OZ5nPqle0zr1+yzXvDhhOyOpvWpCebnnJiYZFo/Os88J9TCCvPcT8elm59z2n7z9inm1Vr1jfl4Fp6Talq/qKzatL54eJZp/fxV5nmfJOvcT1Z9hCuXk93HBxCjEpMd77Iut7fjfW7xRtYiSEd4nM/V40b+nSVrqiy3XTY0dnLZfF9jB+fOO7Le9YeKj/QBtgPPrLWeY1baax4p7oQCAAAAAACA7QhCAQAAAAAAwHYEoQAAAAAAAGA7ckK5IK5DlttDAIIXb5HUpx0Y08M83r7tgHl+Nqt8R6988qVp/a7Uo0zrWzK6mNb37mh+/G0HzK9xr1Tr3A//2WP+EH6vVPNz9tbVWhwpzbTWk2A+psxk85xTm/eaj2fHfvPxdEk2z6VhlTfJa5Gvyyr3kyfB+tqFKzeT1XEAwFEufE43J6U43me3JOfzIQWSnuj8eBqbnU/AE6t5nwKJ62CeW9IObrzm0eTpADnNArmU970tuBMKAAAAAAAAtiMIBQAAAAAAANsRhAIAAAAAAIDtCEIBAAAAAADAdiQmd0F8UrLbQwCClpRxhNtDCNmeevN4e5pF0uo9XvP2mV1/YHGcJtP6AZ2zLEZkntR7zT7zpLJXdfVaHEcaXJ9kWp+aYJ7w25OWYXEk83MY2tG8fste87F2tkg0nuMJrr7CIpF5tie4BLBWicwlqXh4eBKKWiUyD1ficwA4HB0zOjneZ47F56KdEiMsP/Mui+8MdmpyITf7PwIswnFFjH6uJaZ0cKyvpPjISsjvL7JHJ8VF2O8NMyOHxE4SdO6EAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO3JCuWBglnPPDwPh0jXV4/YQQpZjkado2wHzvEapFrmiRuSY53Lq1sH8+GXfmOdrsuJtMs+/ZJWjSpK2W+S7GpRlPlZPgvmYSs5JM62fVVpr0d48t9T8VTUW/Zpf05p684f08yyuabD5lKzG4wRyPwFw0jFB5swLh/1N5r+r7XSyxefbt1IdG8d38lLMP7vtZPWZaqdYzfsUSM8Ozn03TnbhNQ9GpN/ZEkv5ltqDSH+/AAAAAAAAIAoQhAIAAAAAAIDtCEIBAAAAAADAduSEckFDZD/SC5jqZpFXqT1ITTSfdPmp5nkcrNpv32+eQ+qgRTqItCCf3z8907zeKueUJHU/YL7tQKN5rqV+qebtrXI/WV0Lq1xLn+01v0Z3/6ijaf3clebHscqntKisOqj2xcMtLmoAVudmdaxg2wOAHYL9zAmH08zTA9rK22z++eaW/Raft3ZqdOEaLFlTZbntsqH25Ntxo89gZDs451oUWe/79ubpAO+lQC6NgPdZNOJOKAAAAAAAANiOIBQAAAAAAABsRxAKAAAAAAAAtiMnlAvy2nFuHcSurp7oe99u3Gf+K/DMLvWm9SkJFsmfLByX3hj0mMxUea3zAHSx+H2S7THPU9Cl3ry9Ve6nYB2dbn6NrHI5ZSYHd3yr3E9WrPoNdCxPkDkeyP0EIBJYfR7AXl0D5G20S2K88/m/3MjBFAl5nwLp7OCcS4wjqXBbkNspsnAnFAAAAAAAAGxHEAoAAAAAAAC2czUINWPGDJ188slKT09Xly5ddNFFF2nTpk2GNgcPHtSECRPUqVMndezYUSNHjlRlZaWhzdatWzVixAh16NBBXbp00U033aTGRuNjMCtWrNCJJ54oj8ejY445RgsWLDhkPHPmzNFRRx2llJQUDR06VGvXrg37OQMAAAAAAMQiV3NCrVy5UhMmTNDJJ5+sxsZG/eY3v9F5552nDRs2KC0tTZI0ZcoULV26VEuWLFFmZqYmTpyoSy65RG+++aYkqampSSNGjFBeXp7eeust7dy5U1dffbWSkpJ07733SpK2bNmiESNG6Nprr9XChQtVWlqqX/7yl+ratauKiookSYsXL1ZJSYnmzZunoUOHavbs2SoqKtKmTZvUpUuXsJ53fmpweWWASJDTjnNNHGg0z6k0KKshLMe3ygl0zyt7Tet7WeRNssohlZJg3feBpuByBFjlbAr2HH57XnpQ/QbKzRRM+2BzQgXbPtR9AMBt3VKd/5zunRGez9Fg8BiH1Ex6oIjQNcW5ORfpLzk5lxAMV4NQy5YtM5QXLFigLl26qLy8XKeffrpqamr0xBNPaNGiRTr77LMlSfPnz1efPn20evVqDRs2TK+88oo2bNig//73v8rNzdXAgQN111136ZZbbtEdd9yh5ORkzZs3T7169dKDDz4oSerTp49WrVqlhx56yBeEmjVrlsaNG6fi4mJJ0rx587R06VI9+eSTuvXWWx28KgAAAAAAANEnov4xoaamRpKUk5MjSSovL1dDQ4MKCwt9bXr37q0jjzxSZWVlkqSysjL1799fubm5vjZFRUWqra3VRx995Gvz/WN81+a7Y9TX16u8vNzQJj4+XoWFhb42/rxer2praw0/AOzDnAOcx7wDnMWcA5zHvAOcFTFBqObmZk2ePFmnnnqq+vXrJ0mqqKhQcnKysrKyDG1zc3NVUVHha/P9ANR327/bFqhNbW2tDhw4oK+//lpNTU2mbb47hr8ZM2YoMzPT95Ofnx/aiQM4LMw5wHnMO8BZzDnAecw7wFmuPo73fRMmTNCHH36oVatWuT2UwzJ16lSVlJT4yrW1tYf9C2t/U8TE/oB2oy1zzopVriVvk3kOqR37zefu3JU1pvWpCebHCXY8noTgMwFY7WOV78g6Z5P5oKzaW1274uHB9msu2Pbkd2obO+YdAGttmXMHXUg5uvtggKSFNklLjPTsOPYbNYz8O+EU6rwLMi1nm0T6u/6ZtVUh7TdyCO/lWBQRQaiJEyfqxRdf1Ouvv64ePXr46vPy8lRfX6/q6mrD3VCVlZXKy8vztfFfxe671fO+38Z/Rb3KykplZGQoNTVVCQkJSkhIMG3z3TH8eTweeTye0E4YQNCYc4DzmHeAs5hzgPOYd4CzXL0lp6WlRRMnTtSzzz6rV199Vb169TJsHzx4sJKSklRaWuqr27Rpk7Zu3aqCggJJUkFBgdavX69du3b52ixfvlwZGRnq27evr833j/Fdm++OkZycrMGDBxvaNDc3q7S01NcGAAAAAAAAoXP1TqgJEyZo0aJF+ve//6309HRf/qXMzEylpqYqMzNTY8eOVUlJiXJycpSRkaHrrrtOBQUFGjZsmCTpvPPOU9++fXXVVVdp5syZqqio0LRp0zRhwgRfRPvaa6/VI488optvvlm/+MUv9Oqrr+qf//ynli5d6htLSUmJxowZo5NOOklDhgzR7NmzVVdX51stDwAAAAAAAKFzNQg1d+5cSdKZZ55pqJ8/f75+/vOfS5IeeughxcfHa+TIkfJ6vSoqKtKjjz7qa5uQkKAXX3xR48ePV0FBgdLS0jRmzBjdeeedvja9evXS0qVLNWXKFD388MPq0aOH/vznP6uoqMjXZtSoUdq9e7emT5+uiooKDRw4UMuWLTskWTkAAAAAAACC52oQqqWl9RRrKSkpmjNnjubMmWPZpmfPnnrppZcCHufMM8/Ue++9F7DNxIkTNXHixFbH1Fa5KS5kjgTaqFNKs9tDCFnJORlBtbdKft0r3XzuBpv8ev4q80TmoSQgTw1bAnJzvz0vPaj2VscPV0Jxq+NYtbe61lLwydsBIJJ1T3P++2XPjo2O95kSwmdltFm82joJNEnLnZOX6tycC26pG+c1My0RBJZpAwAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgO1dzQsWqtCQemkX7kxyFIWvrfEHmT94XD880rQ8231Hx8Kyg2gc6frYnuN8nduc7irTjW71mABBtmluczxoTSi7DtkqOsJxQV7iQR5C8T5Eh0cHvxpcNjezXPNLHh8gShX9WAgAAAAAAINIQhAIAAAAAAIDtCEIBAAAAAADAduSEckFDs9sjAIK3r8H5XBPhYpX76WCTefvxZwSX+8nbFJ4cUjX15sdJSbC+9uHKU2V3LqdwsXotozn3k9Vr2V5eMwDOcOP7ZU298/+eHeAj0RWLV1dZboum3E1L1lifZ6zmA6q3+B5ph6cDXH8rl8bo69JePbM2+Nd45JD2+RpzJxQAAAAAAABsRxAKAAAAAAAAtiMIBQAAAAAAANuRE8oFaYktbg8BCFqmp/0mMwtXviC7c/BY5aLC/0Rz7icr5H4CcDiuPjXL8T4zk53/bpAYH1nfo6Mp71MgsZr3KZC0JOfei+R3in7tNb9TKLgTCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7cgJ5YL65ji3hwAErSWyUjAEZVFZtWl9uHLtWB3fSjhz/Njdd7DXLlzX2u7XDACizeLVVZbb7MpbFO/CV9rGCPsevWSN9XW3K4+SG33iUE6+F59Za/2aW4mlHENoX7gTCgAAAAAAALYjCAUAAAAAAADbEYQCAAAAAACA7cgJ5YKEuHacXAcxy658Ek6wO49QuPIdhev4oe4TjuO41S8AxLr2/DkdjMT4yPoeTQ6m2OXke5H8Togm3AkFAAAAAAAA2xGEAgAAAAAAgO0IQgEAAAAAAMB2BKEAAAAAAABgOxKTuyAhzu0RAHBTOJNuR1oCb6uk65E2TgCINkvWVFlusyt5thtJuUkEzjWIFPH8TQeEhCAUAABAO9HQ0KAPP/zQUJakpKQkX12/fv0MZQAAgEhBEAoAAKCd+PDDD/XrOc8rI6+nJGnnh6v/X3t3Hh1Flf5//NPZmi0Li0CAsMm+yiKrCCqKqIwoIiIqosOMGgTENTMK4hbcGJevg+IgjL9RQARxdBREZRFlk02QNYASNBgVSAhIgOT+/hjpSXc6pDtJV6XS79c5fQ5169atp6rr6eo8VFUrsloN1W7cQpJ05Me9Gn/pDrVq1cqzDEUpAABQXlCEAgAAsInvlU1S8UWjuLqNVL1hS0lS9sHvFRVX22v6mf9sUe1vcz3Tf0+WOnXqFKItAAAACBxFKBtcx33ccKB3zvKsibO5vhwf7zy/qOTYd0Bgirt9bseOHXrps12eK5t8r2Ty19+Ys6+zWu0kT1GquHgkrpSqKOx4TtDc1UV/NxjWo/ye/4GyUNxnMQD/KEIBAACESHG3z2VsXa34ph2LvJKpqP6Bys87rR07dnimfYteXCkFAACsRBEKAAAghIq7fc5XwSuZAul/Njk//6Bn/pPrVdQqWPTyLVJJXBkFAABChyIUAABAGfG93S2Q2+dCzbeoVZBvkYorowAAQChRhAIQkPL8bKeS4vlFJce+A/zzd/tdMLfP2aFgkYoroxAMnvuEcMZzfoGSoQgFAAAQoEAeNB5bp1GJb5+zG1dGAQCAUKIIBQAAEKBAHzTuZGe7Msq36CZxpRQAAAgcRSgAAIAi+HvGk++VTqV5cHh55+/B5gWLblwpBQAAgkERCgAA4Hf+ik4vfbbLUc94Kmtn+7U+niEFAACCQREKAACErUCLThX1SqfS8r1S6siPezX+0h1q1aqVJG7fAwAA3ihCAQCAsEHRqez5Xin1zH+2cPseAADwiyIUAACoMAL59TqKTqEVzO17vu8PV04BAFCxUYQCAAC28S0aSd5Fh+KKSoEUmfz9eh1FJ3sU96Bz3+nibu+jiAUAgLNQhCojxhhJUnZ2ts2RAM4UGxsrl8sVcH9yDii9UOXd5s2bAx5z165den7+SlWpUVeSdPzQQd075AK1aNHC7/xD+75VROVYJdRtWOR0bKM2qpqXL0nKN0au/HzlFZjOPvi93G63JOnozz8q8vhvTFs5XbW61/vh+/4UnD726096ZMYeJdT9JuD3v+C07/EUKh07Bvawes51gLWCzTmJvANKq7i8c5kzWYZSOXDggJKSkuwOA3CsrKwsxcXFBdyfnANKj7wDrEXOAdYKNuck8g4oreLyjiJUGcnPz9ePP/5YbNUvOztbSUlJSk9PD/oDESXHfrdHMPs92P+pCjTnyjJGFMb+Kx27959deecUdr8/dgrnbZdCt/2hyrlwfb/Cdbsltj1U3y+lwPIunPd/sNhXwakI+6u4vON2vDISERGhBg0aBNw/Li7OsQeVk7Hf7RGK/R5szhWHY6N02H+l45T9V9Z55xROeX9CIZy3XbJ/+/l+GZhw3W6JbQ/FtgeTd+G8/4PFvgpORd5fEXYHAAAAAAAAgIqPIhQAAAAAAABCjiKUxdxutyZNmuT5lRhYg/1uDyfsdyfEWJ6x/0qH/Ve+hfP7E87bLjlv+50Wb1kJ1+2W2Ha7t708xOAU7KvghMP+4sHkAAAAAAAACDmuhAIAAAAAAEDIUYQCAAAAAABAyFGEAgAAAAAAQMhRhCojxhhlZ2eLR2wB1iDnAOuRd4C1yDnAeuQdEFoUocrI0aNHFR8fr6NHj9odChAWyDnAeuQdYC1yDrAeeQeEFkUoAAAAAAAAhBxFKAAAAAAAAIQcRSgAAAAAAACEHEUoAAAAAAAAhBxFKAAAAAAAAIQcRagCfvjhB910002qWbOmKleurPbt2+vrr7+2OywAAAAAAADHi7I7gPLi8OHD6t27ty666CJ9/PHHOuecc7R7925Vr17d7tAAAAAAAAAcjyLU755++mklJSVp5syZnrYmTZrYGBEAAAAAAEDFQRHqd//+9781YMAADR06VMuXL1f9+vV11113afTo0X775+bmKjc31zOdnZ1tVahAWCLnAOuRd4C1yDnAeuQdYC2KUL/bu3evpk2bpgkTJugvf/mL1q1bp7FjxyomJkYjR44s1D81NVWTJ08u0brmrz0c9DJDunFbIOz17prgj1tJuq572Ry7pcm5omIvq9jKavyS7uNglNU2l5VQvzcondLknZPM8zkOh4b4+Ju72nt9w3p4r6+s4/Edz5fv+FbvD/xPuOQcUJ6UNO9K8r2tpN9v+PsRFQkPJv9dfn6+OnfurKeeekqdOnXSn/70J40ePVqvvvqq3/4pKSnKysryvNLT0y2OGAgv5BxgPfIOsBY5B1iPvAOsxZVQv0tMTFSbNm282lq3bq358+f77e92u+V2u60IDYDIOcAO5B1gLXIOsB55B1iLK6F+17t3b+3cudOrbdeuXWrUqJFNEQEAAAAAAFQcFKF+d88992j16tV66qmnlJaWprffflvTp09XcnKy3aEBAAAAAAA4HkWo351//vl67733NHv2bLVr106PP/64XnjhBY0YMcLu0AAAAAAAAByPZ0IVcNVVV+mqq66yOwwAAAAAAIAKx2WMMXYHURFkZ2crPj5eWVlZiouLszscoMIj5wDrkXeAtcg5wHrkHRBa3I4HAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCPW7Rx99VC6Xy+vVqlUru8MCAAAAAACoEKLsDqA8adu2rT799FPPdFQUuwcAAAAAAKAsUGUpICoqSnXr1g35euauPhz0MsN6VA9BJEDgSnLcSuXj2H1njf/Yc0+7/Lbf3DvBb/uc1Uf8tke4jN/2fON//Bt6+B9/9ir/4w/v6b+/JL1bxLZd193/fi9qXxR1WezpIrYhqohtLkpR8QSrqO0tibKKCaE3z+d9H1rG711x4/vmpm9OFrf8m196L1856uz5k298p/3n4RlREd4L+C5fHN/Pad/t8eW7faF+f3xZvT4A8MfKv+nmrw1+XUO6WffZWJL4JGtjRPlBEaqA3bt3q169eqpUqZJ69uyp1NRUNWzY0G/f3Nxc5ebmeqazs7OtChMIS+QcYD3yDrAWOQdYj7wDrMUzoX7XvXt3zZo1S4sWLdK0adO0b98+9enTR0ePHvXbPzU1VfHx8Z5XUlKSxRED4YWcA6xH3gHWIucA65F3gLUoQv1u4MCBGjp0qDp06KABAwboo48+0pEjR/TOO+/47Z+SkqKsrCzPKz093eKIgfBCzgHWI+8Aa5FzgPXIO8Ba3I5XhISEBLVo0UJpaWl+57vdbrndboujAsIXOQdYj7wDrEXOAdYj7wBrcSVUEXJycrRnzx4lJibaHQoAAAAAAIDjUYT63X333afly5fru+++01dffaVrrrlGkZGRGj58uN2hAQAAAAAAOJ7LGBPkD/lWTDfccINWrFihX3/9Veecc44uuOACPfnkkzr33HMDWj47O1vx8fHKyspSXFxciKMFQM4B1iPvAGuRc4D1yDsgtHgm1O/mzJljdwgAAAAAAAAVFrfjAQAAAAAAIOQoQgEAAAAAACDkKEIBAAAAAAAg5CpUESovL0+bNm3S4cOH7Q4FAAAAAAAABTi6CDV+/HjNmDFD0n8LUH379lXnzp2VlJSkZcuW2RscAAAAAAAAPBxdhHr33XfVsWNHSdIHH3ygffv2aceOHbrnnnv017/+1eboAAAAAAAAcIaji1C//PKL6tatK0n66KOPNHToULVo0UK33XabtmzZYnN0AAAAAAAAOMPRRag6depo27ZtysvL06JFi3TppZdKko4fP67IyEibowMAAAAAAMAZUXYHUBqjRo3S9ddfr8TERLlcLvXv31+StGbNGrVq1crm6AAAAAAAAHCGo4tQjz76qNq3b6/9+/dr6NChcrvdkqTIyEg99NBDNkcHAAAAAACAMxxbhDp16pQuv/xyvfrqqxoyZIjXvJEjR9oUFQAAAAAAAPxx7DOhoqOj9c0339gdBgAAAAAAAALg2CKUJN10002aMWOG3WEAAAAAAACgGI69HU+STp8+rTfeeEOffvqpunTpoqpVq3rNnzp1qk2RAQAAAAAAoCBHF6G2bt2qzp07S5J27drlNc/lctkREgAAAAAAAPxwdBFq6dKldocAAAAAAACAADj6mVBnpKWlafHixfrtt98kScYYmyMCAAAAAABAQY4uQv3666+65JJL1KJFC11xxRXKyMiQJN1+++269957bY4OAAAAAAAAZzi6CHXPPfcoOjpa+/fvV5UqVTztw4YN06JFi2yMDAAAAAAAAAU5+plQn3zyiRYvXqwGDRp4tTdv3lzff/+9TVEBAAAAAADAl6OvhDp27JjXFVBnHDp0SG6324aIAAAAAAAA4I+jr4Tq06eP3nzzTT3++OOSJJfLpfz8fD3zzDO66KKLbI6uaK+tyAp6mT9fGB+CSIDAzfgi+ONWkm7vY/+x+9ZXR/y2Hz3lCmqcqlHB/ejB0VP+6/zxMfl+23NO+48nLrro9ebm+W+PLuK/GI4XsY7YGP/rOFXE+O4i9sVvRYxfuYj+13ev7n8FRZi96ojf9uiIsvtBiuuCjAnBm7fm8FnnDw3yPZi72nu8YT2qn3V+hM9hejrfuyHK53jKzfOeH+mzvG9/3/F8P2sqRXr3983LGJ/8Pe1zeB8+6d0h1ie/fOPxXV/h7feejvJZ/029ErymffdnvvEeMMJ19nz0Xb8v3/e/rI8XACgLVv5N924xn4P+WPl9Zv7a4OOTpCHd+PwOR46+EuqZZ57R9OnTNXDgQJ08eVIPPPCA2rVrpxUrVujpp58u8bhTpkyRy+XS+PHjyy5YAAAAAACAMOboIlS7du20a9cuXXDBBbr66qt17NgxXXvttdq4caPOPffcEo25bt06vfbaa+rQoUMZRwsAAAAAABC+HH07niTFx8frr3/9a5mMlZOToxEjRuj111/XE088USZjAgAAAAAAoAIUoQ4fPqwZM2Zo+/btkqQ2bdpo1KhRqlGjRtBjJScn68orr1T//v2LLULl5uYqNzfXM52dnR30+gAEjpwDrEfeAdYi5wDrkXeAtRx9O96KFSvUuHFjvfTSSzp8+LAOHz6sl156SU2aNNGKFSuCGmvOnDnasGGDUlNTA+qfmpqq+Ph4zyspKakkmwAgQOQcYD3yDrAWOQdYj7wDrOXoIlRycrKGDRumffv2acGCBVqwYIH27t2rG264QcnJyQGPk56ernHjxumtt95SpUqVAlomJSVFWVlZnld6enpJNwNAAMg5wHrkHWAtcg6wHnkHWMtljCm737W2WOXKlbVp0ya1bNnSq33nzp0677zz9NtvvwU0zsKFC3XNNdcoMjLS05aXlyeXy6WIiAjl5uZ6zfMnOztb8fHxysrKUlxcXPAbAyAo5BxgPfIOsBY5B1iPvANCy9HPhOrcubO2b99eqAi1fft2dezYMeBxLrnkEm3ZssWrbdSoUWrVqpUefPDBYgtQAAAAAAAAODvHFaG++eYbz7/Hjh2rcePGKS0tTT169JAkrV69Wq+88oqmTJkS8JixsbFq166dV1vVqlVVs2bNQu0AAAAAAAAInuOKUOedd55cLpcK3kX4wAMPFOp34403atiwYVaGBgAAAAAAgCI4rgi1b98+S9azbNkyS9YDAAAAAAAQDhxXhGrUqJHdIQAAAAAAACBIjitC+frxxx+1cuVKZWZmKj8/32ve2LFjbYoKAAAAAAAABTm6CDVr1iz9+c9/VkxMjGrWrCmXy+WZ53K5KEIBAAAAAACUE44uQj3yyCOaOHGiUlJSFBERYXc4AAAAAAAAKIKjKzfHjx/XDTfcQAEKAAAAAACgnHN09eb222/XvHnz7A4DAAAAAAAAxXD07Xipqam66qqrtGjRIrVv317R0dFe86dOnWpTZAAAAAAAACjI8UWoxYsXq2XLlpJU6MHkAAAAAAAAKB8cXYR6/vnn9cYbb+jWW2+1OxQAAAAAAACchaOfCeV2u9W7d2+7wwAAAAAAAEAxHF2EGjdunF5++WW7wwAAAAAAAEAxHH073tq1a/X555/rww8/VNu2bQs9mHzBggU2RQYAAAAAAICCHF2ESkhI0LXXXmt3GAAAAAAAACiGo4tQM2fOtDsEAAAAAAAABMDRz4SSpNOnT+vTTz/Va6+9pqNHj0qSfvzxR+Xk5NgcGQAAAAAAAM5w9JVQ33//vS6//HLt379fubm5uvTSSxUbG6unn35aubm5evXVV+0OEQAAAAAAAHL4lVDjxo1T165ddfjwYVWuXNnTfs011+izzz6zMTIAAAAAAAAU5Ogrob744gt99dVXiomJ8Wpv3LixfvjhB5uiAgAAAAAAgC9HF6Hy8/OVl5dXqP3AgQOKjY21IaLAjFjwW9DLvHVt5eI7ASE0euHxEi33+uAqZRxJ8B5f7P8ZcTuPRfpt71XjlN/2//wc47e9V7z//kdO+b/YtEGVwp9bkvRNlv+P5PZxp/22S9IXh6L9tvcpYht25/hfR/Nq/tfx3TH//dsWsc2ZJ/xvc2LlfL/tR0+7/LbXruS//2n/zYoq4rpel//hJUkRLuO3/fru1YteCCExb81hr+mhPu/B3NXe84f18J4/e9WRUq0/47j3AVQlyvvYOHjC+7Oittv7QPQ9jn/O9R4vN997vu8nT1SE/2PRE5/PeM2ren+GrPH57Gjikz8nfNYfF3n29bWI9f48OOazfSd98rC+z2dahE/e5fuszu2zA4rKxaL4vv8AYAcr/6YryXlueM+EEq2rJOavPVx8Jz+GdOPzPBw5+na8yy67TC+88IJn2uVyKScnR5MmTdIVV1xhX2AAAAAAAADw4ugroZ5//nkNGDBAbdq00YkTJ3TjjTdq9+7dqlWrlmbPnm13eAAAAAAAAPido6+EatCggTZv3qy//OUvuueee9SpUydNmTJFGzduVO3atYMaa9q0aerQoYPi4uIUFxennj176uOPPw5R5AAAAAAAAOHF0VdCSVJUVJRuuummUo/ToEEDTZkyRc2bN5cxRv/85z919dVXa+PGjWrbtm0ZRAoAAAAAABC+HF+E+vHHH7Vy5UplZmYqP9/7SZljx44NeJxBgwZ5TT/55JOaNm2aVq9eTREKAAAAAACglBxdhJo1a5b+/Oc/KyYmRjVr1pSrwM8guVyuoIpQBeXl5WnevHk6duyYevbsWVbhAgAAAAAAhC1HF6EeeeQRTZw4USkpKYqIKP3jrbZs2aKePXvqxIkTqlatmt577z21adPGb9/c3Fzl5uZ6prOzs0u9fgBFI+cA65F3gLXIOcB65B1gLZcxxtgdREnVrFlTa9eu1bnnnlsm4508eVL79+9XVlaW3n33Xf3jH//Q8uXL/RaiHn30UU2ePLlQe1ZWluLi4sokHgD/Q84B1iPvAGuRc4D1yDvAWo4uQj3wwAOqUaOGHnrooZCM379/f5177rl67bXXCs3zVzFPSkriwwoIEXIOsB55B1iLnAOsR94B1nL07Xipqam66qqrtGjRIrVv317R0dFe86dOnVqq8fPz870+kApyu91yu92lGh9A4Mg5wHrkHWAtcg6wHnkHWMvxRajFixerZcuWklToweTBSElJ0cCBA9WwYUMdPXpUb7/9tpYtW6bFixeXacwAAAAAAADhyNFFqOeff15vvPGGbr311lKPlZmZqVtuuUUZGRmKj49Xhw4dtHjxYl166aWlDxQAAAAAACDMOboI5Xa71bt37zIZa8aMGWUyDgAAAAAAAAqLsDuA0hg3bpxefvllu8MAAAAAAABAMRx9JdTatWv1+eef68MPP1Tbtm0LPZh8wYIFNkUGAAAAAACAghxdhEpISNC1115rdxgAAAAAAAAohqOLUDNnzgyo35dffqmuXbvy05sAAAAAAAA2cfQzoQI1cOBA/fDDD3aHAQAAAAAAELbCoghljLE7BAAAAAAAgLAWFkUoAAAAAAAA2IsiFAAAAAAAAEKOIhQAAAAAAABCLiyKUC6Xy+4QAAAAAAAAwlpYFKF4MDkAAAAAAIC9HF2EmjRpkr7//vti+x09elRNmza1ICIAAAAAAAD44+gi1Pvvv69zzz1Xl1xyid5++23l5ubaHRIAAAAAAAD8cHQRatOmTVq3bp3atm2rcePGqW7durrzzju1bt06u0MDAAAAAABAAY4uQklSp06d9NJLL+nHH3/UjBkzdODAAfXu3VsdOnTQiy++qKysLLtDBAAAAAAACHuOL0KdYYzRqVOndPLkSRljVL16df3f//2fkpKSNHfuXLvDAwAAAAAACGuOL0KtX79eY8aMUWJiou655x516tRJ27dv1/Lly7V79249+eSTGjt2rN1hAgAAAAAAhDVHF6Hat2+vHj16aN++fZoxY4bS09M1ZcoUNWvWzNNn+PDh+vnnn22MEgAAAAAAAFF2B1Aa119/vW677TbVr1+/yD61atVSfn6+hVEBAAAAFd+gIcOU8fMhv/MSz6mhD+bzSAwAgDdHF6EeeeQRu0MAAAAAwlLGz4fU7KbH/M5L+9dEi6MBADiB44pQEyZMCLjv1KlTQxgJAAAAAAAAAuW4ItTGjRsD6udyuUIcCQAAAAAAAALluCLU0qVLQzJuamqqFixYoB07dqhy5crq1auXnn76abVs2TIk6wMAAAAAAAgnjv51vLK0fPlyJScna/Xq1VqyZIlOnTqlyy67TMeOHbM7NAAAAAAAAMdz3JVQ1157rWbNmqW4uDhde+21Z+27YMGCgMddtGiR1/SsWbNUu3ZtrV+/XhdeeGGJYi1Kx9TVQS+zOaVHmcYABKtj6poSLbc5pXsZRxK8dn/b5n+GyfPbHFevud/2o/v9j+Nu0Mpv++l9/m8f7tGuk9/2L/Z977e9XVJjv+2StOvbtX7bW7Tt5rd9++6tftsHdmjjt31R5km/7dclRvtt/+yI/9PK4HP8j7P3mP/+51Y77be9KLXc/n8F9fjpom/Njo0xfttP+T8sVDmqiP75/tcxvGeC3/Z31hz223599+r+V1wBzfPZB6d99mFUhDnr/Dyft+Jknvf8Ez7Tx3yOg+J+M9fts/51R7yP99M+6//xlPf4TdzeHdZ/7z+3z4g4edy7weeRAvlRbq/pSofTfeZX8o6vSoL3+LUaeg9/4Fuv6VM1vee7Y2t6TfeI844nPdf7/zC7xXnna0yk9/ZHu7ynE3xyz/f9qlnJOwkjfFIs32f/+84f6pNLvsebL9/+xfE3XrBjAHC+8574IuhlNj3cp0TrmrXySNDL3HpBQonWVRJFfbcpjlXffeavLVl8Q7pZ99lekhitjK8sOa4IFR8f73neU3x8fMjWk5WVJUmqUaOG3/m5ubnKzc31TGdnZ4csFgDkHGAH8g6wFjkHWI+8A6zluCLUzJkz/f67LOXn52v8+PHq3bu32rVr57dPamqqJk+eHJL1AyiMnAOsR94B1iLnAOuRd4C1eCaUH8nJydq6davmzJlTZJ+UlBRlZWV5Xunp6UX2BVB65BxgPfIOsBY5B1iPvAOs5bgroQr69ddfNXHiRC1dulSZmZnKz/d+ysOhQ4eCHnPMmDH68MMPtWLFCjVo0KDIfm63W263u8j5AMoWOQdYj7wDrEXOAdYj7wBrOboIdfPNNystLU2333676tSp43lWVEkYY3T33Xfrvffe07Jly9SkSZMyjBQAAAAAACC8OboI9cUXX2jlypXq2LFjqcdKTk7W22+/rffff1+xsbE6ePCgpP8+/Lxy5cqlHh8AAAAAACCcuYwx/n9z2gHOP/98vfzyy+rRo0epxyrqKqqZM2fq1ltvLXb57OxsxcfHKysrS3FxcaWOB8DZkXOA9cg7wFrB5NygIcOU8bP/R1EknlNDH8yfW+bxdb3wUjW76TG/89L+NVFfr1hS5usEQo1zHRBajr4S6u9//7seeughTZw4Ue3atVN0dLTX/GA+NBxciwMAAECYy/j50FkLQgAAlAeOLkIlJCQoOztbF198sVe7MUYul0t5eXk2RQYAAAAAAICCHF2EGjFihKKjo/X222+X+sHkAAAAAAAACB1HF6G2bt2qjRs3qmXLlnaHAgAAAAAAgLOIsDuA0ujatavS09PtDgMAAAAAAADFcPSVUHfffbfGjRun+++/X+3bty/0YPIOHTrYFBkAAAAAAAAKcnQRatiwYZKk2267zdPmcrl4MDkAAAAAAEA54+gi1L59++wOAQAAAAAAAAFwdBGqUaNGdocAAAAAAACAADi6CHXGtm3btH//fp08edKr/Q9/+INNEQEAAAAAAKAgRxeh9u7dq2uuuUZbtmzxPAtK+u9zoSTxTCgAAAAAAIByIsLuAEpj3LhxatKkiTIzM1WlShV9++23WrFihbp27aply5bZHR4AAAAAAAB+5+groVatWqXPP/9ctWrVUkREhCIiInTBBRcoNTVVY8eO1caNG+0OEQAAAAAAAHL4lVB5eXmKjY2VJNWqVUs//vijpP8+sHznzp12hgYAAAAAAIACHH0lVLt27bR582Y1adJE3bt31zPPPKOYmBhNnz5dTZs2tTs8AAAAAAAA/M5xV0J98803ys/PlyQ9/PDDnoeRP/bYY9q3b5/69Omjjz76SC+99JKdYQIAAAAAAKAAx10J1alTJ2VkZKh27dq68847tW7dOklSs2bNtGPHDh06dEjVq1f3/EIeAAAAAAAA7Oe4K6ESEhK0b98+SdJ3333nuSrqjBo1alCAAgAAAAAAKGccdyXUkCFD1LdvXyUmJsrlcqlr166KjIz023fv3r0WRwcAAAAAAAB/HFeEmj59uq699lqlpaVp7NixGj16tOcX8gAAAABUXIOGDFPGz4f8zks8p4Y+mD/X4ogAAMFwXBFKki6//HJJ0vr16zVu3DiKUAAAAEAYyPj5kJrd9JjfeWn/mmhxNACAYDmyCHXGzJkz7Q4BAAAAAAAAAXB0EcqpLrzxwaCXWfH20yGIBAjchUPHlWi5FfNeLONIgtdrnP+CddSPm/y2/3rBXX7ba65703//PkX0//w5//0vHOu//6p/+O/f7Va/7ZJUc7X/ZQ5dNMFve/Wv5/htP3L+cL/t7u/X+20/97x+ftu3/nDAb3u/xvX9tq88fNJv+/WJ/p/1l33a/+9p1Kuc57c9L99vsyQpNtr4ba8U6b89oojfvHAX0b8o13Wv7rf93TWHQ9rfSnNXe8c2rId3TPOKiP2MfJ9dmnXS+32Pj/F+Y3PzvN+c73O8v96cU8n7+NiRHX3W9X+R7T1dJdJ7/YcyvJ85GXHqhNd01Z92eE1HZ/3gNe3KP+29gqMHvSbza7fyno5ye01HZXqPL7fPFeHHfjnreCfjEr2m82Kqek1HnPrNa/p4Yhvv1VX3Xt4Y7/fj/Djv/K3ik7Y1fd6/6j7Tv/m8nzXd3vMrR3kfIBEu7+l847388J4JAoCyVpLvxiX9XvzC59nFd/Ix/uK4Eq2rJN766kiJlhvRK6FM4yhKUd+ZimPld6r5a4OPcUi3ksVn5br8cdyv44XKihUrNGjQINWrV08ul0sLFy60OyQAAAAAAIAKgyLU744dO6aOHTvqlVdesTsUAAAAAACACofb8X43cOBADRw40O4wAAAAAAAAKiSKUCWUm5ur3Nxcz3R2dvD36QIIHDkHWI+8A6xFzgHWI+8Aa3E7XgmlpqYqPj7e80pKSrI7JKBCI+cA65F3gLXIOcB65B1gLYpQJZSSkqKsrCzPKz093e6QgAqNnAOsR94B1iLnAOuRd4C1uB2vhNxut9xud/Ed/Vjx9tNlHA0QeiX9SdmyUpqc++rFUWUUxZPBdf/z34Lrnxzk+JI0NsjPk9HB/pxwsM/Kax5k/ypB9q+4gv0ZYCt+NrikeTesx9ljG2rhTx6HRpti5ne2JApUPKU51wEomZLmnZXfjcdfHGfZukpiRK8Eu0M4Kyu+M5XWkG7WxWjluvzhSigAAAAAAACEHFdC/S4nJ0dpaWme6X379mnTpk2qUaOGGjZsaGNkAAAAAAAAzkcR6ndff/21LrroIs/0hAkTJEkjR47UrFmzbIoKAAAAAACgYqAI9bt+/frJGGN3GAAAAAAAABUSz4QCAAAAAABAyFGEAgAAAAAAQMhRhAIAAAAAAEDIUYQCAAAAAABAyFGEAgAAAAAAQMhRhAIAAAAAAEDIUYQCAAAAAABAyFGEAgAAAAAAQMhRhAIAAAAAAEDIUYQCAAAAAABAyFGEAgAAAAAAQMhRhAIAAAAAAEDIUYQCAAAAAABAyFGEAgAAAAAAQMhF2R0AAAAAADjRoCHDlPHzIb/zEs+poQ/mz7U4IgAo3yhCAQAAAEAJZPx8SM1ueszvvLR/TbQ4GgAo/7gdDwAAAAAAACFHEQoAAAAAAAAhx+14NrjgzpeDXmbltLtDEAkQuN5jXi3Rcl/+3x1lHEnwetw32297flQlv+25rfr5bY/Z/aXf9t8ad/XbXv1r/+s91OYKv+01tvzbf//zhvhtl6QqGdv8tue1vshve8zmD/22t+r1B7/t63dv99vepXlrv+3rDvzgt/3W1nX8tv/n12i/7ZfXOOW3vSjV3fl+20/kuYpcpkaM/2WKEh3pvz3CZfy3FzHOaeM/pht6JPhtf3fNYb/t13WvXsQayp95Ptsw1Cf2uau95w/r4T3/zS+PeE1H++xc3/fgh2Peb1Yln/fux9+8B8g86T19zOe4Scv1ns7J/tV7wPw87+nTJ70mI48f8ZqOOfqT17SJjPGajjid6zXtyj/tNV1p/1rv9RnvYzmvVnOv6dz4+t7xnMzxmv6tekPv5eO889UV7f1ZGRHl/fXx3NiqXtMNfPLx0Cnv/dezund+R0V4v38xPu9v5Sjv+b79feWffbYifFIw2OMRACTpgjteDHqZla+OK9G6/r4sO+hl7uoXV6J1lcTsVUdKtNzwngllGkdRivouVRwrv2vNXxt8jEO6OfP8xJVQAAAAAAAACDmKUAAAAAAAAAg5ilA+XnnlFTVu3FiVKlVS9+7dtXbt2uIXAgAAAAAAwFlRhCpg7ty5mjBhgiZNmqQNGzaoY8eOGjBggDIzM+0ODQAAAAAAwNEoQhUwdepUjR49WqNGjVKbNm306quvqkqVKnrjjTfsDg0AAAAAAMDR+HW83508eVLr169XSkqKpy0iIkL9+/fXqlWrCvXPzc1Vbu7/fr0mOzv4XywAEDhyDrAeeQdYi5wDrEfeAdaiCPW7X375RXl5eapTx/tnievUqaMdO3YU6p+amqrJkyeXaF0rp91douUAO335f3fYuv7S5Nzq54aXURRXBdd99D1Bjn9/kP0lqWlw3W8aFuT4nYPs3yyo3kVvcaUi54QbK38e2Fdp8q6gocVsw7AeZ59/S++EUsdQturbvP7BNq+/tCrbHcBZFXc8hlJZ5RyAwJU071a+Oi4E0fh3V784y9ZVEsN7JtgdwlnZ+V0qUEO6lf8Yywq345VQSkqKsrKyPK/09HS7QwIqNHIOsB55B1iLnAOsR94B1uJKqN/VqlVLkZGR+umnn7zaf/rpJ9WtW7dQf7fbLbfbbVV4QNgj5wDrkXeAtcg5wHrkHWAtroT6XUxMjLp06aLPPvvM05afn6/PPvtMPXv2tDEyAAAAAAAA5+NKqAImTJigkSNHqmvXrurWrZteeOEFHTt2TKNGjbI7NAAAAADQoCHDlPHzIb/zEs+poQ/mz7U4IgAIHEWoAoYNG6aff/5ZEydO1MGDB3Xeeedp0aJFhR5WDgAAAAB2yPj5kJrd9JjfeWn/mmhxNAAQHIpQPsaMGaMxY8bYHQYAAAAAAECFwjOhAAAAAAAAEHIUoQAAAAAAABBy3I5XRowxkqTs7GybIwGcKTY2Vi6XK+D+5BxQeuQdYK1Q5lx+fr7yTucVOS8UeRsu6yxv8dixzmE3j9JPvx7xO69OzQTN/X8zy3ydZSHYnJM41wGlVVzeucyZLEOpHDhwQElJSXaHAThWVlaW4uLiAu5PzgGlR94B1iLnAGsFm3MSeQeUVnF5RxGqjOTn5+vHH38stuqXnZ2tpKQkpaenB/2BiJJjv9sjmP0e7P9UBZpzZRkjCmP/lY7d+8+uvHMKu98fO4Xztkuh2/5Q5Vy4vl/hut0S2x6q75dSYHkXzvs/WOyr4FSE/VVc3nE7XhmJiIhQgwYNAu4fFxfn2IPKydjv9gjFfg8254rDsVE67L/Sccr+K+u8cwqnvD+hEM7bLtm//Xy/DEy4brfEtodi24PJu3De/8FiXwWnIu8vHkwOAAAAAACAkKMIBQAAAAAAgJCjCGUxt9utSZMmye122x1KWGG/28MJ+90JMZZn7L/SYf+Vb+H8/oTztkvO236nxVtWwnW7Jbbd7m0vDzE4BfsqOOGwv3gwOQAAAAAAAEKOK6EAAAAAAAAQchShAAAAAAAAEHIUoQAAAAAAABByFKHKiDFG2dnZ4hFbgDXIOcB65B1gLXIOsB55B4QWRagycvToUcXHx+vo0aN2hwKEBXIOsB55B1iLnAOsR94BoUURCgAAAAAAACFHEQoAAAAAAAAhRxEKAAAAAAAAIUcRCgAAAAAAACFHEQoAAAAAAAAhRxHqd48++qhcLpfXq1WrVnaHBQAAAAAAUCFE2R1AedK2bVt9+umnnumoKHYPAAAAAABAWaDKUkBUVJTq1q1rdxgAAAAAAAAVDkWoAnbv3q169eqpUqVK6tmzp1JTU9WwYUO/fXNzc5Wbm+uZzs7OtipMICyRc4D1yDvAWuQcYD3yDrAWRajfde/eXbNmzVLLli2VkZGhyZMnq0+fPtq6datiY2ML9U9NTdXkyZNtiBSwx/y1h0u03JBu1ctk/eQc4K2onCyrnJPIu/LC970uy/cY5YvTcu5s3w04TuEUJc27zMxMZWVlBbVMfHy8ateuHfS6gIrEZYwxdgdRHh05ckSNGjXS1KlTdfvttxea769inpSUpKysLMXFxVkZKmAJu4tQ5BzgzYoiFHlXPlCECh9OyzmKUKgISpJ3mZmZata8uY4GedVUbFyc0nbvphCFsMaVUEVISEhQixYtlJaW5ne+2+2W2+22OCogfJFzgPXIO8Ba5BxgvZLkXVZWlo5mZ6vvuBdUtWZiQMsc+zVDy18cr6ysLIpQCGsUoYqQk5OjPXv26Oabb7Y7FAAAAABAOVO1ZqJi6yTZHQbgKBF2B1Be3HfffVq+fLm+++47ffXVV7rmmmsUGRmp4cOH2x0aAAAAAACA43El1O8OHDig4cOH69dff9U555yjCy64QKtXr9Y555xjd2gAAAAAAACORxHqd3PmzLE7BAAAAAAAgAqL2/EAAAAAAAAQchShAAAAAAAAEHIUoQAAAAAAABByFKEAAAAAAAAQchShAAAAAAAAEHIUoQAAAAAAABByFKEAAAAAAAAQclF2BwDAGYZ0q253CAAKICfDB+81yiuOTQBAsLgSCgAAAAAAACFHEQoAAAAAAAAhRxEKAAAAAAAAIUcRCgAAAAAAACFHEQoAAAAAAAAhRxEKAAAAAAAAIUcRCgAAAAAAACFHEQoAAAAAAAAhRxEKAAAAAAAAIUcRCgAAAAAAACFHEQoAAAAAAAAhRxEKAAAAAAAAIUcRCgAAAAAAACEXZXcA4Wj+2sNBLzOkW/UQRAIEriTHrcSxC/h6Z43/XIp0BTdOOOWW7+eP3dte3Oehb3yljT/Y5ct6f5W3/Q//znZchuo9C5d1AgDKDldCAQAAAAAAIOQoQgEAAAAAACDkKEIBAAAAAAAg5ChCAQAAAAAAIOQoQgEAAAAAACDkKEIBAAAAAAAg5ChC+TFlyhS5XC6NHz/e7lAAAAAAAAAqhApXhMrLy9OmTZt0+PDhEi2/bt06vfbaa+rQoUMZRwYAAAAAABC+HF+EGj9+vGbMmCHpvwWovn37qnPnzkpKStKyZcuCGisnJ0cjRozQ66+/rurVq4cgWgAAAAAAgPDk+CLUu+++q44dO0qSPvjgA+3bt087duzQPffco7/+9a9BjZWcnKwrr7xS/fv3L7Zvbm6usrOzvV4AQoecA6xH3gHWIucA65F3gLUcX4T65ZdfVLduXUnSRx99pKFDh6pFixa67bbbtGXLloDHmTNnjjZs2KDU1NSA+qempio+Pt7zSkpKKlH8AAJDzgHWI+8Aa5FzgPXIO8Baji9C1alTR9u2bVNeXp4WLVqkSy+9VJJ0/PhxRUZGBjRGenq6xo0bp7feekuVKlUKaJmUlBRlZWV5Xunp6SXeBgDFI+cA65F3gLXIOcB65B1grSi7AyitUaNG6frrr1diYqJcLpfnVro1a9aoVatWAY2xfv16ZWZmqnPnzp62vLw8rVixQv/3f/+n3NzcQgUtt9stt9tddhsC4KzIOcB65B1gLXIOsB55B1jL8UWoRx99VO3atVN6erqGDh3q+QCJjIzUQw89FNAYl1xySaFb90aNGqVWrVrpwQcfDPiKqkAN6cZDz+E8HLdA2bi+O7kUrPL2+RNsPKWN3+r1hXo8hIYd71O4rBMAUHYcX4R68803NWzYsELV6+HDh2vOnDkBjREbG6t27dp5tVWtWlU1a9Ys1A4AAAAAAIDgOf6ZUKNGjVJWVlah9qNHj2rUqFE2RAQAAAAAAABfjr8Syhgjl8tVqP3AgQOKj48v8bjLli0rRVQAAAAAAAAoyLFFqE6dOsnlcsnlcumSSy5RVNT/NiUvL0/79u3T5ZdfbmOEAAAAAAAAOMOxRajBgwdLkjZt2qQBAwaoWrVqnnkxMTFq3LixhgwZYlN0AAAAAAAAKMixRahJkyZJkho3bqxhw4apUqVKNkcEAAAAAACAoji2CHXGyJEj7Q4BAAAAAAAAxXBkEapGjRratWuXatWqperVq/t9MPkZhw4dsjAyAAAAAAAA+OPIItTf/vY3xcbGSpJeeOEFe4MBAAAAAABAsRxZhNq8ebOuu+46ud1uNWnSRL169fL6dTwAAAAAAACULxF2B1ASL7/8snJyciRJF110EbfcAQAAAAAAlHOOvHyocePGeumll3TZZZfJGKNVq1apevXqfvteeOGFFkcHAAAAAAAAX44sQj377LO64447lJqaKpfLpWuuucZvP5fLpby8PIujAwAAAAAAgC9HFqEGDx6swYMHKycnR3Fxcdq5c6dq165td1gAAAAAAAAogiOLUGdUq1ZNS5cuVZMmTXgwOQAAAAAAQDnmyAeTF9S3b199//33evjhhzV8+HBlZmZKkj7++GN9++23NkcHAAAAAAAAqQIUoZYvX6727dtrzZo1WrBggedX8zZv3qxJkybZHB0AAAAAAACkClCEeuihh/TEE09oyZIliomJ8bRffPHFWr16tY2RAQAAAAAA4AzHF6G2bNni99fxateurV9++cWGiAAAAAAAAODL8UWohIQEZWRkFGrfuHGj6tevb0NEAAAAAAAA8OX4ItQNN9ygBx98UAcPHpTL5VJ+fr6+/PJL3XfffbrlllvsDg8AAAAAAACqAEWop556Sq1atVJSUpJycnLUpk0bXXjhherVq5cefvhhu8MDAAAAAACApCi7AyitmJgYvf7663rkkUe0detW5eTkqFOnTmrevLndoQEAAAAAAOB3ji9CndGwYUM1bNjQ7jAAAAAAAADgh+OLUHl5eZo1a5Y+++wzZWZmKj8/32v+559/blNkAAAAAAAAOMPxRahx48Zp1qxZuvLKK9WuXTu5XC67QwIAAAAAAIAPxxeh5syZo3feeUdXXHGF3aEAAAAAAACgCI4vQsXExKhZs2Z2hxGUd9ccDnqZ67pXD0EkQODmrw3+uJWkId04dlExzFl9xG+7S8Zve2QRF+byeV7++J6Xfd8j388/4/OWF/eeFrd8cRdx+36OFvc9orTHWLD7wze+4uYjNM52XITqc8eOdZ7t+wjHGgCUfxF2B1Ba9957r1588UUZ3290AAAAAAAAKDccfyXUypUrtXTpUn388cdq27atoqOjveYvWLDApsgAAAAAAABwhuOLUAkJCbrmmmvsDgMAAAAAAABn4fgi1MyZM8tknGnTpmnatGn67rvvJElt27bVxIkTNXDgwDIZHwAAAAAAIJw5/plQknT69Gl9+umneu2113T06FFJ0o8//qicnJyAx2jQoIGmTJmi9evX6+uvv9bFF1+sq6++Wt9++22owgYAAAAAAAgbjr8S6vvvv9fll1+u/fv3Kzc3V5deeqliY2P19NNPKzc3V6+++mpA4wwaNMhr+sknn9S0adO0evVqtW3bNhShAwAAAAAAhA3HF6HGjRunrl27avPmzapZs6an/ZprrtHo0aNLNGZeXp7mzZunY8eOqWfPnn775ObmKjc31zOdnZ1donUBCAw5B1iPvAOsRc4B1iPvAGs5/na8L774Qg8//LBiYmK82hs3bqwffvghqLG2bNmiatWqye1264477tB7772nNm3a+O2bmpqq+Ph4zyspKanE2wCgeOQcYD3yDrAWOQdYj7wDrOX4IlR+fr7y8vIKtR84cECxsbFBjdWyZUtt2rRJa9as0Z133qmRI0dq27ZtfvumpKQoKyvL80pPTy9R/AACQ84B1iPvAGuRc4D1yDvAWo6/He+yyy7TCy+8oOnTp0uSXC6XcnJyNGnSJF1xxRVBjRUTE6NmzZpJkrp06aJ169bpxRdf1GuvvVaor9vtltvtLv0GAAgIOQdYj7wDrEXOAdYj7wBrOb4I9fzzz2vAgAFq06aNTpw4oRtvvFG7d+9WrVq1NHv27FKNnZ+f73V/MAAAAAAAAErG8UWoBg0aaPPmzZozZ46++eYb5eTk6Pbbb9eIESNUuXLlgMdJSUnRwIED1bBhQx09elRvv/22li1bpsWLF4cwegAAAAAAgPDg+CKUJEVFRemmm24q1RiZmZm65ZZblJGRofj4eHXo0EGLFy/WpZdeWkZRAgAAAAAAhC+XMcbYHURp7dy5Uy+//LK2b98uSWrdurXGjBmjVq1aWRZDdna24uPjlZWVpbi4OMvWC4Qrcg6wHnkHWIucA6wXSN7t3r1bLVq00BWPzVVsncB+Te/oT+n6aOIw7dq1S82bNy/LkAFHcfyv482fP1/t2rXT+vXr1bFjR3Xs2FEbNmxQ+/btNX/+fLvDAwAAAAAAgCrA7XgPPPCAUlJS9Nhjj3m1T5o0SQ888ICGDBliU2QAAAAAAAA4w/FXQmVkZOiWW24p1H7TTTcpIyPDhogAAAAAAADgy/FFqH79+umLL74o1L5y5Ur16dPHhogAAAAAAADgy5G34/373//2/PsPf/iDHnzwQa1fv149evSQJK1evVrz5s3T5MmT7QoRAAAAAAAABTiyCDV48OBCbX//+9/197//3astOTlZd9xxh0VRAQAAAAAAoCiOLELl5+fbHQIAAAAAAACC4PhnQgWqffv2Sk9PtzsMAAAAAACAsBQ2RajvvvtOp06dsjsMAAAAAACAsBQ2RSgAAAAAAADYhyIUAAAAAAAAQo4iFAAAAAAAAEKOIhQAAAAAAABCjiIUAAAAAAAAQq5CFaFOnDhR5LzXXntNderUsTAaAAAAAAAAnOH4IlR+fr4ef/xx1a9fX9WqVdPevXslSY888ohmzJjh6XfjjTeqatWqdoUJAAAAAAAQ1hxfhHriiSc0a9YsPfPMM4qJifG0t2vXTv/4xz9sjAwAAAAAAABnOL4I9eabb2r69OkaMWKEIiMjPe0dO3bUjh07bIwMAAAAAAAAZzi+CPXDDz+oWbNmhdrz8/N16tQpGyICAAAAAACAL8cXodq0aaMvvviiUPu7776rTp062RARAAAAAAAAfEXZHUBpTZw4USNHjtQPP/yg/Px8LViwQDt37tSbb76pDz/80O7wAAAAAAAAoApwJdTVV1+tDz74QJ9++qmqVq2qiRMnavv27frggw906aWX2h0eAAAAAAAAVAGuhJKkPn36aMmSJXaHAQAAAAAAgCI4/kqodevWac2aNYXa16xZo6+//tqGiAAAAAAAAODL8UWo5ORkpaenF2r/4YcflJycbENEAAAAAAAA8OX4ItS2bdvUuXPnQu2dOnXStm3bbIgIAAAAAAAAvhxfhHK73frpp58KtWdkZCgqqkI88goAAAAAAMDxHF+lueyyy5SSkqL3339f8fHxkqQjR47oL3/5S7n9dbw5q48EvcwNPRLKPA4gGG99daREy43olVCmcQD+vL4iy2/70VOuIpep7jZ+2yNd/ttv6Z0QdFywxrw1h72mI3ze9iHdqntNv+vTvzj5PtNFH1W/9/c5hE7ney8RHendwXc83/6+8nzGj/L5L8U8n4B990dkhPcAvv8j6ZsBecYnfp/lfbfXd33B8n2/Smv+Wu/3u6zHLy9mrzpS5LzhPRNCss6zfTcI1fn/nbPk7/XdrX9vfY+vgkJ1rIXLOgFUTI6/Euq5555Tenq6GjVqpIsuukgXXXSRmjRpooMHD+r5558PeJzU1FSdf/75io2NVe3atTV48GDt3LkzhJEDAAAAAACED8cXoerXr69vvvlGzzzzjNq0aaMuXbroxRdf1JYtW5SUlBTwOMuXL1dycrJWr16tJUuW6NSpU7rssst07NixEEYPAAAAAAAQHhx/O54kVa1aVX/6059KNcaiRYu8pmfNmqXatWtr/fr1uvDCC0s1NgAAAAAAQLirEEWo3bt3a+nSpcrMzFR+vveDECZOnFiiMbOy/vt8kRo1apQ6PgAAAAAAgHDn+CLU66+/rjvvvFO1atVS3bp15XL972mYLperREWo/Px8jR8/Xr1791a7du389snNzVVubq5nOjs7O/jgAQSMnAOsR94B1iLnAOuRd4C1HP9MqCeeeEJPPvmkDh48qE2bNmnjxo2e14YNG0o0ZnJysrZu3ao5c+YU2Sc1NVXx8fGeVzDPnwIQPHIOsB55B1iLnAOsR94B1nJ8Eerw4cMaOnRomY03ZswYffjhh1q6dKkaNGhQZL+UlBRlZWV5Xunp6WUWA4DCyDnAeuQdYC1yDrAeeQdYy/G34w0dOlSffPKJ7rjjjlKNY4zR3Xffrffee0/Lli1TkyZNztrf7XbL7XaXap0AAkfOAdYj7wBrkXOA9cg7wFqOL0I1a9ZMjzzyiFavXq327dsrOjraa/7YsWMDGic5OVlvv/223n//fcXGxurgwYOSpPj4eFWuXLnM4wYAAAAAAAgnji9CTZ8+XdWqVdPy5cu1fPlyr3kulyvgItS0adMkSf369fNqnzlzpm699dayCBUAAAAAACBsOb4ItW/fvjIZxxhTJuMAAAAAAACgMMc/mBwAAAAAAADln+OvhJKkAwcO6N///rf279+vkydPes2bOnWqTVEBAAAAAADgDMcXoT777DP94Q9/UNOmTbVjxw61a9dO3333nYwx6ty5s93h+XVDjwS7QwCCNqJXgt0hAEUafWG83SHARkO7Vw+q/3VB9oezDekWHu/38J4Jlq/Tju8G15ez/LXj+AqXdQKomBx/O15KSoruu+8+bdmyRZUqVdL8+fOVnp6uvn37aujQoXaHBwAAAAAAAFWAItT27dt1yy23SJKioqL022+/qVq1anrsscf09NNP2xwdAAAAAAAApApQhKpatarnOVCJiYnas2ePZ94vv/xiV1gAAAAAAAAowPHPhOrRo4dWrlyp1q1b64orrtC9996rLVu2aMGCBerRo4fd4QEAAAAAAEAVoAg1depU5eTkSJImT56snJwczZ07V82bN+eX8QAAAAAAAMoJRxeh8vLydODAAXXo0EHSf2/Ne/XVV22OCgAAAAAAAL4c/UyoyMhIXXbZZTp8+LDdoQAAAAAAAOAsHF2EkqR27dpp7969docBAAAAAACAs3B8EeqJJ57Qfffdpw8//FAZGRnKzs72egEAAAAAAMB+jn4mlCRdccUVkqQ//OEPcrlcnnZjjFwul/Ly8uwKDQAAAAAAAL9zfBFq6dKldocAAAAAAACAYji+CNW3b1+7QwAAAAAAAEAxHF+EWrFixVnnX3jhhRZFAgAAAAAAgKI4vgjVr1+/Qm0Fnw3FM6EAAAAAAADs5/hfxzt8+LDXKzMzU4sWLdL555+vTz75xO7wAAAAAAAAoApwJVR8fHyhtksvvVQxMTGaMGGC1q9fb0NUAAAAAAAAKMjxV0IVpU6dOtq5c6fdYQAAAAAAAEAV4Eqob775xmvaGKOMjAxNmTJF5513nj1BAQAAAAAAwIvji1DnnXeeXC6XjDFe7T169NAbb7xhU1QAAAAAAAAoyPFFqH379nlNR0RE6JxzzlGlSpVsiggAAAAAAAC+HF+EatSoUaG2I0eOUIQCAAAAAAAoRxz/YPKnn35ac+fO9Uxff/31qlGjhurXr6/NmzfbGBkAAAAAAADOcHwR6tVXX1VSUpIkacmSJVqyZIkWLVqkgQMH6v7777c5OgAAAAAAAEgV4Ha8gwcPeopQH374oa6//npddtllaty4sbp3725zdAAAAAAAAJAqwJVQ1atXV3p6uiRp0aJF6t+/vyTJGKO8vDw7QwMAAAAAAMDvHH8l1LXXXqsbb7xRzZs316+//qqBAwdKkjZu3KhmzZrZHB0AAAAAAACkCnAl1N/+9jeNGTNGbdq00ZIlS1StWjVJUkZGhu66666Ax1mxYoUGDRqkevXqyeVyaeHChSGKGAAAAAAAIPw4/kqo6Oho3XfffYXa77nnnqDGOXbsmDp27KjbbrtN1157bVmF59eLS7ODXmbcRXEhiAQI3CvLgj9uJSm5H8duOEldctRv+68n/f+fx6e/nvbbPqROpN/2Y3kuv+0dq5/y2z68Z4LfdpQv89ce9poe0q261/S7a7znX9fde/48n/nGZ3zfo8Z3+rRx+cz3HuGkz3F3Kt97OirCu7/v+o/4HP+VI7175Pku4CPSJ2DfeGIiz75+/1lTtHyfAeJifOLN954fVcx/afpun2//aN/959PfVcwGBHu8VFR/P8t5+q4QnYtf+LzodY6/ODTrnLXySJHzbr0gISTrPJvZq44UOS9U5yDfY7ygUB3vvp/TBfnmoJPXCSD0HF+EkqTdu3dr6dKlyszMVH6+9zejiRMnBjTGwIEDPbfyAQAAAAAAoGw5vgj1+uuv684771StWrVUt25duQr8d5nL5Qq4CBWs3Nxc5ebmeqazs0t2lQiAwJBzgPXIO8Ba5BxgPfIOsJbjnwn1xBNP6Mknn9TBgwe1adMmbdy40fPasGFDyNabmpqq+Ph4zyspKSlk6wJAzgF2IO8Aa5FzgPXIO8Baji9CHT58WEOHDrV8vSkpKcrKyvK80tPTLY8BCCfkHGA98g6wFjkHWI+8A6zl+Nvxhg4dqk8++UR33HGHpet1u91yu92WrhMIZ+QcYD3yDrAWOQdYj7wDrOX4IlSzZs30yCOPaPXq1Wrfvr2io6O95o8dO9amyAAAAAAAAHCG44tQ06dPV7Vq1bR8+XItX77ca57L5Qq4CJWTk6O0tDTP9L59+7Rp0ybVqFFDDRs2LNOYAQAAAAAAwo3ji1D79u0rk3G+/vprXXTRRZ7pCRMmSJJGjhypWbNmlck6AAAAAAAAwpUji1ATJkzQ448/rqpVq3qKRf64XC49//zzAY3Zr18/GWPKKkQAAAAAAAAU4Mgi1MaNG3Xq1CnPv4vicrmsCgkAAAAAAABn4cgi1NKlS/3+GwAAAAAAAOVThN0BAAAAAAAAoOKjCAUAAAAAAICQcxmexl0msrOzFR8fr6ysLMXFxdkdDlDhkXOA9cg7wFrkHGC9QPJu9+7datGiha54bK5i6yQFNO7Rn9L10cRh2rVrl5o3b16WIQOOwpVQAAAAAAAACDmKUAAAAAAAAAg5ilAAAAAAAAAIOYpQAAAAAAAACDmKUAAAAAAAAAg5ilAAAAAAAAAIOYpQAAAAAAAACDmKUAAAAAAAAAg5ilAAAAAAAAAIOYpQAAAAAAAACDmKUAAAAAAAAAg5ilAAAAAAAAAIOYpQAAAAAAAACLkouwMIRxcOHRf0MivmvRiCSIDAXXj9+BItt+KdF8o0jpK44K6/+22PyEr32/5rt1v9ttdc/7b//p1v8N//y1f997/w7uD69xztt12Saq6d5X+ZvkWsY9VMv+1HLx7rtz1q+zK/7Q06X+q3PS3rqN/2Lbef47cdFdO7aw57Tbtc3vPzjff06XzvDlER3h2OnfKeHxPpu7z39MHfvDtE+qw/44T3/8H9ctJ7+nCe9wLfH8/1Xt+J417T5niW13TUce/tr3Qk/azzI04e85rOq5zgNe3Kz/Oajvxlt9e0TnvHp2q1vSZP1jzXe/mTOV7TufENvKZPVK/vM14t73givb8+1qkW6zXduor3G+Lzdqlx1dPe4/m8P5Uivd//yj7T0T7/hRrpc7z4DFdo2td13at7Tfsev77z56/1ni9JQ7pVL9RmtQvuKPq74spXg//uGYizfacN1XfX8574osh5mx7uE5J1ns2IBb8VOe+tayuHZJ2vrcgqct6fL4wPyTrnri583J8xrEdojn/fXCzINy8BOAdXQgEAAAAAACDkuBIKAAAAAIByKjMzU1lZRV8B5098fLxq165dfEfAYhShAAAAAAAohzIzM9WseXMdzc4OarnYuDil7d5NIQrlDkUoAAAAAADKoaysLB3NzlbfcS+oas3EgJY59muGlr84XllZWRShUO5QhAIAAAAAoByrWjNRsXWS7A4DKDUeTA4AAAAAAICQowgFAAAAAACAkKMIBQAAAAAAgJCjCAUAAAAAAICQowjl45VXXlHjxo1VqVIlde/eXWvXrrU7JAAAAAAAAMejCFXA3LlzNWHCBE2aNEkbNmxQx44dNWDAAGVmZtodGgAAAAAAgKNRhCpg6tSpGj16tEaNGqU2bdro1VdfVZUqVfTGG2/YHRoAAAAAAICjRdkdQHlx8uRJrV+/XikpKZ62iIgI9e/fX6tWrSrUPzc3V7m5uZ7p7OxsS+IEwhU5B1iPvAOsRc4B1iPvAGu5jDHG7iDKgx9//FH169fXV199pZ49e3raH3jgAS1fvlxr1qzx6v/oo49q8uTJhcbJyspSXFxcyOMFwg05B1iPvAOsRc4B1itJ3u3evVstWrTQFY/NVWydpIDWc/SndH00cZh27dql5s2bBxyflesCrMDteCWUkpKirKwszys9Pd3ukIAKjZwDrEfeAdYi5wDrkXeAtbgd73e1atVSZGSkfvrpJ6/2n376SXXr1i3U3+12y+12WxUeEPbIOcB65B1gLXIOsB55B1iLItTvYmJi1KVLF3322WcaPHiwJCk/P1+fffaZxowZY29wAAAAAACUQ5mZmcrKygp6ufj4eNWuXTsEEaE8owhVwIQJEzRy5Eh17dpV3bp10wsvvKBjx45p1KhRdocGAAAAAEC5kpmZqWbNm+toCR7oHhsXp7TduylEhRmKUAUMGzZMP//8syZOnKiDBw/qvPPO06JFi1SnTh27QwMAAAAAoFzJysrS0exs9R33gqrWTAx4uWO/Zmj5i+OVlZVFESrMUITyMWbMGG6/AwAAAAAgQFVrJgb8630Ib/w6HgAAAAAAAEKOK6EAAAAAAECF5IQHp5ckRqc+2J0iVBkxxkiSskvwQDYAUmxsrFwuV8D9yTmg9Mg7wFrkHGCtYHNOCizvcnJyJElHM39QXl5eQOMe//WgJGnbtm2e5QOxf/9+y9ZVEiWJT7IuxkOHDunqwdfoWM7RoJetWq2a3l+4UDVq1AhBZP9T0hitik+SqlevHvB6iss7lzmTZSiVAwcOKCmJe2CBksrKylJcXFzA/ck5oPTIO8Ba5BxgrWBzTiLvgNIqLu8oQpWR/Px8/fjjj8VW/bKzs5WUlKT09PSgPxBRcux3ewSz34P9n6pAc64sY0Rh7L/SsXv/2ZV3TmH3+2OncN52KXTbH6qcC9f3K1y3W2LbQ/X9Ugos78J5/weLfRWcirC/iss7bscrIxEREWrQoEHA/ePi4hx7UDkZ+90eodjvweZccTg2Sof9VzpO2X9lnXdO4ZT3JxTCedsl+7ef75eBCdftltj2UGx7MHkXzvs/WOyr4FTk/cWv4wEAAAAAACDkKEIBAAAAAAAg5ChCWcztdmvSpElyu912hxJW2O/2cMJ+d0KM5Rn7r3TYf+VbOL8/4bztkvO232nxlpVw3W6Jbbd728tDDE7BvgpOOOwvHkwOAAAAAACAkONKKAAAAAAAAIQcRSgAAAAAAACEHEUoAAAAAAAAhBxFKAAAAAAAAIQcRagQeOWVV9S4cWNVqlRJ3bt319q1a8/af968eWrVqpUqVaqk9u3b66OPPrIo0oolmP0+a9YsuVwur1elSpUsjNb5VqxYoUGDBqlevXpyuVxauHBhscssW7ZMnTt3ltvtVrNmzTRr1qyQxylJqampOv/88xUbG6vatWtr8ODB2rlzp1efEydOKDk5WTVr1lS1atU0ZMgQ/fTTT5bE5zRTpkyRy+XS+PHjPW3sv7P74YcfdNNNN6lmzZqqXLmy2rdvr6+//toz3xijiRMnKjExUZUrV1b//v21e/duGyN2pkByvV+/foU+/++44w6vPvv379eVV16pKlWqqHbt2rr//vt1+vRprz6BfJ4F+32gtB599NFC29aqVSvP/EDy1KnbLkmNGzcutP0ul0vJycmSKu57b8e+tlsguR4O/J2PK7LizqVWCcecKwnytOQqfG4blKk5c+aYmJgY88Ybb5hvv/3WjB492iQkJJiffvrJb/8vv/zSREZGmmeeecZs27bNPPzwwyY6Otps2bLF4sidLdj9PnPmTBMXF2cyMjI8r4MHD1octbN99NFH5q9//atZsGCBkWTee++9s/bfu3evqVKlipkwYYLZtm2befnll01kZKRZtGhRyGMdMGCAmTlzptm6davZtGmTueKKK0zDhg1NTk6Op88dd9xhkpKSzGeffWa+/vpr06NHD9OrV6+Qx+Y0a9euNY0bNzYdOnQw48aN87Sz/4p26NAh06hRI3PrrbeaNWvWmL1795rFixebtLQ0T58pU6aY+Ph4s3DhQrN582bzhz/8wTRp0sT89ttvNkbuPIHket++fc3o0aO9Pv+zsrI880+fPm3atWtn+vfvbzZu3Gg++ugjU6tWLZOSkuLpE8jnWbDnpbIwadIk07ZtW69t+/nnnz3zi8tTJ2+7McZkZmZ6bfuSJUuMJLN06VJjTMV87+3a13YLJNcruqLOxxVVIOdSK4RrzpUEeVoy4ZDbFKHKWLdu3UxycrJnOi8vz9SrV8+kpqb67X/99debK6+80qute/fu5s9//nNI46xogt3vM2fONPHx8RZFV/EFUoR64IEHTNu2bb3ahg0bZgYMGBDCyPzLzMw0kszy5cuNMcYcOXLEREdHm3nz5nn6bN++3Ugyq1atsjy+8uro0aOmefPmZsmSJaZv376eEyP77+wefPBBc8EFFxQ5Pz8/39StW9c8++yznrYjR44Yt9ttZs+ebUWIFZZvrhtjvI5dfz766CMTERHh9R8T06ZNM3FxcSY3N9cYE9jnWbDnpbIwadIk07FjR7/zAslTJ2+7P+PGjTPnnnuuyc/PN8ZUzPe+vOxru/nL9YqsqPNxRVbcudQq5FzJhVuelkS45Da345WhkydPav369erfv7+nLSIiQv3799eqVav8LrNq1Sqv/pI0YMCAIvujsJLsd0nKyclRo0aNlJSUpKuvvlrffvutFeGGrfJ0rGdlZUmSatSoIUlav369Tp065RVfq1at1LBhQ3KxgOTkZF155ZWF3kf239n9+9//VteuXTV06FDVrl1bnTp10uuvv+6Zv2/fPh08eNBr/8XHx6t79+7sv1LyzfUz3nrrLdWqVUvt2rVTSkqKjh8/7pm3atUqtW/fXnXq1PG0DRgwQNnZ2Z7zRHGfZyU9L5WF3bt3q169emratKlGjBih/fv3SwosT52+7QWdPHlS//rXv3TbbbfJ5XJ52ivSe19e9nV5UFSuV1RFnY8rsuLOpVYg50on3PK0JMIlt6PsDqAi+eWXX5SXl+f15UWS6tSpox07dvhd5uDBg377Hzx4MGRxVjQl2e8tW7bUG2+8oQ4dOigrK0vPPfecevXqpW+//VYNGjSwIuywU9Sxnp2drd9++02VK1e2JI78/HyNHz9evXv3Vrt27TyxxcTEKCEhoVB85OJ/zZkzRxs2bNC6desKzWP/nd3evXs1bdo0TZgwQX/5y1+0bt06jR07VjExMRo5cqRnH3EuKFv+cl2SbrzxRjVq1Ej16tXTN998owcffFA7d+7UggULJBX9WXVm3tn6nPk8O3z4cNDnpbLQvXt3zZo1Sy1btlRGRoYmT56sPn36aOvWrQHlqZO33dfChQt15MgR3XrrrZ62ivbel+T7T0VUVK5XVGc7H1dkxZ1LrUDOlVy45WlJhFNuU4RCWOrZs6d69uzpme7Vq5dat26t1157TY8//riNkSHUkpOTtXXrVq1cudLuUBwjPT1d48aN05IlS3iAfwnk5+era9eueuqppyRJnTp10tatW/Xqq69a9sU5HBWV63/60588/27fvr0SExN1ySWXaM+ePTr33HOtDrNMDRw40PPvDh06qHv37mrUqJHeeecdywr95cWMGTM0cOBA1atXz9NWkd/7cBZO5/VwPh9zLnW2cMrTkgi33OZ2vDJUq1YtRUZGFvqlmZ9++kl169b1u0zdunWD6o/CSrLffUVHR6tTp05KS0sLRYhQ0cd6XFycZX8cjRkzRh9++KGWLl3qdcVb3bp1dfLkSR05cqRQfOTif2/jyczMVOfOnRUVFaWoqCgtX75cL730kqKiolSnTh3231kkJiaqTZs2Xm2tW7f23CZ1Zh9xLig7ReW6P927d5ckz+d/UZ9VZ+adrc+Zz7OyOC+VhYSEBLVo0UJpaWkBfc5VlG3//vvv9emnn+qPf/zjWfs5/b0vD/vabsHkekVQ3Pk4Ly/P7hBDprhzqRXIuZIJtzwtiXDLbYpQZSgmJkZdunTRZ5995mnLz8/XZ5995nXVTUE9e/b06i9JS5YsKbI/CivJfveVl5enLVu2KDExMVRhhj07j3VjjMaMGaP33ntPn3/+uZo0aeI1v0uXLoqOjvaKb+fOndq/fz+5KOmSSy7Rli1btGnTJs+ra9euGjFihOff7L+i9e7du9BPEu/atUuNGjWSJDVp0kR169b12n/Z2dlas2YN+y9IxeW6P5s2bZIkz+d/z549tWXLFmVmZnr6LFmyRHFxcZ4/gIr7PCuL81JZyMnJ0Z49e5SYmBjQ51xF2faZM2eqdu3auvLKK8/az+nvfXnY13YpSa5XBMWdjyMjI+0OMWSKO5daIZxzriTCNU9LIuxy297nolc8c+bMMW6328yaNcts27bN/OlPfzIJCQmeX1q5+eabzUMPPeTp/+WXX5qoqCjz3HPPme3bt5tJkyaZ6Ohos2XLFrs2wZGC3e+TJ082ixcvNnv27DHr1683N9xwg6lUqZL59ttv7doExzl69KjZuHGj2bhxo5Fkpk6dajZu3Gi+//57Y4wxDz30kLn55ps9/c/8rPX9999vtm/fbl555ZVCP2sdKnfeeaeJj483y5Yt8/pp7uPHj3v63HHHHaZhw4bm888/N19//bXp2bOn6dmzZ8hjcyrfX+xg/xVt7dq1Jioqyjz55JNm9+7d5q233jJVqlQx//rXvzx9pkyZYhISEsz7779vvvnmG3P11VebJk2amN9++83GyJ2nuFxPS0szjz32mPn666/Nvn37zPvvv2+aNm1qLrzwQs8Yp0+fNu3atTOXXXaZ2bRpk1m0aJE555xzTEpKiqdPIJ9nxZ2XQuHee+81y5YtM/v27TNffvml6d+/v6lVq5bJzMw0xhSfp07e9jPy8vJMw4YNzYMPPujVXlHfezv3tZ0COa+Hi4r8C1oFBXIutUK45lxJkKelU5FzmyJUCLz88sumYcOGJiYmxnTr1s2sXr3aM69v375m5MiRXv3feecd06JFCxMTE2Patm1r/vOf/1gcccUQzH4fP368p2+dOnXMFVdcYTZs2GBD1M61dOlSI6nQ68x+HjlypOnbt2+hZc477zwTExNjmjZtambOnGlJrP7ilOS1/t9++83cddddpnr16qZKlSrmmmuuMRkZGZbE50S+J0b239l98MEHpl27dsbtdptWrVqZ6dOne83Pz883jzzyiKlTp45xu93mkksuMTt37rQpWucqLtf3799vLrzwQlOjRg3jdrtNs2bNzP3332+ysrK8xvnuu+/MwIEDTeXKlU2tWrXMvffea06dOuXVJ5DPs7Odl0Jh2LBhJjEx0cTExJj69eubYcOGmbS0NM/8QPLUqdt+xuLFi42kQvlTkd97u/a1nQI5r4eLivyHqq/izqVWCcecKwnytHQqcm67jDHGgguuAAAAAAAAEMZ4JhQAAAAAAABCjiIUAAAAAAAAQo4iFAAAAAAAAEKOIhQAAAAAAABCjiIUAAAAAAAAQo4iFAAAAAAAAEKOIhQAAAAAAABCjiIUIOnWW2/V4MGD7Q4DAFCB9evXT+PHj7c7DMAyxhj96U9/Uo0aNeRyubRp06aQrMf3e1xFzbXvvvsupPsRzlBRj++y5nK5tHDhQrvDkCQtXLhQzZo1U2RkpMaPH69Zs2YpISHB7rBsE2V3AAAAAOFgwYIFio6OtjsMwDKLFi3SrFmztGzZMjVt2lS1atUKyXpefPFFGWNCMjZQ3nAucZ4///nPGjVqlMaOHavY2FhFRUXpiiuu8Mx/9NFHtXDhwrApMFOEAsqAMUZ5eXmKiiKlAAD+1ahRw+4QAEvt2bNHiYmJ6tWrV0jXEx8fH9LxK7qTJ08qJibG7jAQIDvPJfzNE7ycnBxlZmZqwIABqlevnqe9cuXKNkZlL27HQ7ly9OhRjRgxQlWrVlViYqL+9re/eV1ympubq/vuu0/169dX1apV1b17dy1btsyz/JlLGxcvXqzWrVurWrVquvzyy5WRkeHpk5eXpwkTJighIUE1a9bUAw88UOh/z/Lz85WamqomTZqocuXK6tixo959913P/GXLlsnlcunjjz9Wly5d5Ha7tXLlypDuG6A8WLRokS644AJP/lx11VXas2ePZ/5XX32l8847T5UqVVLXrl21cOHCQrcObN26VQMHDlS1atVUp04d3Xzzzfrll19s2BrAWgXPZ40bN9ZTTz2l2267TbGxsWrYsKGmT5/u1f/AgQMaPny4atSooapVq6pr165as2aNZ/60adN07rnnKiYmRi1bttT/+3//z2t5l8ul1157TVdddZWqVKmi1q1ba9WqVUpLS1O/fv1UtWpV9erVyyuHJen9999X586dValSJTVt2lSTJ0/W6dOnQ7NTUGHdeuutuvvuu7V//365XC41bty42HPImdvN3nnnHfXp00eVK1fW+eefr127dmndunXq2rWrqlWrpoEDB+rnn3/2WldRj1V47LHH1K5du0Lt5513nh555JGAtmPw4MF66qmnVKdOHSUkJOixxx7T6dOndf/996tGjRpq0KCBZs6c6bVcenq6rr/+eiUkJKhGjRq6+uqr9d1335V6XEnasWOHevXqpUqVKqldu3Zavny51/zizrP9+vXTmDFjNH78eNWqVUsDBgyQMUaPPvqoGjZsKLfbrXr16mns2LHF7h9YL5hzycmTJzVmzBglJiaqUqVKatSokVJTUyX5v73zyJEjcrlcnr+vivqbZ8+ePbr66qtVp04dVatWTeeff74+/fRTrzjL4jxX2vNRRkaGBg4cqMqVK6tp06Zef89Jgefpc889p8TERNWsWVPJyck6deqUp8/Z/j5dtmyZYmNjJUkXX3yxZ98WvB1v1qxZmjx5sjZv3iyXyyWXy6VZs2ZV7Jw0QDnyxz/+0TRq1Mh8+umnZsuWLeaaa64xsbGxZty4cZ75vXr1MitWrDBpaWnm2WefNW632+zatcsYY8zMmTNNdHS06d+/v1m3bp1Zv369ad26tbnxxhs963j66adN9erVzfz58822bdvM7bffbmJjY83VV1/t6fPEE0+YVq1amUWLFpk9e/aYmTNnGrfbbZYtW2aMMWbp0qVGkunQoYP55JNPTFpamvn1118t20+AXd59910zf/58s3v3brNx40YzaNAg0759e5OXl2eysrJMjRo1zE033WS+/fZb89FHH5kWLVoYSWbjxo3GGGMOHz5szjnnHJOSkmK2b99uNmzYYC699FJz0UUX2bthgAX69u3rOZ81atTI1KhRw7zyyitm9+7dJjU11URERJgdO3YYY4w5evSoadq0qenTp4/54osvzO7du83cuXPNV199ZYwxZsGCBSY6Otq88sorZufOneb55583kZGR5vPPP/esT5KpX7++mTt3rtm5c6cZPHiwady4sbn44ovNokWLzLZt20yPHj3M5Zdf7llmxYoVJi4uzsyaNcvs2bPHfPLJJ6Zx48bm0UcftW5HoUI4cuSIeeyxx0yDBg1MRkaGyczMPOs5xBhj9u3bZyR5voOdOUa7dOli+vXrZ1auXGk2bNhgmjVrZu644w7PukaOHOn1Pa5grqWnp5uIiAizdu1az/wNGzYYl8tl9uzZU+x2jBw50sTGxprk5GSzY8cOM2PGDCPJDBgwwDz55JNm165d5vHHHzfR0dEmPT3dGGPMyZMnTevWrc1tt91mvvnmG7Nt2zZz4403mpYtW5rc3NwSj3tm/zRo0MC8++67Ztu2beaPf/yjiY2NNb/88osxJrDzbN++fU21atXM/fffb3bs2GF27Nhh5s2bZ+Li4sxHH31kvv/+e7NmzRozffr0ErzzCLVgziXPPvusSUpKMitWrDDfffed+eKLL8zbb79tjPnf8XTmO5ox/z1+JJmlS5caY4r+m2fTpk3m1VdfNVu2bDG7du0yDz/8sKlUqZL5/vvvPWOV9jxX2vORJFOzZk3z+uuvm507d5qHH37YREZGmm3bthljAs/TuLg4c8cdd5jt27ebDz74wFSpUsUrN87292lubq7ZuXOnkWTmz59vMjIyTG5urpk5c6aJj483xhhz/Phxc++995q2bduajIwMk5GRYY4fP16hc5IiFMqN7OxsEx0dbebNm+dpO3LkiKlSpYoZN26c+f77701kZKT54YcfvJa75JJLTEpKijHmv0UoSSYtLc0z/5VXXjF16tTxTCcmJppnnnnGM33q1CnToEEDz5eXEydOmCpVqng+AM+4/fbbzfDhw40x//tAXrhwYdlsPOBQP//8s5FktmzZYqZNm2Zq1qxpfvvtN8/8119/3esLzuOPP24uu+wyrzHS09ONJLNz504rQwcs5/uHw0033eSZl5+fb2rXrm2mTZtmjDHmtddeM7GxsUX+B0evXr3M6NGjvdqGDh1qrrjiCs+0JPPwww97pletWmUkmRkzZnjaZs+ebSpVquSZvuSSS8xTTz3lNe7/+3//zyQmJga5tYAxf/vb30yjRo2KnF/wHGLM//4o/sc//uHpM3v2bCPJfPbZZ5621NRU07JlS8/02YpQxhgzcOBAc+edd3qm7777btOvX7+AtmHkyJGmUaNGnkKZMca0bNnS9OnTxzN9+vRpU7VqVTN79mxjzH9zpmXLliY/P9/TJzc311SuXNksXry4xOOe2T9Tpkzx9DnzPfbpp582xgR2nu3bt6/p1KmTV5/nn3/etGjRwpw8eTKg/QL7BHMuufvuu83FF1/sdSyeEUwRKpC/edq2bWtefvllz3Rpz3OlPR9J8ipWG2NM9+7dPZ8FweTp6dOnPX2GDh1qhg0bZowxAf196rtPjTFeRShjjJk0aZLp2LGj1xgVOSe5HQ/lxt69e3Xq1Cl169bN0xYfH6+WLVtKkrZs2aK8vDy1aNFC1apV87yWL1/udSl3lSpVdO6553qmExMTlZmZKUnKyspSRkaGunfv7pkfFRWlrl27eqbT0tJ0/PhxXXrppV7refPNNwvdslBwOSAc7N69W8OHD1fTpk0VFxenxo0bS5L279+vnTt3qkOHDqpUqZKnf8F8lqTNmzdr6dKlXrnVqlUrSSqUX0BF16FDB8+/XS6X6tat6zlfbdq0SZ06dSry2R/bt29X7969vdp69+6t7du3F7mOOnXqSJLat2/v1XbixAllZ2dL+m+OPvbYY145Onr0aGVkZOj48eOl2Frg7OeQggI5bs/kSiBGjx6t2bNn68SJEzp58qTefvtt3XbbbQEv37ZtW0VE/O/Ppjp16njFExkZqZo1a3pi2rx5s9LS0hQbG+vJoxo1aujEiRNe57pgxz2jZ8+enn+f+R57JvcDPc926dLFa8yhQ4fqt99+U9OmTTV69Gi999573IbrEGc7l9x6663atGmTWrZsqbFjx+qTTz4p0Tp8/+bJycnRfffdp9atWyshIUHVqlXT9u3bz5rLwZ7nyuJ8VDBXzkwXzJVA8zQyMtIzXfBvy0D/Pi2JipyTPFEMjpGTk6PIyEitX7/e64NAkqpVq+b5t++vRbhcrqB+MSUnJ0eS9J///Ef169f3mud2u72mq1atGvC4QEUwaNAgNWrUSK+//rrq1aun/Px8tWvXTidPngxo+ZycHA0aNEhPP/10oXmJiYllHS5Qrvk7X+Xn50squweWFlyHy+Uqsu3MenNycjR58mRde+21hcYqWGAGSiLQc0ggx+2ZYzbQ9brdbr333nuKiYnRqVOndN111wW8vL9cPVv+5uTkqEuXLnrrrbcKjXXOOeeUeNxABHqe9f0Om5SUpJ07d+rTTz/VkiVLdNddd+nZZ5/V8uXL+SW2cu5sx0znzp21b98+ffzxx/r00091/fXXq3///nr33Xc9BdCCfycVfNZRQb7Hy3333aclS5boueeeU7NmzVS5cmVdd911Z81l39iKO8+F+nxUmjwtmOuB/H1aEhU5JylCodxo2rSpoqOjtW7dOjVs2FDSf69c2rVrly688EJ16tRJeXl5yszMVJ8+fUq0jvj4eCUmJmrNmjW68MILJUmnT5/W+vXr1blzZ0lSmzZt5Ha7tX//fvXt27dsNg6oAH799Vft3LlTr7/+uicHCz6Qv2XLlvrXv/6l3NxcT8F23bp1XmN07txZ8+fPV+PGjfllFeAsOnTooH/84x86dOiQ3/8lbt26tb788kuNHDnS0/bll1+qTZs2pVpv586dtXPnTjVr1qxU4wC+ijuHhFJUVJRGjhypmTNnKiYmRjfccENIf5mqc+fOmjt3rmrXrq24uLgyH3/16tWFvseOGTPGs+6SnmcrV66sQYMGadCgQUpOTlarVq20ZcsWz3dkOFNcXJyGDRumYcOG6brrrtPll1+uQ4cOeQotGRkZ6tSpkyR5PaT8bL788kvdeuutuuaaayT9txhT8IHegSjuPFcW56PVq1frlltu8Zo+s61lkadl8fepJMXExCgvL69Qe0XNSW7HQ7kRGxurkSNH6v7779fSpUv17bff6vbbb1dERIRcLpdatGihESNG6JZbbtGCBQu0b98+rV27VqmpqfrPf/4T8HrGjRunKVOmaOHChdqxY4fuuusuHTlyxCuO++67T/fcc4/++c9/as+ePdqwYYNefvll/fOf/wzBlgPOUL16ddWsWVPTp09XWlqaPv/8c02YMMEz/8Ybb1R+fr7+9Kc/afv27Vq8eLGee+45Sf/7n+zk5GQdOnRIw4cP17p167Rnzx4tXrxYo0aN8nvyBcLV8OHDVbduXQ0ePFhffvml9u7dq/nz52vVqlWSpPvvv1+zZs3StGnTtHv3bk2dOlULFizQfffdV6r1Tpw4UW+++aYmT56sb7/9Vtu3b9ecOXP08MMPl8VmIYwVdw4JtT/+8Y/6/PPPtWjRoqBuxSuJESNGqFatWrr66qv1xRdfaN++fVq2bJnGjh2rAwcOlHr8V155Re+995527Nih5ORkHT582LNNJT3Pzpo1SzNmzNDWrVu1d+9e/etf/1LlypXVqFGjUscL+0ydOlWzZ8/Wjh07tGvXLs2bN09169ZVQkKCKleurB49emjKlCnavn27li9fHvBnffPmzbVgwQJt2rRJmzdv9nwHDEZx57myOB/NmzdPb7zxhnbt2qVJkyZp7dq1noJtWeRpWf192rhxY+3bt0+bNm3SL7/8otzc3AqdkxShUK5MnTpVPXv21FVXXaX+/furd+/eat26teeSy5kzZ+qWW27Rvffeq5YtW2rw4MFeV04F4t5779XNN9+skSNHqmfPnoqNjfVU8c94/PHH9cgjjyg1NVWtW7fW5Zdfrv/85z9q0qRJmW4v4CQRERGaM2eO1q9fr3bt2umee+7Rs88+65kfFxenDz74QJs2bdJ5552nv/71r5o4caKk/102Xa9ePX355ZfKy8vTZZddpvbt22v8+PFKSEjwei4GEO5iYmL0ySefqHbt2rriiivUvn17TZkyxXO5/+DBg/Xiiy/queeeU9u2bfXaa69p5syZ6tevX6nWO2DAAH344Yf65JNPdP7556tHjx7629/+ViG+9MJexZ1DQq158+bq1auXWrVq5fVs0FCoUqWKVqxYoYYNG+raa69V69atdfvtt+vEiRNlcmXUlClTNGXKFHXs2FErV67Uv//9b9WqVUtSyc+zCQkJev3119W7d2916NBBn376qT744APVrFmz1PHCPrGxsXrmmWfUtWtXnX/++fruu+/00UcfeY6FN954Q6dPn1aXLl00fvx4PfHEEwGNO3XqVFWvXl29evXSoEGDNGDAgKCvzinuPFcW56PJkydrzpw56tChg958803Nnj3bc8VwWeVpWfx9OmTIEF1++eW66KKLdM4552j27NkVOiddJpiH5QAWO3bsmOrXr6/nn39et99+u93hAAjSW2+9pVGjRikrKyuktz4AAHA2xhg1b95cd911l6VXYAEAvPFADpQrGzdu1I4dO9StWzdlZWXpsccekyRdffXVNkcGIBBvvvmmmjZtqvr162vz5s168MEHdf3111OAAgDY5ueff9acOXN08OBBjRo1yu5wACCsUYRCufPcc89p586diomJUZcuXfTFF194LjEGUL4dPHhQEydO1MGDB5WYmKihQ4fqySeftDssAEAYq127tmrVqqXp06erevXqXvPO9gtWH3/8cakeNgwgNN566y39+c9/9juvUaNG+vbbby2OCMHgdjwAAAAAYSktLa3IefXr1+dKXqAcOnr0qH766Se/86Kjo3mOYTlHEQoAAAAAAAAhx08RAQAAAAAAIOQoQgEAAAAAACDkKEIBAAAAAAAg5ChCAQAAAAAAIOQoQgEAAAAAACDkKEIBAAAAAAAg5ChCAQAAAAAAIOQoQgEAAAAAACDk/j+lgUsgkv3y0AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x1200 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_df_pair_plot = sns.pairplot(main_df, kind = 'hist')\n",
    "main_df_pair_plot.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it is rather difficult to identify any obvious groups from the above pair plot. Maybe looking at the correlation values is a good idea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.015456</td>\n",
       "      <td>-0.007315</td>\n",
       "      <td>0.011565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.001953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>-0.009064</td>\n",
       "      <td>0.654964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.015456</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031687</td>\n",
       "      <td>-0.013123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family_members</th>\n",
       "      <td>-0.007315</td>\n",
       "      <td>-0.009064</td>\n",
       "      <td>-0.031687</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insurance_benefits</th>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.654964</td>\n",
       "      <td>-0.013123</td>\n",
       "      <td>-0.039303</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      gender       age    income  family_members  \\\n",
       "gender              1.000000  0.001953  0.015456       -0.007315   \n",
       "age                 0.001953  1.000000 -0.017386       -0.009064   \n",
       "income              0.015456 -0.017386  1.000000       -0.031687   \n",
       "family_members     -0.007315 -0.009064 -0.031687        1.000000   \n",
       "insurance_benefits  0.011565  0.654964 -0.013123       -0.039303   \n",
       "\n",
       "                    insurance_benefits  \n",
       "gender                        0.011565  \n",
       "age                           0.654964  \n",
       "income                       -0.013123  \n",
       "family_members               -0.039303  \n",
       "insurance_benefits            1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, the above correlation values are not very useful. \n",
    "\n",
    "The only correlation that is moderately strong, which a value of 0.654964, is the one between **age** and **insurance_benefits**. This implies that a customer's age is a moderately good predictor of how many insurance benefits the customer receives. Since the correlation is positive, that means older customers tend to receive a larger number of benefits than younger customers. \n",
    "\n",
    "Every other correlation value has an absolute value less than 0.1, meaning virtually no correlation between the features. I need to find a way to combine several variables simultaneously in order to reveal useful insights. Thankfully, Linear Algebra and Machine Learning are effective at this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Similar Customers <a id = 3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to identify objects that make sense to group together, because they are very similar, is to develop a procedure (using machine learning) that returns k nearest neighbors (objects) for a given object based on the distance between the objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will write a function that returns the k nearest neighbors for an $n^{th}$ object based on a specified distance metric (either Euclidean or Manhattan). The number of received insurance benefits will not be taken into account for this task, since that is the target. \n",
    "\n",
    "The function will be tested using every possible combination of the following:\n",
    "\n",
    "<b>Scaling:</b>\n",
    "  - The data is not scaled\n",
    "  - The data is scaled with the [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) scaler\n",
    "\n",
    "<b>Distance Metrics:</b>\n",
    "  - Euclidean\n",
    "  - Manhattan\n",
    "\n",
    "I will also answer these questions:\n",
    "- Does the data being not scaled affect the kNN algorithm? If so, how does that appear?\n",
    "- How similar are the results using the Manhattan distance metric, regardless of the scaling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next line, I define the function **get_knn** where...\n",
    "\n",
    "- parameter df: The pandas DataFrame used to find similar objects within.\n",
    "- parameter n: The object number for which the nearest neighbours are looked for.\n",
    "- parameter k: The number of nearest neighbours to return.\n",
    "- parameter metric: The name of distance metric (Euclidean or Manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors = k, metric = metric)\n",
    "    nbrs.fit(df[features_names].values)\n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][features_names]], k, return_distance = True)\n",
    "    \n",
    "    df_res = pd.concat([df.iloc[nbrs_indices[0]], \n",
    "                        pd.DataFrame(nbrs_distances.T, index = nbrs_indices[0], columns = ['distance'])], axis = 1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\340739115.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.63076923 0.70769231 0.44615385 ... 0.30769231 0.33846154 0.43076923]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  main_df_scaled.loc[:, features_names] = transformer_mas.transform(main_df[features_names].to_numpy())\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\340739115.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.6278481  0.48101266 0.26582278 ... 0.42911392 0.41392405 0.51392405]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  main_df_scaled.loc[:, features_names] = transformer_mas.transform(main_df[features_names].to_numpy())\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\340739115.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.16666667 0.16666667 0.         ... 0.33333333 0.5        0.16666667]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  main_df_scaled.loc[:, features_names] = transformer_mas.transform(main_df[features_names].to_numpy())\n"
     ]
    }
   ],
   "source": [
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(main_df[features_names].to_numpy())\n",
    "\n",
    "main_df_scaled = main_df.copy()\n",
    "main_df_scaled.loc[:, features_names] = transformer_mas.transform(main_df[features_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>insurance_benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>0</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.598734</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>1</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.479747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>1</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.583544</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>0.441772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>0</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>0</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.440506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.606329</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.736709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>0</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  insurance_benefits\n",
       "4578       0  0.630769  0.598734        0.333333                   0\n",
       "2898       1  0.430769  0.479747        0.000000                   0\n",
       "2139       1  0.369231  0.583544        0.333333                   0\n",
       "575        1  0.523077  0.441772        0.000000                   0\n",
       "4671       0  0.707692  0.611392        0.000000                   1\n",
       "3461       0  0.446154  0.430380        0.333333                   0\n",
       "2053       0  0.446154  0.440506        0.000000                   0\n",
       "2221       0  0.461538  0.606329        0.166667                   0\n",
       "3188       1  0.615385  0.736709        0.000000                   0\n",
       "4154       0  0.323077  0.481013        0.000000                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4847 entries, 0 to 4846\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   gender              4847 non-null   int64  \n",
      " 1   age                 4847 non-null   float64\n",
      " 2   income              4847 non-null   float64\n",
      " 3   family_members      4847 non-null   float64\n",
      " 4   insurance_benefits  4847 non-null   int64  \n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 189.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "display(main_df_scaled.sample(10))\n",
    "print()\n",
    "print(main_df_scaled.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data was correctly scaled! Now let's test the **get_knn** function for every combination of scaling and distance metrics.\n",
    "\n",
    "Specifically, I will set n = 0 and k = 11 in order to find the 10 customers who are most similar to the first customer in the dataframe. (The reason why k needs to be set equal to 11 instead of 10 is because the first customer, n = 0, is counted as one of the 11.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>1.732051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>3.316625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>4.123106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>4.242641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>5.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>5.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>8.062258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  income  family_members  distance\n",
       "0          1   41   49600               1  0.000000\n",
       "1992       1   41   49600               0  1.000000\n",
       "1214       0   42   49600               0  1.732051\n",
       "3916       1   44   49600               2  3.162278\n",
       "3334       0   38   49600               0  3.316625\n",
       "810        1   37   49600               2  4.123106\n",
       "4520       0   45   49600               0  4.242641\n",
       "2094       0   37   49600               2  4.242641\n",
       "2311       1   46   49600               2  5.099020\n",
       "3790       1   36   49600               0  5.099020\n",
       "3590       1   33   49600               0  8.062258"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "not_scaled_euclidean = get_knn(main_df[features_names], 0, 11, 'euclidean')\n",
    "display(not_scaled_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.634177</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.017754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>1</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.018418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>1</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.028550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.029624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.635443</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.034893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608861</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.036156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  distance\n",
       "0          1  0.630769  0.627848        0.166667  0.000000\n",
       "2632       1  0.630769  0.634177        0.166667  0.006329\n",
       "133        1  0.615385  0.636709        0.166667  0.017754\n",
       "4720       1  0.646154  0.637975        0.166667  0.018418\n",
       "3192       1  0.646154  0.651899        0.166667  0.028550\n",
       "1550       1  0.615385  0.602532        0.166667  0.029624\n",
       "2072       1  0.630769  0.596203        0.166667  0.031646\n",
       "124        1  0.661538  0.635443        0.166667  0.031693\n",
       "3541       1  0.615385  0.600000        0.166667  0.031815\n",
       "3099       1  0.600000  0.611392        0.166667  0.034893\n",
       "69         1  0.600000  0.608861        0.166667  0.036156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_euclidean = get_knn(main_df_scaled[features_names], 0, 11, 'euclidean')\n",
    "display(scaled_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>49600</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>49600</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  age  income  family_members  distance\n",
       "0          1   41   49600               1       0.0\n",
       "1992       1   41   49600               0       1.0\n",
       "1214       0   42   49600               0       3.0\n",
       "3916       1   44   49600               2       4.0\n",
       "3334       0   38   49600               0       5.0\n",
       "810        1   37   49600               2       5.0\n",
       "4520       0   45   49600               0       6.0\n",
       "2094       0   37   49600               2       6.0\n",
       "2311       1   46   49600               2       6.0\n",
       "3790       1   36   49600               0       6.0\n",
       "3590       1   33   49600               0       9.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "not_scaled_manhattan = get_knn(main_df[features_names], 0, 11, 'manhattan')\n",
    "display(not_scaled_manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>family_members</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.627848</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.634177</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.636709</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.024245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>1</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.637975</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.025511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.596203</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.031646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.635443</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.038364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>1</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.588608</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.039241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>1</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.039435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.040701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.043233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.047225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender       age    income  family_members  distance\n",
       "0          1  0.630769  0.627848        0.166667  0.000000\n",
       "2632       1  0.630769  0.634177        0.166667  0.006329\n",
       "133        1  0.615385  0.636709        0.166667  0.024245\n",
       "4720       1  0.646154  0.637975        0.166667  0.025511\n",
       "2072       1  0.630769  0.596203        0.166667  0.031646\n",
       "124        1  0.661538  0.635443        0.166667  0.038364\n",
       "4173       1  0.630769  0.588608        0.166667  0.039241\n",
       "3192       1  0.646154  0.651899        0.166667  0.039435\n",
       "1550       1  0.615385  0.602532        0.166667  0.040701\n",
       "3541       1  0.615385  0.600000        0.166667  0.043233\n",
       "3099       1  0.600000  0.611392        0.166667  0.047225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaled_manhattan = get_knn(main_df_scaled[features_names], 0, 11, 'manhattan')\n",
    "display(scaled_manhattan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the data being not scaled affect the kNN algorithm? If so, how does that appear?** \n",
    "\n",
    "Oh, absolutely it does! The distances are much smaller when the data is scaled, regardless of the distance metric.\n",
    "\n",
    "When the data is not scaled, the 10 shortest distances using the euclidean metric range from 1 to 8.062258, and using the manhattan metric the 10 shortest distances range from 1 to 9.\n",
    "\n",
    "In contrast, when the data is scaled all 10 shortest distances are less than 1 (in fact, all 10 shortest distances are much closer to 0 than to 1). The euclidean metric distances range from 0.006329 to 0.036156 and the manhattan metric distances range from 0.006329 to 0.047225.\n",
    "\n",
    "I think the **income** column is the main reason why the data being not scaled affects the kNN algorithm. In the original (i.e. not scaled) dataframe, the income values have a much larger magnitude than the other features, and thus the income column influences the distances much more than the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How similar are the results using the Manhattan distance metric (regardless of the scaling)?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's store the distance values and their corresponding indexes into new dataframes to make comparing the results easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_not_scaled_euc</th>\n",
       "      <th>index_not_scaled_man</th>\n",
       "      <th>same_index</th>\n",
       "      <th>distance_not_scaled_euc</th>\n",
       "      <th>distance_not_scaled_man</th>\n",
       "      <th>distance_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.267949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3916</td>\n",
       "      <td>3916</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.837722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3334</td>\n",
       "      <td>3334</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.683375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>810</td>\n",
       "      <td>810</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.876894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4520</td>\n",
       "      <td>4520</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.757359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2094</td>\n",
       "      <td>2094</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.757359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2311</td>\n",
       "      <td>2311</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.099020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.900980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3790</td>\n",
       "      <td>3790</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5.099020</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.900980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3590</td>\n",
       "      <td>3590</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.062258</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.937742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_not_scaled_euc  index_not_scaled_man same_index  \\\n",
       "1                   1992                  1992        Yes   \n",
       "2                   1214                  1214        Yes   \n",
       "3                   3916                  3916        Yes   \n",
       "4                   3334                  3334        Yes   \n",
       "5                    810                   810        Yes   \n",
       "6                   4520                  4520        Yes   \n",
       "7                   2094                  2094        Yes   \n",
       "8                   2311                  2311        Yes   \n",
       "9                   3790                  3790        Yes   \n",
       "10                  3590                  3590        Yes   \n",
       "\n",
       "    distance_not_scaled_euc  distance_not_scaled_man  distance_difference  \n",
       "1                  1.000000                      1.0             0.000000  \n",
       "2                  1.732051                      3.0             1.267949  \n",
       "3                  3.162278                      4.0             0.837722  \n",
       "4                  3.316625                      5.0             1.683375  \n",
       "5                  4.123106                      5.0             0.876894  \n",
       "6                  4.242641                      6.0             1.757359  \n",
       "7                  4.242641                      6.0             1.757359  \n",
       "8                  5.099020                      6.0             0.900980  \n",
       "9                  5.099020                      6.0             0.900980  \n",
       "10                 8.062258                      9.0             0.937742  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_and_distance_not_scaled_df = pd.DataFrame()\n",
    "\n",
    "index_and_distance_not_scaled_df['index_not_scaled_euc'] = not_scaled_euclidean.index\n",
    "index_and_distance_not_scaled_df['index_not_scaled_man'] = not_scaled_manhattan.index\n",
    "index_and_distance_not_scaled_df['same_index'] = (index_and_distance_not_scaled_df['index_not_scaled_euc'] == index_and_distance_not_scaled_df['index_not_scaled_man']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "index_and_distance_not_scaled_df['distance_not_scaled_euc'] = not_scaled_euclidean['distance'].values\n",
    "index_and_distance_not_scaled_df['distance_not_scaled_man'] = not_scaled_manhattan['distance'].values\n",
    "index_and_distance_not_scaled_df['distance_difference'] = index_and_distance_not_scaled_df['distance_not_scaled_man'] - index_and_distance_not_scaled_df['distance_not_scaled_euc']\n",
    "\n",
    "index_and_distance_not_scaled_df.drop(index_and_distance_not_scaled_df.index[0], inplace = True)\n",
    "\n",
    "display(index_and_distance_not_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, when the data is not scaled the euclidean and manhattan metrics yield very similar results. In fact, 7 out of the 10 shortest distances for both metrics have the same index, meaning 7 out of the 10 customers nearest to the first customer are not only the same people for both metrics, but also those 7 people are located in the same slot.\n",
    "\n",
    "As for the 3 customers not in the exact same slot (index values 2094, 3790, and 2311), they are all nevertheless present in a nearby slot. For example, the customer with index 3790 is the 8th nearest customer when using the euclidean metric, and is the 9th nearest customer when using the manhattan metric.\n",
    "\n",
    "Lastly, the distances are all quite similar. Manhattan distance is always greater than or equal to euclidean distance, never less than, so it makes sense that most of the manhattan distances are slightly larger. Thankfully, all of the manhattan distances are less than 2 units larger than the euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_scaled_euc</th>\n",
       "      <th>index_scaled_man</th>\n",
       "      <th>same_index</th>\n",
       "      <th>distance_scaled_euc</th>\n",
       "      <th>distance_scaled_man</th>\n",
       "      <th>distance_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2632</td>\n",
       "      <td>2632</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>133</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>0.006492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4720</td>\n",
       "      <td>4720</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>0.025511</td>\n",
       "      <td>0.007093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3192</td>\n",
       "      <td>2072</td>\n",
       "      <td>No</td>\n",
       "      <td>0.028550</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.003095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1550</td>\n",
       "      <td>124</td>\n",
       "      <td>No</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.008740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2072</td>\n",
       "      <td>4173</td>\n",
       "      <td>No</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.039241</td>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>124</td>\n",
       "      <td>3192</td>\n",
       "      <td>No</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.039435</td>\n",
       "      <td>0.007743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3541</td>\n",
       "      <td>1550</td>\n",
       "      <td>No</td>\n",
       "      <td>0.031815</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>0.008886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3099</td>\n",
       "      <td>3541</td>\n",
       "      <td>No</td>\n",
       "      <td>0.034893</td>\n",
       "      <td>0.043233</td>\n",
       "      <td>0.008340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>69</td>\n",
       "      <td>3099</td>\n",
       "      <td>No</td>\n",
       "      <td>0.036156</td>\n",
       "      <td>0.047225</td>\n",
       "      <td>0.011069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_scaled_euc  index_scaled_man same_index  distance_scaled_euc  \\\n",
       "1               2632              2632        Yes             0.006329   \n",
       "2                133               133        Yes             0.017754   \n",
       "3               4720              4720        Yes             0.018418   \n",
       "4               3192              2072         No             0.028550   \n",
       "5               1550               124         No             0.029624   \n",
       "6               2072              4173         No             0.031646   \n",
       "7                124              3192         No             0.031693   \n",
       "8               3541              1550         No             0.031815   \n",
       "9               3099              3541         No             0.034893   \n",
       "10                69              3099         No             0.036156   \n",
       "\n",
       "    distance_scaled_man  distance_difference  \n",
       "1              0.006329             0.000000  \n",
       "2              0.024245             0.006492  \n",
       "3              0.025511             0.007093  \n",
       "4              0.031646             0.003095  \n",
       "5              0.038364             0.008740  \n",
       "6              0.039241             0.007595  \n",
       "7              0.039435             0.007743  \n",
       "8              0.040701             0.008886  \n",
       "9              0.043233             0.008340  \n",
       "10             0.047225             0.011069  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_and_distance_scaled_df = pd.DataFrame()\n",
    "\n",
    "index_and_distance_scaled_df['index_scaled_euc'] = scaled_euclidean.index\n",
    "index_and_distance_scaled_df['index_scaled_man'] = scaled_manhattan.index\n",
    "index_and_distance_scaled_df['same_index'] = (index_and_distance_scaled_df['index_scaled_euc'] == index_and_distance_scaled_df['index_scaled_man']).map({True: 'Yes', False: 'No'})\n",
    "\n",
    "index_and_distance_scaled_df['distance_scaled_euc'] = scaled_euclidean['distance'].values\n",
    "index_and_distance_scaled_df['distance_scaled_man'] = scaled_manhattan['distance'].values\n",
    "index_and_distance_scaled_df['distance_difference'] = index_and_distance_scaled_df['distance_scaled_man'] - index_and_distance_scaled_df['distance_scaled_euc']\n",
    "\n",
    "\n",
    "index_and_distance_scaled_df.drop(index_and_distance_scaled_df.index[0], inplace = True)\n",
    "\n",
    "display(index_and_distance_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the indexes are not as similar when using the scaled data. The top 3 shortest distance customers (index values 2632, 133, and 4720) are the same for both metrics, but only those 3. \n",
    "\n",
    "On the bright side, both metrics identified 6 additional customers as being somewhere in the top 10: those with index values, in order from least to greatest, 124, 1550, 2072, 3099, 3192, 3541. \n",
    "\n",
    "Interestingly, the customer with index 69 got 10th place when using euclidean distance, but does not appear anywhere in the top 10 using manhattan distance. Furthermore, the customer with index 4173 only appears in the top 10 using manhattan distance,  in 6th place. \n",
    "\n",
    "Lastly, I should mention that the distance values are extremely similar. The <b><i>largest</b></i> difference in distance is 0.011069, which is still very close to 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Is The Customer Likely to Receive Insurance Benefits? <a id = 4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above question can be treated as a binary classification task, since either a customer receives insurance benefits or does not.\n",
    "\n",
    "With `insurance_benefits` being more than zero as the target, I wonder if kNN classification can do better than a dummy model.\n",
    "\n",
    "I will now follow these instructions:\n",
    "- Build a KNN-based classifier and measure its quality with the F1 metric for parameter **n_neighbors** = 1 through 10 for both the original data and the scaled one. (It would be interesting to see how k influences the evaluation metric, and whether scaling the data makes any difference.)\n",
    "- Build a dummy model which is just random for this case. It should return \"1\" with some probability. Let's test the dummy model with four probability values: 0, the value of the probability of receiving any insurance benefit, 0.5, and 1.\n",
    "\n",
    "The probability of receiving any insurance benefit can be defined as\n",
    "\n",
    "$$\n",
    "P\\{\\text{insurance benefit received}\\}=\\frac{\\text{number of customers who received any insurance benefit}}{\\text{total number of customers}}.\n",
    "$$\n",
    "\n",
    "I will split the whole data using a 70:30 ratio for the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line adds a new column to the **main_df**, which indicates whether or not a customer received at least 1 benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['insurance_benefits_received'] = main_df['insurance_benefits'].apply(lambda x: \n",
    "                                                                             'No' if x == 0 \n",
    "                                                                             else 'Yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worry that there is a serious class imbalance with the **insurance_benefits_received** values. Let's see if there is... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "insurance_benefits_received\n",
       "No     4284\n",
       "Yes     563\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['insurance_benefits_received'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, there is a class imbalance because there are <b><i>far more</b></i> customers who receive no benefits than there are customers who receive at least one benefit. Thankfully, this can be remedied using the **stratify** parameter of **train_test_split**. Let's split the original data into training and test sets using a 70:30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_scaled_train, not_scaled_test = train_test_split(main_df, test_size = 0.3, \n",
    "                                                     stratify = main_df['insurance_benefits_received'], \n",
    "                                                     random_state = 12345)\n",
    "\n",
    "not_scaled_train_features = not_scaled_train[features_names].copy()\n",
    "not_scaled_train_targets = not_scaled_train['insurance_benefits_received'].copy()\n",
    "\n",
    "not_scaled_test_features = not_scaled_test[features_names].copy()\n",
    "not_scaled_test_targets = not_scaled_test['insurance_benefits_received'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test a KNN classifier by finding the F1 score and the confusion matrix when the **n_neighbors** parameter is set equal to every integer between 1 and 10, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred, pos_label = 'Yes')\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score and confusion matrix for n_neighbors = 1\n",
      "F1: 0.66\n",
      "Confusion Matrix\n",
      "[[1255   31]\n",
      " [  70   99]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 2\n",
      "F1: 0.35\n",
      "Confusion Matrix\n",
      "[[1281    5]\n",
      " [ 132   37]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 3\n",
      "F1: 0.40\n",
      "Confusion Matrix\n",
      "[[1268   18]\n",
      " [ 122   47]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 4\n",
      "F1: 0.19\n",
      "Confusion Matrix\n",
      "[[1282    4]\n",
      " [ 151   18]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 5\n",
      "F1: 0.20\n",
      "Confusion Matrix\n",
      "[[1276   10]\n",
      " [ 149   20]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 6\n",
      "F1: 0.12\n",
      "Confusion Matrix\n",
      "[[1284    2]\n",
      " [ 158   11]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 7\n",
      "F1: 0.13\n",
      "Confusion Matrix\n",
      "[[1282    4]\n",
      " [ 157   12]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 8\n",
      "F1: 0.06\n",
      "Confusion Matrix\n",
      "[[1286    0]\n",
      " [ 164    5]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 9\n",
      "F1: 0.06\n",
      "Confusion Matrix\n",
      "[[1285    1]\n",
      " [ 164    5]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 10\n",
      "F1: 0.00\n",
      "Confusion Matrix\n",
      "[[1286    0]\n",
      " [ 169    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for integer in range(1, 11):\n",
    "    print('F1 score and confusion matrix for n_neighbors =', integer)\n",
    "    knn_not_scaled = sklearn.neighbors.KNeighborsClassifier(n_neighbors = integer)\n",
    "    knn_not_scaled.fit(not_scaled_train_features, not_scaled_train_targets)\n",
    "    eval_classifier(not_scaled_test_targets, knn_not_scaled.predict(not_scaled_test_features))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, the F1 score decreases as the value of **n_neighbors** increases. The best F1 score, by far, is 0.65 which occurs when **n_neighbors** = 1. \n",
    "\n",
    "In fact, this is the only F1 score that is greater than 0.5, which suggests that the balance between precision and recall is pretty good (but not great)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same with the scaled data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.35384615 0.4        0.56923077 ... 0.4        0.29230769 0.56923077]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  scaled_train_features.loc[:, features_names] = transformer_mas.fit_transform(scaled_train_features)\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.5837766  0.63696809 0.56515957 ... 0.59441489 0.49867021 0.65957447]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  scaled_train_features.loc[:, features_names] = transformer_mas.fit_transform(scaled_train_features)\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.         0.         0.16666667 ... 0.33333333 0.         0.33333333]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  scaled_train_features.loc[:, features_names] = transformer_mas.fit_transform(scaled_train_features)\n",
      "C:\\Users\\18604\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MaxAbsScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.27692308 0.38461538 0.29230769 ... 0.53846154 0.6        0.43076923]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  scaled_test_features.loc[:, features_names] = transformer_mas.transform(scaled_test_features.to_numpy())\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.65691489 0.57579787 0.47074468 ... 0.5731383  0.47606383 0.60505319]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  scaled_test_features.loc[:, features_names] = transformer_mas.transform(scaled_test_features.to_numpy())\n",
      "C:\\Users\\18604\\AppData\\Local\\Temp\\ipykernel_33668\\3154835995.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.16666667 0.         0.33333333 ... 0.33333333 0.16666667 0.        ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  scaled_test_features.loc[:, features_names] = transformer_mas.transform(scaled_test_features.to_numpy())\n"
     ]
    }
   ],
   "source": [
    "scaled_train, scaled_test = train_test_split(main_df, test_size = 0.3, \n",
    "                                             stratify = main_df['insurance_benefits_received'], \n",
    "                                             random_state = 12345)\n",
    "\n",
    "scaled_train_features = scaled_train[features_names].copy()\n",
    "scaled_train_features.loc[:, features_names] = transformer_mas.fit_transform(scaled_train_features)\n",
    "\n",
    "scaled_train_targets = scaled_train['insurance_benefits_received'].copy()\n",
    "\n",
    "scaled_test_features = scaled_test[features_names].copy()\n",
    "scaled_test_features.loc[:, features_names] = transformer_mas.transform(scaled_test_features.to_numpy())\n",
    "\n",
    "scaled_test_targets = scaled_test['insurance_benefits_received'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score and confusion matrix for n_neighbors = 1\n",
      "F1: 0.95\n",
      "Confusion Matrix\n",
      "[[1280    6]\n",
      " [  11  158]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 2\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1285    1]\n",
      " [  25  144]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 3\n",
      "F1: 0.94\n",
      "Confusion Matrix\n",
      "[[1279    7]\n",
      " [  14  155]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 4\n",
      "F1: 0.90\n",
      "Confusion Matrix\n",
      "[[1283    3]\n",
      " [  29  140]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 5\n",
      "F1: 0.93\n",
      "Confusion Matrix\n",
      "[[1280    6]\n",
      " [  17  152]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 6\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1285    1]\n",
      " [  23  146]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 7\n",
      "F1: 0.94\n",
      "Confusion Matrix\n",
      "[[1283    3]\n",
      " [  17  152]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 8\n",
      "F1: 0.92\n",
      "Confusion Matrix\n",
      "[[1284    2]\n",
      " [  22  147]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 9\n",
      "F1: 0.94\n",
      "Confusion Matrix\n",
      "[[1283    3]\n",
      " [  17  152]]\n",
      "\n",
      "F1 score and confusion matrix for n_neighbors = 10\n",
      "F1: 0.91\n",
      "Confusion Matrix\n",
      "[[1286    0]\n",
      " [  28  141]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for integer in range(1, 11):\n",
    "    print('F1 score and confusion matrix for n_neighbors =', integer)\n",
    "    knn_scaled = sklearn.neighbors.KNeighborsClassifier(n_neighbors = integer)\n",
    "    knn_scaled.fit(scaled_train_features, scaled_train_targets)\n",
    "    eval_classifier(scaled_test_targets, knn_scaled.predict(scaled_test_features))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! These are fantastic results! Just like how the scaled data got much better results in Task 1, in the form of much shortest distances, the scaled data also has much better results in this task. I think it is fantastic to see that all 10 confusion matrices of the scaled data correspond to an F1 score that is at least 0.9. Since all of the F1 scores are so close to 1, that implies an excellent balance between precision and recall. The practical takeaway from this is that <u>Sure Tomorrow</u> can use the scaled data to identify at least 10 (possibly more) neighbors for any given customer with a high degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for the dummy model. The very next line generates the outputs of a random (dummy) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnd_model_predict(P, size, seed = 42):\n",
    "\n",
    "    rng = np.random.default_rng(seed = seed)\n",
    "    return rng.binomial(n = 1, p = P, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability: 0.00\n",
      "F1: 0.00\n",
      "Confusion Matrix\n",
      "[[4284    0]\n",
      " [ 563    0]]\n",
      "\n",
      "The probability: 0.12\n",
      "F1: 0.13\n",
      "Confusion Matrix\n",
      "[[3805  479]\n",
      " [ 493   70]]\n",
      "\n",
      "The probability: 0.50\n",
      "F1: 0.19\n",
      "Confusion Matrix\n",
      "[[2175 2109]\n",
      " [ 287  276]]\n",
      "\n",
      "The probability: 1.00\n",
      "F1: 0.21\n",
      "Confusion Matrix\n",
      "[[   0 4284]\n",
      " [   0  563]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_value in [0, main_df['insurance_benefits_received'].value_counts()['Yes'] / len(main_df), 0.5, 1]:\n",
    "\n",
    "    print(f'The probability: {p_value:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(p_value, main_df['insurance_benefits_received'].shape[0])\n",
    "    y_pred_rnd = ['Yes' if pred == 1 else 'No' for pred in y_pred_rnd]\n",
    "    \n",
    "    eval_classifier(main_df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very best dummy model has an F1 score of 0.21, which is worse than even the original data has **n_neighbors** set equal to 1, 2, or 3.\n",
    "\n",
    "Perhaps it goes without saying, but the dummy model is nowhere near as good as the KNN classifier when using the scaled data. This is, of course, great news because there would be no point in using a model that isn't significantly better than a dummy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Linear Regression <a id = 5></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `insurance_benefits` as the target, evaluate what RMSE would be for a Linear Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own implementation of LR. For that, recall how the linear regression task's solution is formulated in terms of LA. Check RMSE for both the original data and the scaled one. Can you see any difference in RMSE between these two cases?\n",
    "\n",
    "Let's denote\n",
    "- $X$ — Feature matrix, each row is a case, each column is a feature, the first column consists of unities\n",
    "- $y$ — Target (a vector)\n",
    "- $\\hat{y}$ — Estimated tagret (a vector)\n",
    "- $w$ — Weight vector\n",
    "\n",
    "The task of linear regression in the language of matrices can be formulated as\n",
    "\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "The training objective then is to find such $w$ that it would minimize the L2-distance (MSE) between $Xw$ and $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "It appears that there is analytical solution for the above:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "The formula above can be used to find the weights $w$ and the latter can be used to calculate predicted values\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the whole data into the ratio 70:30 for the training and test sets. Use the RMSE metric for the model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X_feature, y_target):\n",
    "        \n",
    "        X2_feature = np.append(np.ones([len(X_feature), 1]), X_feature, axis = 1)\n",
    "        self.weights = np.linalg.inv(X2_feature.T.dot(X2_feature)).dot(X2_feature.T).dot(y_target)\n",
    "\n",
    "    def predict(self, X_feature):\n",
    "        \n",
    "        X2_feature = np.append(np.ones([len(X_feature), 1]), X_feature, axis = 1)\n",
    "        y_pred = X2_feature.dot(self.weights)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now ready to test the linear regression on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.77366679e-01  1.95594897e-02  3.58042290e-02  5.85335011e-07\n",
      " -1.21618426e-02]\n",
      "RMSE: 0.36\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_feature_od = main_df[features_names].to_numpy()\n",
    "y_target_od = main_df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_feature_od_train, X_feature_od_test, y_target_od_train, y_target_od_test = train_test_split(X_feature_od, y_target_od, \n",
    "                                                                                              test_size = 0.3, \n",
    "                                                                                              random_state = 12345)\n",
    "\n",
    "not_scaled_lr = MyLinearRegression()\n",
    "not_scaled_lr.fit(X_feature_od_train, y_target_od_train)\n",
    "\n",
    "print(not_scaled_lr.weights)\n",
    "\n",
    "y_target_od_test_pred = not_scaled_lr.predict(X_feature_od_test)\n",
    "eval_regressor(y_target_od_test, y_target_od_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what RMSE and R2 values the scaled data gives us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97736668  0.01955949  2.32727489  0.04378306 -0.07297106]\n",
      "RMSE: 0.36\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_feature_sd_train, X_feature_sd_test, y_target_sd_train, y_target_sd_test = train_test_split(X_feature_od, y_target_od, \n",
    "                                                                                              test_size = 0.3, \n",
    "                                                                                              random_state = 12345)\n",
    "\n",
    "\n",
    "X_feature_sd_train = transformer_mas.fit_transform(X_feature_sd_train)\n",
    "X_feature_sd_test = transformer_mas.transform(X_feature_sd_test)\n",
    "\n",
    "scaled_lr = MyLinearRegression()\n",
    "scaled_lr.fit(X_feature_sd_train, y_target_sd_train)\n",
    "\n",
    "print(scaled_lr.weights)\n",
    "\n",
    "y_target_sd_test_pred = scaled_lr.predict(X_feature_sd_test)\n",
    "eval_regressor(y_target_sd_test, y_target_sd_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really? Fascinating... I was expecting the scaled data to yield a smaller RMSE value and a larger R2 value than the original data, but (despite having different values in the resulting vectors) instead these values are exactly the same. Though the scaled data was the clear \"winner\" in Tasks 1 and 2, in this task I am not sure how to tell which of the two data sets is better to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Obfuscating Data <a id = 6></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It best to obfuscate data by multiplying the numerical features (remember, they can be seen as the matrix $X$) by an invertible matrix $P$. \n",
    "\n",
    "$$\n",
    "X' = XP\n",
    "$$\n",
    "\n",
    "I will do that and then check how the features' values look after the transformation. It is imperative that I make sure $P$ is invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df_pn = main_df[features_names].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix = main_df_pn.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have the values of the dataframe been correctly put into the matrix? Let's see if the first 10 rows match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age  income  family_members\n",
      "0       1   41   49600               1\n",
      "1       0   46   38000               1\n",
      "2       0   29   21000               0\n",
      "3       0   21   41700               2\n",
      "4       1   28   26100               0\n",
      "5       1   43   41000               2\n",
      "6       1   39   39700               2\n",
      "7       1   25   38600               4\n",
      "8       1   36   49700               1\n",
      "9       1   32   51700               1\n"
     ]
    }
   ],
   "source": [
    "print(main_df_pn.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    41 49600     1]\n",
      " [    0    46 38000     1]\n",
      " [    0    29 21000     0]\n",
      " [    0    21 41700     2]\n",
      " [    1    28 26100     0]\n",
      " [    1    43 41000     2]\n",
      " [    1    39 39700     2]\n",
      " [    1    25 38600     4]\n",
      " [    1    36 49700     1]\n",
      " [    1    32 51700     1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_matrix[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes they have (been correctly put into the matrix)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate a random matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed = 42)\n",
    "P_matrix = rng.random(size = (X_matrix.shape[1], X_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the matrix $P$ invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix P is:\n",
      "[[0.77395605 0.43887844 0.85859792 0.69736803]\n",
      " [0.09417735 0.97562235 0.7611397  0.78606431]\n",
      " [0.12811363 0.45038594 0.37079802 0.92676499]\n",
      " [0.64386512 0.82276161 0.4434142  0.22723872]]\n",
      "\n",
      "The (apparent) inverse of matrix P is:\n",
      "[[ 0.41467992 -1.43783972  0.62798546  1.14001268]\n",
      " [-1.06101789  0.44219337  0.1329549   1.18425933]\n",
      " [ 1.42362442  1.60461607 -2.0553823  -1.53699695]\n",
      " [-0.11128575 -0.65813802  1.74995517 -0.11816316]]\n"
     ]
    }
   ],
   "source": [
    "print('The matrix P is:')\n",
    "print(P_matrix)\n",
    "print()\n",
    "print('The (apparent) inverse of matrix P is:')\n",
    "print(np.linalg.inv(P_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears as though $P$ is indeed invertible. If I now multiply $P$ by its apparent inverse, then I should get the identity matrix. (The identity matrix is the one where all of the numbers in the main diagonal are 1, and every other number is 0.)\n",
    "\n",
    "Oftentimes when doing this kind of operation, the numbers that are not in the main diagonal are not exactly 0, but rather extremely close to 0. The code below will print the product of the matrices in such a way that all the numbers are rounded to the nearest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of matrix P and its (apparent) inverse is:\n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "print('The product of matrix P and its (apparent) inverse is:')\n",
    "print(np.round(P_matrix @ np.linalg.inv(P_matrix)).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! I acquired the identity matrix, as I hoped I would!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I guess the customers' ages or income after the transformation?\n",
    "\n",
    "Recall that I printed the first 10 rows of the matrix earlier. If the transformation works correctly, then it would be extremely difficult, if not impossible, to correctly guess the gender, age, income, and family members values of the first 10 rows, and really all of the rows, after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 rows of the matrix before the transformation:\n",
      "[[    1    41 49600     1]\n",
      " [    0    46 38000     1]\n",
      " [    0    29 21000     0]\n",
      " [    0    21 41700     2]\n",
      " [    1    28 26100     0]\n",
      " [    1    43 41000     2]\n",
      " [    1    39 39700     2]\n",
      " [    1    25 38600     4]\n",
      " [    1    36 49700     1]\n",
      " [    1    32 51700     1]]\n",
      "\n",
      "The first 10 rows of the matrix after the transformation:\n",
      "[[ 6359.71527314 22380.40467609 18424.09074184 46000.69669016]\n",
      " [ 4873.29406479 17160.36702982 14125.78076133 35253.45577301]\n",
      " [ 2693.11742928  9486.397744    7808.83156024 19484.86063067]\n",
      " [ 5345.60393712 18803.22720286 15479.14837264 38663.06186284]\n",
      " [ 3347.17673462 11782.82928336  9699.99894205 24211.27337753]\n",
      " [ 5258.77025195 18509.8596165  15237.19342704 38032.31715339]\n",
      " [ 5091.84582008 17920.45540783 14752.11143673 36824.37841067]\n",
      " [ 4950.8900715  17413.01768645 14334.46448264 35794.3865001 ]\n",
      " [ 6372.05574967 22420.56515812 18457.36484575 46089.44286752]\n",
      " [ 6627.90630563 23317.43454451 19195.91633541 47939.82858799]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = False)\n",
    "\n",
    "print('The first 10 rows of the matrix before the transformation:')\n",
    "print(X_matrix[:10])\n",
    "print()\n",
    "print('The first 10 rows of the matrix after the transformation:')\n",
    "print((X_matrix @ P_matrix)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! To give just one example of how difficult it now is to guess any of the features values of a customer, before the transformation 3 of the customers in the first 10 rows have a gender value of 0, and after the transformation the gender values of those 3 customers are now 4873.29406479, 2693.11742928, and 5345.60393712. I doubt anyone would recognize that those three very different numbers are actually associated with the same gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can I recover the original data from $X'$ if I know $P$? I should be able to by multiplying $X'$ by the inverse of $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    1    41 49600     1]\n",
      " [    0    46 38000     1]\n",
      " [    0    29 21000     0]\n",
      " [    0    21 41700     2]\n",
      " [    1    28 26100     0]\n",
      " [    1    43 41000     2]\n",
      " [    1    39 39700     2]\n",
      " [    1    25 38600     4]\n",
      " [    1    36 49700     1]\n",
      " [    1    32 51700     1]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "print(np.round(X_matrix @ P_matrix @ np.linalg.inv(P_matrix))[:10].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! I successfully recovered the first 10 rows of the original data, which suggests to me that I should be able to recover the whole matrix if need be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all three cases for a few customers\n",
    "- The original data\n",
    "- The transformed one\n",
    "- The reversed (recovered) one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, I actually already did this. However, let's do it again without any rounding. Since the directions ask for only a \"few\" customers, let's look at the last 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last 4 rows of the original dataframe's features columns:\n",
      "      gender  age  income  family_members\n",
      "4843       0   34   52400               1\n",
      "4844       0   20   33900               2\n",
      "4845       1   22   32700               3\n",
      "4846       1   28   40600               1\n",
      "\n",
      "The last 4 rows of the matrix before the transformation:\n",
      "[[    0    34 52400     1]\n",
      " [    0    20 33900     2]\n",
      " [    1    22 32700     3]\n",
      " [    1    28 40600     1]]\n",
      "\n",
      "The last 4 rows of the matrix after the transformation:\n",
      "[[ 6717.00024715 23634.2170673  19456.13863385 48589.43884077]\n",
      " [ 4346.2234249  15289.24126492 12586.16264392 31433.50888552]\n",
      " [ 4194.09324155 14751.9910242  12144.02930637 30323.88763426]\n",
      " [ 5205.46827354 18314.24814446 15077.01370762 37649.59295455]]\n",
      "\n",
      "The last 4 rows of the matrix after reversing the transformation:\n",
      "[[-1.18234311e-11  3.40000000e+01  5.24000000e+04  1.00000000e+00]\n",
      " [ 9.09494702e-13  2.00000000e+01  3.39000000e+04  2.00000000e+00]\n",
      " [ 1.00000000e+00  2.20000000e+01  3.27000000e+04  3.00000000e+00]\n",
      " [ 1.00000000e+00  2.80000000e+01  4.06000000e+04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = False)\n",
    "\n",
    "print('The last 4 rows of the original dataframe\\'s features columns:')\n",
    "print(main_df_pn.tail(4))\n",
    "print()\n",
    "print('The last 4 rows of the matrix before the transformation:')\n",
    "print(X_matrix[-4:])\n",
    "print()\n",
    "print('The last 4 rows of the matrix after the transformation:')\n",
    "print((X_matrix @ P_matrix)[-4:])\n",
    "print()\n",
    "print('The last 4 rows of the matrix after reversing the transformation:')\n",
    "print((X_matrix @ P_matrix @ np.linalg.inv(P_matrix))[-4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can probably see that some values are not exactly the same as they are in the original data. What might be the reason for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, some of the values are not <b><i>exactly</b></i> the same, but they are similar enough that I should not be worried. I think some of the values are slightly off because the transformation caused many of the values of the matrix to go from being integers to floats that have many decimal places, and it is difficult to precisely multiply numbers that have so many decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Proof That Data Obfuscation Can Work with Linear Regression</b> <a id = 6.1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression task has been solved with linear regression in this project. I must now prove <b>_analytically_</b> that the given obfuscation method won't affect the linear regression in terms of the predicted values (i.e. their values will remain the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the data is obfuscated and there is $X \\times P$ instead of just $X$ now. Consequently, there are other weights $w_P$ as\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would $w$ and $w_P$ be linked if you simplify the formula for $w_P$ above? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proof begins with the assumption that $w_P = [(XP)^T XP]^{-1} (XP)^T y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope to show that $w$ and $w_P$ are linked by demonstrating that the expression for $w$ can be substituted into $w_P$ after using properties of matrices to rearrange the expression for $w_P$ in particular ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $(XP)^T$ = $P^TX^T$, then $w_P = [(XP)^T XP]^{-1} (XP)^T y = [P^TX^T XP]^{-1} P^TX^T y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, $[P^TX^T XP]^{-1} = P^{-1}(X^T X)^{-1}(P^{T})^{-1}$ meaning $w_P = [P^TX^T XP]^{-1} P^TX^T y = P^{-1}(X^T X)^{-1}(P^{T})^{-1} P^TX^T y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $(P^{T})^{-1} P^T = I$ (the identity matrix), which implies $w_P = P^{-1}(X^T X)^{-1}(P^{T})^{-1} P^TX^T y = P^{-1}(X^T X)^{-1}IX^T y = P^{-1}(X^T X)^{-1}X^T y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I realized that because $w = (X^T X)^{-1} X^T y$ then $w_P = P^{-1}(X^T X)^{-1}X^T y = P^{-1}w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, I have demonstrated that $w$ and $w_P$ can be linked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be predicted values with $w_P$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by mentioning that $A = Xw$ and $A′ = X′w_p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $X′ = XP$ (this was mentioned earlier) and $w_P = P^{-1}w$ then $A′ = X′w_p = XPP^{-1}w = Xw = A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does that mean for the quality of linear regression if you measure it with RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since A and A′ are equal, then the RMSE (which was calculated in Task 3) for both the original and the transformed datasets will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Test the Linear Regression With Data Obfuscation</b> <a id = 6.2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prove Linear Regression can work computationally with the chosen obfuscation transformation.\n",
    "\n",
    "I will build a procedure that runs the Linear Regression optionally with the obfuscation.\n",
    "\n",
    "I will run a Linear Regression for both the original data and the obfuscated, then compare the predicted values, the RMSE values, and the $R^2$ metric values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Procedure</u>\n",
    "\n",
    "- Create a square matrix $P$ of random numbers.\n",
    "- Check that it is invertible. If not, repeat the first point until we get an invertible matrix.\n",
    "- Use $XP$ as the new feature matrix.\n",
    "- Test both the original data and the obfuscated data using a Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rng = np.random.default_rng(seed = 42)\n",
    "new_P_matrix = rng.random(size = (X_matrix.shape[1], X_matrix.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The (new) matrix P is:\n",
      "[[0.55458479 0.06381726 0.82763117 0.6316644 ]\n",
      " [0.75808774 0.35452597 0.97069802 0.89312112]\n",
      " [0.7783835  0.19463871 0.466721   0.04380377]\n",
      " [0.15428949 0.68304895 0.74476216 0.96750973]]\n",
      "\n",
      "The (apparent) inverse of (the new) matrix P is:\n",
      "[[-3.30407744  4.40917525 -0.27870525 -1.90039547]\n",
      " [-0.95858897 -1.33121709  1.62644533  1.78106755]\n",
      " [ 6.24868421 -7.35167522  2.19103126  2.60761164]\n",
      " [-3.6064091   5.89580272 -2.79039845 -1.92803822]]\n"
     ]
    }
   ],
   "source": [
    "print('The (new) matrix P is:')\n",
    "print(new_P_matrix)\n",
    "print()\n",
    "print('The (apparent) inverse of (the new) matrix P is:')\n",
    "print(np.linalg.inv(new_P_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem as though the new matrix $P$ is invertible. Let's see if the product of $P$ and its (apparent) inverse is the identity matrix (as it should be)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of (the new) matrix P and its (apparent) inverse is:\n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress = True)\n",
    "\n",
    "print('The product of (the new) matrix P and its (apparent) inverse is:')\n",
    "print(np.round(new_P_matrix @ np.linalg.inv(new_P_matrix)).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! This confirms that I may use $XP$ as the new feature matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df_pn_new = main_df[features_names].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features and the targets are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_new = main_df_pn_new.to_numpy()\n",
    "y_target_new = main_df['insurance_benefits'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm ready to use a Linear Regression on the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97736668  0.01955949  0.03580423  0.00000059 -0.01216184]\n",
      "RMSE: 0.36\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_feature_new_train, X_feature_new_test, y_target_new_train, y_target_new_test = train_test_split(\n",
    "    X_feature_new, y_target_new, test_size = 0.3, random_state = 12345)\n",
    "\n",
    "new_lr_og_data = MyLinearRegression()\n",
    "new_lr_og_data.fit(X_feature_new_train, y_target_new_train)\n",
    "\n",
    "print(new_lr_og_data.weights)\n",
    "\n",
    "y_target_new_test_pred = new_lr_og_data.predict(X_feature_new_test)\n",
    "eval_regressor(y_target_new_test, y_target_new_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if I get the same RMSE and R2 values with the obfuscated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9773666   0.11635627 -0.08807214 -0.17271779  0.16400536]\n",
      "RMSE: 0.36\n",
      "R2: 0.66\n"
     ]
    }
   ],
   "source": [
    "X_feature_new_prime = X_feature_new @ new_P_matrix\n",
    "\n",
    "X_feature_new_train_ob, X_feature_new_test_ob, y_target_new_train_ob, y_target_new_test_ob = train_test_split(\n",
    "    X_feature_new_prime, y_target_new, test_size = 0.3, random_state = 12345)\n",
    "\n",
    "new_lr_ob_data = MyLinearRegression()\n",
    "new_lr_ob_data.fit(X_feature_new_train_ob, y_target_new_train_ob)\n",
    "\n",
    "print(new_lr_ob_data.weights)\n",
    "\n",
    "y_target_new_test_ob_pred = new_lr_ob_data.predict(X_feature_new_test_ob)\n",
    "eval_regressor(y_target_new_test_ob, y_target_new_test_ob_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! The fact that the RMSE and R2 values are the same implies that the data obfuscation does not impact the model's quality.\n",
    "\n",
    "This means that <u>Sure Tomorrow</u> is able to protect the personal details of its clients without needing to worry about this compromising the model's accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a id = 7></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have successfully solved all four tasks that <u>Sure Tomorrow</u> assigned me.\n",
    "\n",
    "<b>Task 1:</b> I wrote a function that returns the k nearest neighbors of a given customer. In particular, I discovered that scaling the data allows the function to make the distance between the 10 (if not more) nearest neighbors of a particular customer close to 0. This function will really help the company figure out how to effectively market its services to people of similar demographics.  \n",
    "\n",
    "<b>Task 2:</b> I successfully build a high-quality KNN-based classifier that can predict with a high degree of accuracy whether or not a new customer is likely to receive an insurance benefit. Specifically, when using the scaled data with the classifier, it has an F1 score at least 0.9 for all n_neighbors values between 1 and 10 inclusive. This is far superior to even the best dummy model, which has an F1 score of 0.21.\n",
    "\n",
    "<b>Task 3:</b> I used a linear regression model to predict the number of insurance benefits a new customer is likely to receive. The linear regression has an RMSE value of 0.36 (which is very small, as we would want it to be) and an R2 value of 0.66 (which is moderately large, also a good thing). These values were obtained regardless of whether the original or the scaled data was used.\n",
    "\n",
    "<b>Task 4:</b> I demonstrated that the linear regression model from Task 3 works equally as well after the customers' personal data received protection using data obfuscation as it did before. Thanks to the data obfuscation, it is now difficult for a malicious person or persons to acquire a customer's personal information if the data were to fall into their possession."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices <a id = 8></a>\n",
    "\n",
    "<b>Appendix A: Writing Formulas in Jupyter Notebooks</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write formulas in your Jupyter Notebook in a markup language provided by a high-quality publishing system called $\\LaTeX$ (pronounced \"Lah-tech\"), and they will look like formulas in textbooks.\n",
    "\n",
    "To put a formula in a text, put the dollar sign (\\\\$) before and after the formula's text e.g. $\\frac{1}{2} \\times \\frac{3}{2} = \\frac{3}{4}$ or $y = x^2, x \\ge 1$.\n",
    "\n",
    "If a formula should be in its own paragraph, put the double dollar sign (\\\\$\\\\$) before and after the formula text e.g.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i.\n",
    "$$\n",
    "\n",
    "The markup language of [LaTeX](https://en.wikipedia.org/wiki/LaTeX) is very popular among people who use formulas in their articles, books and texts. It can be complex but its basics are easy. Check this two page [cheatsheet](http://tug.ctan.org/info/undergradmath/undergradmath.pdf) for learning how to compose the most common formulas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Appendix B: Properties of Matrices</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices have many properties in Linear Algebra. A few of them are listed here which can help with the analytical proof in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>Distributivity</td><td>$A(B+C)=AB+AC$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Non-commutativity</td><td>$AB \\neq BA$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Associative property of multiplication</td><td>$(AB)C = A(BC)$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Multiplicative identity property</td><td>$IA = AI = A$</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td></td><td>$A^{-1}A = AA^{-1} = I$\n",
    "</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td></td><td>$(AB)^{-1} = B^{-1}A^{-1}$</td>\n",
    "</tr>    \n",
    "<tr>\n",
    "<td>Reversivity of the transpose of a product of matrices</td><td>$(AB)^T = B^TA^T$</td>\n",
    "</tr>    \n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
